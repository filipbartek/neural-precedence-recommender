% Source: https://fit.cvut.cz/cs/studium/programy-a-obory/doktorske/dsp-informatika/pro-stavajici-studenty/sablony

\documentclass[a4paper]{beamer}
%
% Josef Hlavac & Tomas Zahradnicky (21.10.2010)
%
%\usepackage{pgfpages}
%\pgfpagesuselayout{4 on 1}[a4paper,border shrink=5mm,landscape]
%\pgfpagesuselayout{resize}[a4paper,border shrink=5mm,landscape]
\usepackage[latin2]{inputenc}
\usepackage{color}
\usetheme{Frankfurt}
\useinnertheme{circles}
\usepackage{subfigure}
\usepackage[english]{babel}%\useinnertheme{rounded}

\input{preamble}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{pgfplots}

% glossaries should be loaded after hyperref.
\input{glossary}

% https://tex.stackexchange.com/a/33612/202639
\def\FuncSigmoid(#1){1.0/(1.0 + exp(-(#1)))}

%\useinnertheme{rectangles}
%\useinnertheme{balls}
\usefonttheme{professionalfonts}
%
\def\uv#1{\char92\relax #1\char34\relax}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand\Email{filip.bartek@cvut.cz}
\newcommand\DissertationTitle{Neural Precedence Recommender}
\newcommand\University{Czech Technical University in Prague}
\newcommand\FacultyAndUniversityAbbr{CTU}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author[F. Bártek, M. Suda]{\underline{Filip Bártek} \and Martin Suda}
\title{\DissertationTitle}
\titlegraphic{\includegraphics[width=1.5cm]{pic/LogoCVUT.pdf}}
\institute[\FacultyAndUniversityAbbr]{\University}
\date{\today}
%
\begin{document}
\begin{frame}
%\begin{center}
%\includegraphics[width=1.5cm]{pic/LogoCVUT.pdf}
%\end{center}
\titlepage
\end{frame}

\section*{Outline}
\begin{frame}%[allowframebreaks]
\frametitle{Outline}
\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}
\frametitle{Context}
\centering
\digraph[scale=0.5]{Context}{
graph [splines=ortho, ranksep=0.25];
node [shape=box, fontsize=14, width=0, height=0];
atp [label="Automated theorem proving for first-order logic"];
%cnf [label="Conjunctive normal form (CNF)", color=darkgray, fontcolor=darkgray];
superposition [label="Superposition calculus"];
sot [label="Simplification ordering on terms"];
kbo [label="Knuth-Bendix ordering"];
%selection [label="Literal selection", color=darkgray, fontcolor=darkgray];
%rewriting [label="Equality orientation", color=darkgray, fontcolor=darkgray];
precedence [label="Symbol precedence", style=bold];
frequency [label="Frequency heuristic"];
gcn [label="Graph convolutional network (GCN)", style=bold];
atp -> superposition -> sot -> kbo -> precedence -> frequency;
%atp -> cnf [color=darkgray];
%sot -> selection [color=darkgray];
%sot -> rewriting [color=darkgray];
precedence -> gcn;
}
\end{frame}

\section{Architecture}

\begin{frame}
\frametitle{Graph representation of a \acrshort{cnf} problem}
% Mention: relational graph, node types, edge types

Input problem: $a=b \wedge f(a,b) \neq f(b,b)$

\digraph[scale=0.5]{GcnExample}{
graph [ranksep=0.3];
node [fontsize=14, shape=record, height=0, width=0];
edge [fontsize=14, dir=both, arrowtail=empty];
problem [label=<problem|a=b &and; f(a,b)&ne;f(b,b)>];
{ rank = same;
c0 [label="clause|a=b"];
c1 [label=<clause|f(a,b)&ne;f(b,b)>];
}
problem -> c0;
problem -> c1;
{ rank = same;
t0 [label="equality atom|a=b"];
t1 [label="equality atom|f(a,b)=f(b,b)"];
}
c0 -> t0 [label=" pos "];
c1 -> t1 [label=" neg "];
{ rank = same;
tfab [label="term|f(a,b)"];
tfbb [label="term|f(b,b)"];
}
{ rank = same;
ta [label="term|a"];
tb [label="term|b"];
}
ff [label="function|f"];
fa [label="function|a"];
fb [label="function|b"];
tfab0 [label="argument|1"];
tfab1 [label="argument|2"];
tfbb0 [label="argument|1"];
tfbb1 [label="argument|2"];
t0 -> ta;
t0 -> tb;
t1 -> tfab;
t1 -> tfbb;
tfab -> ff;
tfab -> tfab0;
tfab0 -> tfab1;
tfab0 -> ta;
tfab1 -> tb;
tfbb -> ff;
tfbb -> tfbb0;
tfbb0 -> tfbb1;
tfbb0 -> tb;
tfbb1 -> tb;
ta -> fa;
tb -> fb;
% Technical details:
%ff -> ff [dir=forward];
%fa -> fa [dir=forward];
%fb -> fb [dir=forward];
}
\end{frame}

\begin{frame}
\frametitle{\Acrfull{gcn}}

Initial embedding of node $d$:
$$
h_d^{(0)} = \textrm{(feature vector)} \oplus \textrm{(trainable vector)}
$$

Feature vector:
\begin{itemize}
\item Clause: role (axiom, assumption, negated conjecture)
\item Symbol: introduced in preprocessing, in conjecture
\end{itemize}

Propagation rule for layer $l$:
$$
h_d^{(l+1)} =
\sum_{r \in \mathcal{R}} \sigma \Parentheses*{\sum_{s \in \mathcal{N}_d^r} \frac{1}{\sqrt{\card{\mathcal{N}_s^r}} \sqrt{\card{\mathcal{N}_d^r}}} (W_r^{(l)} h_s^{(l)} + b_r^{(l)})}
$$

\end{frame}

\begin{frame}
\frametitle{Precedence recommender overview}
\centering
\digraph[scale=0.5]{ArchitectureOverview}{
graph [splines=ortho, ranksep=0.25];
node [shape=box, fontsize=14, width=0, height=0];
Problem [label="First-order logic problem"];
Graphifier [style=rounded, label="Graph constructor"];
g [label="Graph"];
GCN [style=<rounded,bold>, label="Graph convolutional network"];
SymbolEmbedding [label="Symbol embeddings"];
SymbolCostModel [style=<rounded,bold>, label="Output layer"];
SymbolCost [label="Symbol costs"];
Problem -> Graphifier -> g -> GCN;
GCN -> SymbolEmbedding -> SymbolCostModel -> SymbolCost [penwidth=3];
subgraph cluster_prediction {
	label="Recommending";
	style=dashed;
	Sort [style=rounded, label="Sort"];
	Precedence [label=<Recommended precedence>];
	Sort -> Precedence;
}
SymbolCost -> Sort;
subgraph cluster_training {
	label="Training";
	style=dashed;
	{ rank = same;
	pi [label=<Precedence &pi;>];
	rho [label=<Precedence &rho;>];
	}
	LossFunction [style=rounded, label="Loss function"];
	Loss [label="Loss value"];
	pi -> LossFunction:nw;
	rho -> LossFunction:ne;
	LossFunction -> Loss [penwidth=3];
}
SymbolCost -> LossFunction [penwidth=3];
}
\end{frame}

\section{Training}

\begin{frame}
\frametitle{Training: Precedence cost}
Reminder: $c_i$ is the cost of the $i$-th symbol.

\begin{block}{Cost of symbol precedence $\pi$ over signature of length $n$}
\begin{equation*}
C(\pi) = \frac{2}{n(n+1)} \sum_{i=1}^n i \cdot c_{\pi(i)}
\end{equation*}
\end{block}

\begin{lemma}[Precedence cost minimization]
The precedence cost $C$ is minimized by any precedence that sorts the symbols by their costs in non-increasing order:
$$
\argmin_{\rho \in \mathrm{Perm}(n)} C(\rho) = \argsort^- (c_1, \ldots, c_n)
$$
\end{lemma}

\end{frame}

\begin{frame}
\frametitle{Training: Loss function}

\begin{exampleblock}{Training example $\Better{\PrecBetter}{\PrecWorse}{P}$}
Precedence $\PrecBetter$ is better than precedence $\PrecWorse$ for problem $P$.
\end{exampleblock}

Reminder: $C(\pi)$ is the predicted cost of precedence $\pi$.

\begin{block}{Loss on training example $\Better{\PrecBetter}{\PrecWorse}{P}$}
\begin{equation*}
\loss(P, \PrecBetter, \PrecWorse) = - \log \sigmoid (C(\PrecWorse) - C(\PrecBetter))
\end{equation*}

\centering
% https://pgf-tikz.github.io/pgf/pgfmanual.pdf : 94. Mathematical Expressions
\begin{tikzpicture}
\begin{axis}[
    domain=-12:12,
    xmin=-12,
    xmax=12,
    ymin=-1,
    ymax=11,
    samples=100,
    xlabel={$C(\PrecWorse) - C(\PrecBetter)$},
    ylabel={$\loss(P, \PrecBetter, \PrecWorse)$},
    scale only axis,
    width=0.5\textwidth,
    height=0.25\textwidth
]
%\addplot[gray] {0};
%\addplot[gray] {-x};
\addplot[] {-ln(\FuncSigmoid(x))};
\end{axis}
\end{tikzpicture}
\end{block}

\end{frame}

\section{Evaluation}

\begin{frame}
\frametitle{Evaluation}

\fontsize{10pt}{12}\selectfont

\centering
\begin{tabular}{l|ll|rl}

Symbol cost model & \multicolumn{2}{l}{Success count\footnote{Total number of validation problems: \num{7648}. Number of repetitions: 5.}} & \multicolumn{2}{l}{Improvement} \\
& Mean & Std & Absolute & Relative \\

\hline


\acrshort{gcn} (pred. and func.) &
% VML-706
\num{3951.6} &
\num[round-mode=places,round-precision=2]{1.624807680927192} &
%\SI{51.69}{\percent} &
+182.0 &
\num[round-mode=places,round-precision=3]{1.048280985} \\


\acrshort{gcn} (predicate only) &
% Success rate: mean: 0.513023013, std: 0.000292887
% Evaluation results: https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-553
% Total: validation_solver_eval/all/problems/measured&split&category: 7648
% Difference in success count from baseline: 154 ~ 0.020135983
% Estimated difference from baseline (estimate on 891 problems): 0.021099888
% Checkpoint: outputs/2021-02-06/14-55-41/tf_ckpts/epoch/weights.00079-0.61.tf VML-540 0.511785
\num{3923.6} &
% Success mean: validation_solver_eval/all/success/count/mean: 3923.6
\num{2.24} &
% Success std: validation_solver_eval/all/success/count/std 2.24
%\SI{51.30}{\percent} &
% Success rate: 0.513023013
+154.0 &
\num[round-mode=places,round-precision=3]{1.040853141} \\


\acrshort{gcn} (function only) &
% Final evaluation: VML-677
% Evaluated checkpoint: outputs/2021-02-16/12-28-14/tf_ckpts/epoch/weights.00289.tf
% Results file: sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/outputs/2021-02-17/12-01-09/solver_eval/symbol_cost/epoch_-1/logs.yaml
% Total: val/all/problems/measured&split&category: 7648
\num{3874.2} &
% Success mean: val/all/success/count/mean: 3874.2
\num[round-mode=places,round-precision=2]{1.8330302779823362} &
% Success std: val/all/success/count/mean: 1.8330302779823362
%\SI{50.66}{\percent} &
% Success rate: val/all/success/count/mean: 0.5065638075313807
+104.6 &
\num[round-mode=places,round-precision=3]{1.027748302} \\


%Simple (predicate only) &
% https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-737
%\num{3827.2} &
%\num[round-mode=places,round-precision=2]{1.9390719429665317} &
%\SI{50.04}{\percent} &
%+57.6 &
%\num[round-mode=places,round-precision=3]{1.015280136} \\
% Final vector from PAAR paper: [0,0.429306921481749,0.57069307851825,0,0,0,0,0,0,0,0,0]
% Source: https://docs.google.com/spreadsheets/d/1HSsC7piUAtWt6uwA9SYOX5vmiF0Ab3Ae4FPyGsDALIg/edit#gid=99404775


%Frequency (regular \acrshort{kbo}) &
%\texttt{vampire -lcm standard} &
%\num{3823.0} &
%\num[round-mode=places,round-precision=2]{3.40587727318528} &
%\SI[round-mode=places,round-precision=2]{49.9869247}{\percent} &
%+53.4 &
%\num[round-mode=places,round-precision=3]{1.014165959} \\
% VML-741


Frequency (baseline) &
%\texttt{vampire -lcm predicate} &
% Success rate: mean: 0.492887029, std: 0.000401412
% https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-490
% sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/outputs/2021-02-04/17-17-38
% /home/filip/projects/vampire-ml/vampire-ml/outputs/2021-02-09/12-13-43
% Row: 'val&graphified&solver_eval'
% Problems total: 7648
% Success rate: 0.492887029
\num{3769.6} &
\num{3.07} &
%\SI{49.29}{\percent} &
0.0 &
\num[round-mode=places,round-precision=3]{1.0} \\

\end{tabular}

\end{frame}

\section{Summary}
\subsection*{Summary}
\begin{frame}
\frametitle{Summary}
\begin{itemize}
\item \Acrshort{gcn} over a graph representation of a \acrshort{fol} problem predicts symbol costs
\item Sorting symbols by symbol costs yields a precedence
\item Training is performed on oriented precedence pairs ``$\Better{\PrecBetter}{\PrecWorse}{P}$'' \\
(``Precedence $\PrecBetter$ is better than precedence $\PrecWorse$ in problem $P$.'')
\item Combination of two \acrshortpl{gcn} outperforms the ``frequency'' heuristic by \SI{4.8}{\percent}
\end{itemize}
\end{frame}

\section*{Discussion}
\begin{frame}
\begin{center}
\vspace*{1cm}
{\bf Thank you for your attention!}\\
\vspace*{2cm}
{\bf\Large Filip Bártek}\\
{\tt \Email}
\vspace*{1cm}
\end{center}

Details are soon to be published:\nocite{Bartek2021}
\bibliographystyle{plain}
\bibliography{main}

\vfill
% https://tex.stackexchange.com/a/142950/202639
{\tiny {\bf Acknowledgement:} This work was supported by
the Czech Science Foundation project no.~20-06390Y (JUNIOR grant),
the project RICAIP no.~857306 under the EU-H2020 programme,
and
the Grant Agency of the Czech Technical University in Prague, grant
no.~SGS20/215/OHK3/3T/37.\par}
\end{frame}
%
\appendix

\begin{frame}
\frametitle{Notation overview}
\begin{center}
\begin{tabular}{ll}
$\pi(i)$ & index of the $i$-th symbol in precedence $\pi$ \\
$c$ & vector of symbol costs (output of the \acrshort{gcn}) \\
$c_i$ & cost of the $i$-th symbol \\
$C(\pi)$ & cost of symbol precedence $\pi$ \\
$\loss(P, \PrecBetter, \PrecWorse)$ & loss for training example $\Better{\PrecBetter}{\PrecWorse}{P}$ \\
\end{tabular}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Prediction of symbol precedence $\pi$}
\begin{algorithmic} % enter the algorithmic environment
\REQUIRE Problem $P$
\ENSURE Symbol precedence $\pi$
\STATE $c \gets \mathrm{\acrshort{gcn}}(P)$
\COMMENT {Forward pass through the \acrshort{gcn} to obtain vector of symbol costs $c$}
\STATE $\pi \gets \argsort^- (c_1, \ldots, c_n)$
\COMMENT {Sort symbols by $c$ in non-increasing order to obtain precedence $\pi$}
\RETURN $\pi$
\end{algorithmic}
\end{frame}

\begin{frame}
\frametitle{Proof sketch: Precedence cost minimization}

$C(\pi) = \frac{2}{n(n+1)} \sum_{i=1}^n i \cdot c_{\pi(i)}$

\begin{lemma}[Precedence cost minimization]
$$
\argmin_{\rho \in \mathrm{Perm}(n)} C(\rho) = \argsort^- (c_1, \ldots, c_n)
$$
\end{lemma}

\newcommand{\StairsSorted}{
\begin{tikzpicture}[baseline=5pt]
\begin{axis}[ybar interval=1, axis lines=none, height=60pt, width=60pt]
\addplot[black] coordinates {(1,5) (2,4) (3,3) (4,2) (5,1) (6,0)};
\end{axis}
\end{tikzpicture}
}

\newcommand{\StairsUnsorted}{
\begin{tikzpicture}[baseline=5pt]
\begin{axis}[ybar interval=1, axis lines=none, height=60pt, width=60pt]
\addplot[black] coordinates {(1,5) (2,3) (3,4) (4,2) (5,1) (6,0)};
\end{axis}
\end{tikzpicture}
}

\begin{example}
$$
C\Parentheses*{\StairsSorted} < C\Parentheses*{\StairsUnsorted}
$$

Proof:
\begin{align*}
C\Parentheses*{\StairsUnsorted} - C\Parentheses*{\StairsSorted}
&\propto ((2 \cdot 3 + 3 \cdot 4) - (2 \cdot 4 + 3 \cdot 3)) \\
&= 18 - 17 = 1 > 0
\end{align*}
\end{example}

\end{frame}

\begin{frame}
\frametitle{Concise representation of training examples}
\begin{block}{Cost of symbol precedence $\pi$ over signature of length $n$}
\begin{equation*}
C(\pi)
= \frac{2}{n(n+1)} \sum_{i=1}^n i \cdot c_{\pi(i)}
= \frac{2}{n(n+1)} \sum_{i=1}^n c_i \cdot \inv{\pi}(i)
\end{equation*}
\end{block}

\begin{block}{Loss of training example $\Better{\PrecBetter}{\PrecWorse}{P}$}
\begin{align*}
\loss(P, \PrecBetter, \PrecWorse)
&= - \log \sigmoid (C(\PrecWorse) - C(\PrecBetter)) \\
&= - \log \sigmoid \frac{2}{n(n+1)} \sum_{i=1}^n i (c_{\PrecWorse(i)} - c_{\PrecBetter(i)}) \\
&= - \log \sigmoid \frac{2}{n(n+1)} \sum_{i=1}^n c_i (\inv{\PrecWorse}(i) - \inv{\PrecBetter}(i))
\end{align*}
\end{block}

Concise representation of $\Better{\PrecBetter}{\PrecWorse}{P}$:
$\inv{\PrecWorse} - \inv{\PrecBetter}$
\end{frame}

\end{document}
