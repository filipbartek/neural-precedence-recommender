@book{DBLP:books/daglib/0040158,
  author    = {Ian J. Goodfellow and
               Yoshua Bengio and
               Aaron C. Courville},
  title     = {Deep Learning},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {2016},
  url       = {http://www.deeplearningbook.org/},
  isbn      = {978-0-262-03561-3},
  timestamp = {Sat, 25 Mar 2017 20:16:59 +0100},
  biburl    = {https://dblp.org/rec/books/daglib/0040158.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{DBLP:books/el/RV01/NonnengartW01,
  author    = {Andreas Nonnengart and
               Christoph Weidenbach},
  title     = {Computing Small Clause Normal Forms},
  booktitle = {Handbook of Automated Reasoning (in 2 volumes)},
  pages     = {335--367},
  year      = {2001},
  crossref  = {DBLP:books/el/RobinsonV01},
  url       = {https://doi.org/10.1016/b978-044450813-3/50008-4},
  doi       = {10.1016/b978-044450813-3/50008-4},
  timestamp = {Thu, 25 Jul 2019 12:26:00 +0200},
  biburl    = {https://dblp.org/rec/books/el/RV01/NonnengartW01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{DBLP:books/el/RobinsonV01,
  editor    = {John Alan Robinson and
               Andrei Voronkov},
  title     = {Handbook of Automated Reasoning (in 2 volumes)},
  publisher = {Elsevier and {MIT} Press},
  year      = {2001},
  url       = {https://www.sciencedirect.com/book/9780444508133/handbook-of-automated-reasoning},
  isbn      = {0-444-50813-9},
  timestamp = {Thu, 18 Feb 2021 15:31:26 +0100},
  biburl    = {https://dblp.org/rec/books/el/RobinsonV01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cade/WeidenbachDFKSW09,
  author    = {Christoph Weidenbach and
               Dilyana Dimova and
               Arnaud Fietzke and
               Rohit Kumar and
               Martin Suda and
               Patrick Wischnewski},
  title     = {{SPASS} Version 3.5},
  booktitle = {Automated Deduction - CADE-22, 22nd International Conference on Automated
               Deduction, Montreal, Canada, August 2-7, 2009. Proceedings},
  pages     = {140--145},
  year      = {2009},
  crossref  = {DBLP:conf/cade/2009},
  url       = {https://doi.org/10.1007/978-3-642-02959-2\_10},
  doi       = {10.1007/978-3-642-02959-2\_10},
  timestamp = {Tue, 14 May 2019 10:00:39 +0200},
  biburl    = {https://dblp.org/rec/conf/cade/WeidenbachDFKSW09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/cade/2009,
  editor    = {Renate A. Schmidt},
  title     = {Automated Deduction - CADE-22, 22nd International Conference on Automated
               Deduction, Montreal, Canada, August 2-7, 2009. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {5663},
  publisher = {Springer},
  year      = {2009},
  url       = {https://doi.org/10.1007/978-3-642-02959-2},
  doi       = {10.1007/978-3-642-02959-2},
  isbn      = {978-3-642-02958-5},
  timestamp = {Thu, 18 Feb 2021 15:25:24 +0100},
  biburl    = {https://dblp.org/rec/conf/cade/2009.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% GCN
@misc{kipf2017semisupervised,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2017},
      eprint={1609.02907},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% R-GCN
@article{Schlichtkrull2017,
archivePrefix = {arXiv},
arxivId = {1703.06103},
author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and van den Berg, Rianne and Titov, Ivan and Welling, Max},
eprint = {1703.06103},
month = {mar},
title = {{Modeling Relational Data with Graph Convolutional Networks}},
url = {https://arxiv.org/abs/1703.06103},
year = {2017}
}

% E
@InProceedings{10.1007/978-3-030-29436-6_29,
author="Schulz, Stephan
and Cruanes, Simon
and Vukmirovi{\'{c}}, Petar",
editor="Fontaine, Pascal",
title="Faster, Higher, Stronger: E 2.3",
booktitle="Automated Deduction -- CADE 27",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="495--507",
abstract="E 2.3 is a theorem prover for many-sorted first-order logic with equality. We describe the basic logical and software architecture of the system, as well as core features of the implementation. We particularly discuss recently added features and extensions, including the extension to many-sorted logic, optional limited support for higher-order logic, and the integration of SAT techniques via PicoSAT. Minor additions include improved support for TPTP standard features, always-on internal proof objects, and lazy orphan removal. The paper also gives an overview of the performance of the system, and describes ongoing and future work.",
isbn="978-3-030-29436-6"
}

% Vampire
@InProceedings{10.1007/978-3-642-39799-8_1,
author="Kov{\'a}cs, Laura
and Voronkov, Andrei",
editor="Sharygina, Natasha
and Veith, Helmut",
title="First-Order Theorem Proving and Vampire",
booktitle="Computer Aided Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--35",
abstract="In this paper we give a short introduction in first-order theorem proving and the use of the theorem prover Vampire. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in Vampire. Further, we also cover more recent topics and features of Vampire designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.",
isbn="978-3-642-39799-8"
}

% LPO
@Unpublished{Kamin1980,
  author    = {Samuel N. Kamin and Jacques L{\'e}vy},
  title     = {Two generalizations of the recursive path ordering},
  year      = {1980},
  owner     = {filip},
  timestamp = {2019-12-02},
  note      = {Unpublished letter to Nachum Dershowitz},
  url       = {http://www.cs.tau.ac.il/~nachumd/term/kamin-levy80spo.pdf},
}

% KBO
@Inbook{Knuth1983,
author="Knuth, D. E.
and Bendix, P. B.",
editor="Siekmann, J{\"o}rg H.
and Wrightson, Graham",
title="Simple Word Problems in Universal Algebras",
bookTitle="Automation of Reasoning: 2: Classical Papers on Computational Logic 1967--1970",
year="1983",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="342--376",
abstract="An algorithm is described which is capable of solving certain word problems: i.e. of deciding whether or not two words composed of variables and operators can be proved equal as a consequence of a given set of identities satisfied by the operators. Although the general word problem is well known to be unsolvable, this algorithm provides results in many interesting cases. For example in elementary group theory if we are given the binary operator {\textperiodcentered}, the unary operator −, and the nullary operator e, the algorithm is capable of deducing from the three identities a {\textperiodcentered} (b {\textperiodcentered} c) = (a {\textperiodcentered} b) {\textperiodcentered} c, a {\textperiodcentered} a− = e, a {\textperiodcentered} e = a, the laws a− {\textperiodcentered} a = e, e {\textperiodcentered} a = a, a− −= a, etc.; and furthermore it can show that a {\textperiodcentered} b = b {\textperiodcentered} a−is not a consequence of the given axioms.",
isbn="978-3-642-81955-1",
doi="10.1007/978-3-642-81955-1\_23",
url="https://doi.org/10.1007/978-3-642-81955-1\_23"
}

% TKBO
@inproceedings{Ludwig2007,
abstract = {The Knuth-Bendix ordering is usually preferred over the lexicographic path ordering in successful implementations of resolution and superposition, but it is incompatible with certain requirements of hierarchic superposition calculi. Moreover, it does not allow non-linear definition equations to be oriented in a natural way. We present an extension of the Knuth-Bendix ordering that makes it possible to overcome these restrictions. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Ludwig, Michel and Waldmann, Uwe},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-75560-9\_26},
isbn = {9783540755586},
issn = {16113349},
month = {oct},
pages = {348--362},
publisher = {Springer Verlag},
title = {{An extension of the Knuth-Bendix ordering with LPO-like properties}},
url = {https://link.springer.com/chapter/10.1007/978-3-540-75560-9\_26},
volume = {4790 LNAI},
year = {2007}
}

% TKBO in Vampire
@inproceedings{Kovacs2011,
abstract = {In this paper we discuss the recently introduced transfinite Knuth-Bendix orders. We prove that any such order with finite subterm coefficients and for a finite signature is equivalent to an order using ordinals below $\omega$$\omega$, that is, finite sequences of natural numbers of a fixed length. We show that this result does not hold when subterm coefficients are infinite. However, we prove that in this general case ordinals below $\omega$$\omega$$\omega$ suffice. We also prove that both upper bounds are tight. We briefly discuss the significance of our results for the implementation of first-order theorem provers and describe relationships between the transfinite Knuth-Bendix orders and existing implementations of extensions of the Knuth-Bendix orders. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Kov{\'{a}}cs, Laura and Moser, Georg and Voronkov, Andrei},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-22438-6\_29},
isbn = {9783642224379},
issn = {03029743},
pages = {384--399},
publisher = {Springer, Berlin, Heidelberg},
title = {{On transfinite Knuth-Bendix orders}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-22438-6\_29},
volume = {6803 LNAI},
year = {2011}
}

% invfreq
@MISC{E-manual,
  author =   {Stephan Schulz},
  title =   {{E 2.4 User Manual}},
  url = {http://wwwlehre.dhbw-stuttgart.de/~sschulz/WORK/E\_DOWNLOAD/V\_2.4/eprover.pdf},
  urldate = {May 2020},
  year =   2019,
}

% UCB1
@article{Auer2002,
abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.},
author = {Auer, Peter and Cesa-Bianchi, Nicol{\`{o}} and Fischer, Paul},
doi = {10.1023/A:1013689704352},
issn = {08856125},
journal = {Machine Learning},
keywords = {Adaptive allocation rules,Bandit problems,Finite horizon regret},
month = {may},
number = {2-3},
pages = {235--256},
publisher = {Springer},
title = {{Finite-time analysis of the multiarmed bandit problem}},
url = {https://link.springer.com/article/10.1023/A:1013689704352},
volume = {47},
year = {2002}
}

% Adam
@article{Kingma2014,
   abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
   author = {Diederik P. Kingma and Jimmy Ba},
   month = {12},
   title = {Adam: A Method for Stochastic Optimization},
   url = {http://arxiv.org/abs/1412.6980},
   year = {2014},
}

@book{Harrison2009,
address = {Cambridge},
author = {Harrison, John},
doi = {10.1017/CBO9780511576430},
isbn = {9780511576430},
publisher = {Cambridge University Press},
title = {{Handbook of Practical Logic and Automated Reasoning}},
year = {2009}
}

% Tseitin transformation
@incollection{Tseitin1983,
address = {Berlin, Heidelberg},
author = {Tseitin, G. S.},
booktitle = {Automation of Reasoning},
doi = {10.1007/978-3-642-81955-1\_28},
pages = {466--483},
publisher = {Springer Berlin Heidelberg},
title = {{On the Complexity of Derivation in Propositional Calculus}},
url = {http://link.springer.com/10.1007/978-3-642-81955-1\_28},
year = {1983}
}

% TPTP
@article{Sutcliffe2017,
author = {Sutcliffe, Geoff},
doi = {10.1007/s10817-017-9407-7},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
month = {dec},
number = {4},
title = {{The TPTP Problem Library and Associated Infrastructure}},
volume = {59},
year = {2017}
}

% Heterogeneous information network (HIN)
@article{Shi2015,
archivePrefix = {arXiv},
arxivId = {1511.04854},
author = {Shi, Chuan and Li, Yitong and Zhang, Jiawei and Sun, Yizhou and Yu, Philip S.},
eprint = {1511.04854},
month = {nov},
title = {{A Survey of Heterogeneous Information Network Analysis}},
url = {https://arxiv.org/abs/1511.04854},
year = {2015}
}

% Argument-order-preserving graphification by the use of auxiliary argument nodes
% Section 5, paragraph Representation
@inproceedings{Rawson2020,
author = {Rawson, Michael and Reger, Giles},
booktitle = {Joint Proceedings of the 7th Workshop on Practical Aspects of Automated Reasoning (PAAR) and the 5th Satisfiability Checking and Symbolic Computation Workshop (SC-Square) Workshop},
editor = {Fontaine, Pascal and Korovin, Konstantin and Kotsireas, Ilias S. and R{\"{u}}mmer, Philipp and Tourret, Sophie},
pages = {109--119},
title = {{Directed Graph Networks for Logical Reasoning (Extended Abstract)}},
url = {http://ceur-ws.org/Vol-2752/paper8.pdf},
year = {2020}
}

% Graph neural networks (GNNs)
@article{Zhou2018,
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
month = {dec},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
url = {http://arxiv.org/abs/1812.08434},
year = {2018}
}
