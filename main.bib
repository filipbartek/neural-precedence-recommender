@book{Sutton1998,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018 }
}


@inproceedings{DBLP:conf/cade/Bartek020,
  author    = {Filip B{\'{a}}rtek and
               Martin Suda},
  title     = {Learning Precedences from Simple Symbol Features},
  booktitle = {Joint Proceedings of the 7th Workshop on Practical Aspects of Automated
               Reasoning {(PAAR)} and the 5th Satisfiability Checking and Symbolic
               Computation Workshop (SC-Square) Workshop, 2020 co-located with the
               10th International Joint Conference on Automated Reasoning {(IJCAR}
               2020), Paris, France, June-July, 2020 (Virtual)},
  pages     = {21--33},
  year      = {2020},
  crossref  = {DBLP:conf/cade/2020paar},
  url       = {http://ceur-ws.org/Vol-2752/paper2.pdf},
  timestamp = {Tue, 09 Feb 2021 17:28:14 +0100},
  biburl    = {https://dblp.org/rec/conf/cade/Bartek020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/cade/2020paar,
  editor    = {Pascal Fontaine and
               Konstantin Korovin and
               Ilias S. Kotsireas and
               Philipp R{\"{u}}mmer and
               Sophie Tourret},
  title     = {Joint Proceedings of the 7th Workshop on Practical Aspects of Automated
               Reasoning {(PAAR)} and the 5th Satisfiability Checking and Symbolic
               Computation Workshop (SC-Square) Workshop, 2020 co-located with the
               10th International Joint Conference on Automated Reasoning {(IJCAR}
               2020), Paris, France, June-July, 2020 (Virtual)},
  series    = {{CEUR} Workshop Proceedings},
  volume    = {2752},
  publisher = {CEUR-WS.org},
  year      = {2020},
  url       = {http://ceur-ws.org/Vol-2752},
  urn       = {urn:nbn:de:0074-2752-0},
  timestamp = {Tue, 23 Feb 2021 01:16:56 +0100},
  biburl    = {https://dblp.org/rec/conf/cade/2020paar.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{RegerSuda2017,
  author       = {Giles Reger and Martin Suda},
  title        = {Measuring progress to predict success: {Can} a good proof strategy be evolved?},
  year         = {2017},
  booktitle    = {AITP 2017},
  pages        = {20--21},
  url          = {http://aitp-conference.org/2017/aitp17-proceedings.pdf},
}

@inproceedings{DBLP:conf/cade/HustadtKS05,
  author    = {Ullrich Hustadt and
               Boris Konev and
               Renate A. Schmidt},
  title     = {Deciding Monodic Fragments by Temporal Resolution},
  booktitle = {Automated Deduction - CADE-20, 20th International Conference on Automated
               Deduction, Tallinn, Estonia, July 22-27, 2005, Proceedings},
  pages     = {204--218},
  year      = {2005},
  crossref  = {DBLP:conf/cade/2005},
  url       = {https://doi.org/10.1007/11532231\_15},
  doi       = {10.1007/11532231\_15},
  timestamp = {Tue, 14 May 2019 10:00:39 +0200},
  biburl    = {https://dblp.org/rec/conf/cade/HustadtKS05.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/cade/2005,
  editor    = {Robert Nieuwenhuis},
  title     = {Automated Deduction - CADE-20, 20th International Conference on Automated
               Deduction, Tallinn, Estonia, July 22-27, 2005, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {3632},
  publisher = {Springer},
  year      = {2005},
  url       = {https://doi.org/10.1007/11532231},
  doi       = {10.1007/11532231},
  isbn      = {3-540-28005-7},
  timestamp = {Mon, 22 Feb 2021 21:51:16 +0100},
  biburl    = {https://dblp.org/rec/conf/cade/2005.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/lics/GanzingerN99,
  author    = {Harald Ganzinger and
               Hans de Nivelle},
  title     = {A Superposition Decision Procedure for the Guarded Fragment with Equality},
  booktitle = {14th Annual {IEEE} Symposium on Logic in Computer Science, Trento,
               Italy, July 2-5, 1999},
  pages     = {295--303},
  year      = {1999},
  crossref  = {DBLP:conf/lics/1999},
  url       = {https://doi.org/10.1109/LICS.1999.782624},
  doi       = {10.1109/LICS.1999.782624},
  timestamp = {Wed, 16 Oct 2019 14:14:54 +0200},
  biburl    = {https://dblp.org/rec/conf/lics/GanzingerN99.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/lics/1999,
  title     = {14th Annual {IEEE} Symposium on Logic in Computer Science, Trento,
               Italy, July 2-5, 1999},
  publisher = {{IEEE} Computer Society},
  year      = {1999},
  url       = {https://ieeexplore.ieee.org/xpl/conhome/6352/proceeding},
  isbn      = {0-7695-0158-3},
  timestamp = {Mon, 22 Feb 2021 21:50:27 +0100},
  biburl    = {https://dblp.org/rec/conf/lics/1999.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cade/KovacsMV11,
  author    = {Laura Kov{\'{a}}cs and
               Georg Moser and
               Andrei Voronkov},
  editor    = {Nikolaj Bj{\o}rner and
               Viorica Sofronie{-}Stokkermans},
  title     = {On Transfinite {K}nuth-{B}endix Orders},
  booktitle = {Automated Deduction -- {CADE-23}},
  series    = {Lecture Notes in Computer Science},
  number    = {6803},
  pages     = {384--399},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  year      = {2011},
  doi       = {10.1007/978-3-642-22438-6\_29},
  isbn      = {978-3-642-22438-6},
  timestamp = {Tue, 14 May 2019 10:00:39 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cade/KovacsMV11},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{Reger2016,
  author    = {Giles Reger and Martin Suda and Andrei Voronkov},
  title     = {New Techniques in Clausal Form Generation},
  booktitle = {GCAI 2016. 2nd Global Conference on Artificial Intelligence},
  year      = {2016},
  editor    = {Christoph Benzm\"uller and Geoff Sutcliffe and Raul Rojas},
  volume    = {41},
  series    = {EPiC Series in Computing},
  pages     = {11--23},
  publisher = {EasyChair},
  bibsource = {EasyChair, https://easychair.org},
  doi       = {10.29007/dzfz},
  issn      = {2398-7340},
  owner     = {filip},
  timestamp = {2019-12-03},
  url       = {https://easychair.org/publications/paper/XncX},
}

@article{Bachmair89completionwithout,
    author = {Leo Bachmair and Nachum Dershowitz and David A. Plaisted},
    title = {Completion Without Failure},
    journal = {Coll. on the Resolution of Equations in Algebraic Structures, Austin, 1987},
    publisher={Academic Press},
    year = {1989}
}

@incollection{DBLP:books/el/RV01/BachmairG01,
  author    = {Leo Bachmair and
               Harald Ganzinger and
               David A. McAllester and
               Christopher Lynch},
  title     = {Resolution Theorem Proving},
  booktitle = {Handbook of Automated Reasoning (in 2 volumes)},
  pages     = {19--99},
  year      = {2001},
  crossref  = {DBLP:books/el/RobinsonV01},
  url       = {https://doi.org/10.1016/b978-044450813-3/50004-7},
  doi       = {10.1016/b978-044450813-3/50004-7},
  timestamp = {Thu, 25 Jul 2019 12:26:00 +0200},
  biburl    = {https://dblp.org/rec/books/el/RV01/BachmairG01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{Robinson1983,
author="Robinson, G.
and Wos, Larry",
editor="Siekmann, J{\"o}rg H.
and Wrightson, Graham",
title="Paramodulation and Theorem-Proving in First-Order Theories with Equality",
bookTitle="Automation of Reasoning: 2: Classical Papers on Computational Logic 1967--1970",
year="1983",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="298--313",
abstract="A term is an individual constant or variable or an n-adic function letter followed by n terms. An atomic formula is an n-adic predicate letter followed by n terms. A literal is an atomic formula or the negation thereof. A clause is a set of literals and is thought of as representing the universally-quantified disjunction of its members. It will sometimes be notationally convenient1 to distinguish between the empty clause □, viewed as a clause, and `other' empty sets such as the empty set of clauses, even though all these empty sets are the same set-theoretic object {\o}. A ground clause (term, literal) is one with no variables. A clause C' (literal, term) is an instance of another clause C (literal, term) if there is a uniform replacement of the variables in C by terms that transform C into C'.",
isbn="978-3-642-81955-1",
doi="10.1007/978-3-642-81955-1\_19",
}

@incollection{DBLP:books/el/RV01/NieuwenhuisR01,
  author    = {Robert Nieuwenhuis and
               Albert Rubio},
  title     = {Paramodulation-Based Theorem Proving},
  booktitle = {Handbook of Automated Reasoning (in 2 volumes)},
  pages     = {371--443},
  year      = {2001},
  crossref  = {DBLP:books/el/RobinsonV01},
  url       = {https://doi.org/10.1016/b978-044450813-3/50009-6},
  doi       = {10.1016/b978-044450813-3/50009-6},
  timestamp = {Thu, 25 Jul 2019 12:26:00 +0200},
  biburl    = {https://dblp.org/rec/books/el/RV01/NieuwenhuisR01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cav/KovacsV13,
  author    = {Laura Kov{\'{a}}cs and
               Andrei Voronkov},
  title     = {First-Order Theorem Proving and {Vampire}},
  booktitle = {Computer Aided Verification - 25th International Conference, {CAV}
               2013, Saint Petersburg, Russia, July 13-19, 2013. Proceedings},
  pages     = {1--35},
  year      = {2013},
  crossref  = {DBLP:conf/cav/2013},
  url       = {https://doi.org/10.1007/978-3-642-39799-8\_1},
  doi       = {10.1007/978-3-642-39799-8\_1},
  timestamp = {Tue, 14 May 2019 10:00:43 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cav/KovacsV13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/cav/2013,
  editor    = {Natasha Sharygina and
               Helmut Veith},
  title     = {Computer Aided Verification - 25th International Conference, {CAV}
               2013, Saint Petersburg, Russia, July 13-19, 2013. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {8044},
  publisher = {Springer},
  year      = {2013},
  url       = {https://doi.org/10.1007/978-3-642-39799-8},
  doi       = {10.1007/978-3-642-39799-8},
  isbn      = {978-3-642-39798-1},
  timestamp = {Tue, 14 May 2019 10:00:43 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/cav/2013},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/logcom/BachmairG94,
  author    = {Leo Bachmair and
               Harald Ganzinger},
  title     = {Rewrite-Based Equational Theorem Proving with Selection and Simplification},
  journal   = {J. Log. Comput.},
  volume    = {4},
  number    = {3},
  pages     = {217--247},
  year      = {1994},
  url       = {https://doi.org/10.1093/logcom/4.3.217},
  doi       = {10.1093/logcom/4.3.217},
  timestamp = {Wed, 17 May 2017 14:25:56 +0200},
  biburl    = {https://dblp.org/rec/journals/logcom/BachmairG94.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{DBLP:books/daglib/0040158,
  author    = {Ian J. Goodfellow and
               Yoshua Bengio and
               Aaron C. Courville},
  title     = {Deep Learning},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {2016},
  url       = {http://www.deeplearningbook.org/},
  isbn      = {978-0-262-03561-3},
  timestamp = {Sat, 25 Mar 2017 20:16:59 +0100},
  biburl    = {https://dblp.org/rec/books/daglib/0040158.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{DBLP:books/el/RV01/NonnengartW01,
  author    = {Andreas Nonnengart and
               Christoph Weidenbach},
  title     = {Computing Small Clause Normal Forms},
  booktitle = {Handbook of Automated Reasoning (in 2 volumes)},
  pages     = {335--367},
  year      = {2001},
  crossref  = {DBLP:books/el/RobinsonV01},
  url       = {https://doi.org/10.1016/b978-044450813-3/50008-4},
  doi       = {10.1016/b978-044450813-3/50008-4},
  timestamp = {Thu, 25 Jul 2019 12:26:00 +0200},
  biburl    = {https://dblp.org/rec/books/el/RV01/NonnengartW01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{DBLP:books/el/RobinsonV01,
  editor    = {John Alan Robinson and
               Andrei Voronkov},
  title     = {Handbook of Automated Reasoning (in 2 volumes)},
  publisher = {Elsevier and {MIT} Press},
  year      = {2001},
  url       = {https://www.sciencedirect.com/book/9780444508133/handbook-of-automated-reasoning},
  isbn      = {0-444-50813-9},
  timestamp = {Thu, 18 Feb 2021 15:31:26 +0100},
  biburl    = {https://dblp.org/rec/books/el/RobinsonV01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/cade/WeidenbachDFKSW09,
  author    = {Christoph Weidenbach and
               Dilyana Dimova and
               Arnaud Fietzke and
               Rohit Kumar and
               Martin Suda and
               Patrick Wischnewski},
  title     = {{SPASS} Version 3.5},
  booktitle = {Automated Deduction - CADE-22, 22nd International Conference on Automated
               Deduction, Montreal, Canada, August 2-7, 2009. Proceedings},
  pages     = {140--145},
  year      = {2009},
  crossref  = {DBLP:conf/cade/2009},
  url       = {https://doi.org/10.1007/978-3-642-02959-2\_10},
  doi       = {10.1007/978-3-642-02959-2\_10},
  timestamp = {Tue, 14 May 2019 10:00:39 +0200},
  biburl    = {https://dblp.org/rec/conf/cade/WeidenbachDFKSW09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/cade/2009,
  editor    = {Renate A. Schmidt},
  title     = {Automated Deduction - CADE-22, 22nd International Conference on Automated
               Deduction, Montreal, Canada, August 2-7, 2009. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {5663},
  publisher = {Springer},
  year      = {2009},
  url       = {https://doi.org/10.1007/978-3-642-02959-2},
  doi       = {10.1007/978-3-642-02959-2},
  isbn      = {978-3-642-02958-5},
  timestamp = {Thu, 18 Feb 2021 15:25:24 +0100},
  biburl    = {https://dblp.org/rec/conf/cade/2009.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% GCN
@misc{kipf2017semisupervised,
      title={Semi-Supervised Classification with Graph Convolutional Networks}, 
      author={Thomas N. Kipf and Max Welling},
      year={2017},
      eprint={1609.02907},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% R-GCN
@article{Schlichtkrull2017,
archivePrefix = {arXiv},
arxivId = {1703.06103},
author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and van den Berg, Rianne and Titov, Ivan and Welling, Max},
eprint = {1703.06103},
month = {mar},
title = {{Modeling Relational Data with Graph Convolutional Networks}},
url = {https://arxiv.org/abs/1703.06103},
year = {2017}
}

@article{Chvalovsky2019,
archivePrefix = {arXiv},
arxivId = {1903.03182},
author = {Chvalovsk{\'{y}}, Karel and Jakubův, Jan and Suda, Martin and Urban, Josef},
doi = {10.1007/978-3-030-29436-6\_12},
eprint = {1903.03182},
month = {mar},
title = {{ENIGMA-NG: Efficient Neural and Gradient-Boosted Inference Guidance for E}},
url = {https://arxiv.org/abs/1903.03182},
year = {2019}
}

% Layer Normalization
@article{Ba2016,
abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
archivePrefix = {arXiv},
arxivId = {1607.06450},
author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
eprint = {1607.06450},
month = {jul},
title = {{Layer Normalization}},
url = {http://arxiv.org/abs/1607.06450},
year = {2016}
}

% E
@inproceedings{Schulz2019,
abstract = {E 2.3 is a theorem prover for many-sorted first-order logic with equality. We describe the basic logical and software architecture of the system, as well as core features of the implementation. We particularly discuss recently added features and extensions, including the extension to many-sorted logic, optional limited support for higher-order logic, and the integration of SAT techniques via PicoSAT. Minor additions include improved support for TPTP standard features, always-on internal proof objects, and lazy orphan removal. The paper also gives an overview of the performance of the system, and describes ongoing and future work.},
author = {Schulz, Stephan and Cruanes, Simon and Vukmirovi{\'{c}}, Petar},
booktitle = {Automated Deduction -- CADE 27},
doi = {10.1007/978-3-030-29436-6\_29},
editor = {Fontaine, Pascal},
isbn = {978-3-030-29436-6},
issn = {1611-3349},
month = {aug},
pages = {495--507},
publisher = {Springer},
title = {Faster, Higher, Stronger: {E} 2.3},
url = {http://link.springer.com/10.1007/978-3-030-29436-6\_29},
volume = {11716},
series = {LNAI},
year = {2019}
}

% Vampire
@InProceedings{10.1007/978-3-642-39799-8_1,
author="Kov{\'a}cs, Laura
and Voronkov, Andrei",
editor="Sharygina, Natasha
and Veith, Helmut",
title="First-Order Theorem Proving and Vampire",
booktitle="Computer Aided Verification",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--35",
abstract="In this paper we give a short introduction in first-order theorem proving and the use of the theorem prover Vampire. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in Vampire. Further, we also cover more recent topics and features of Vampire designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.",
isbn="978-3-642-39799-8"
}

% LPO
@Unpublished{Kamin1980,
  author    = {Samuel N. Kamin and Jacques L{\'e}vy},
  title     = {Two generalizations of the recursive path ordering},
  year      = {1980},
  owner     = {filip},
  timestamp = {2019-12-02},
  note      = {Unpublished letter to Nachum Dershowitz},
  url       = {http://www.cs.tau.ac.il/~nachumd/term/kamin-levy80spo.pdf},
}

% KBO
@Inbook{Knuth1983,
author="Knuth, D. E.
and Bendix, P. B.",
editor="Siekmann, J{\"o}rg H.
and Wrightson, Graham",
title="Simple Word Problems in Universal Algebras",
bookTitle="Automation of Reasoning: 2: Classical Papers on Computational Logic 1967--1970",
year="1983",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="342--376",
abstract="An algorithm is described which is capable of solving certain word problems: i.e. of deciding whether or not two words composed of variables and operators can be proved equal as a consequence of a given set of identities satisfied by the operators. Although the general word problem is well known to be unsolvable, this algorithm provides results in many interesting cases. For example in elementary group theory if we are given the binary operator {\textperiodcentered}, the unary operator −, and the nullary operator e, the algorithm is capable of deducing from the three identities a {\textperiodcentered} (b {\textperiodcentered} c) = (a {\textperiodcentered} b) {\textperiodcentered} c, a {\textperiodcentered} a− = e, a {\textperiodcentered} e = a, the laws a− {\textperiodcentered} a = e, e {\textperiodcentered} a = a, a− −= a, etc.; and furthermore it can show that a {\textperiodcentered} b = b {\textperiodcentered} a−is not a consequence of the given axioms.",
isbn="978-3-642-81955-1",
doi="10.1007/978-3-642-81955-1\_23",
url="https://doi.org/10.1007/978-3-642-81955-1\_23"
}

% TKBO
@inproceedings{Ludwig2007,
abstract = {The Knuth-Bendix ordering is usually preferred over the lexicographic path ordering in successful implementations of resolution and superposition, but it is incompatible with certain requirements of hierarchic superposition calculi. Moreover, it does not allow non-linear definition equations to be oriented in a natural way. We present an extension of the Knuth-Bendix ordering that makes it possible to overcome these restrictions. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Ludwig, Michel and Waldmann, Uwe},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-75560-9\_26},
isbn = {9783540755586},
issn = {16113349},
month = {oct},
pages = {348--362},
publisher = {Springer Verlag},
title = {{An extension of the Knuth-Bendix ordering with LPO-like properties}},
url = {https://link.springer.com/chapter/10.1007/978-3-540-75560-9\_26},
volume = {4790 LNAI},
year = {2007}
}

% TKBO in Vampire
@inproceedings{Kovacs2011,
abstract = {In this paper we discuss the recently introduced transfinite Knuth-Bendix orders. We prove that any such order with finite subterm coefficients and for a finite signature is equivalent to an order using ordinals below $\omega$$\omega$, that is, finite sequences of natural numbers of a fixed length. We show that this result does not hold when subterm coefficients are infinite. However, we prove that in this general case ordinals below $\omega$$\omega$$\omega$ suffice. We also prove that both upper bounds are tight. We briefly discuss the significance of our results for the implementation of first-order theorem provers and describe relationships between the transfinite Knuth-Bendix orders and existing implementations of extensions of the Knuth-Bendix orders. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Kov{\'{a}}cs, Laura and Moser, Georg and Voronkov, Andrei},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-22438-6\_29},
isbn = {9783642224379},
issn = {03029743},
pages = {384--399},
publisher = {Springer, Berlin, Heidelberg},
title = {{On transfinite Knuth-Bendix orders}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-22438-6\_29},
volume = {6803 LNAI},
year = {2011}
}

% invfreq
@MISC{E-manual,
  author =   {Stephan Schulz},
  title =   {{E 2.4 User Manual}},
  url = {http://wwwlehre.dhbw-stuttgart.de/~sschulz/WORK/E\_DOWNLOAD/V\_2.4/eprover.pdf},
  urldate = {May 2020},
  year =   2019,
}

% UCB1
@article{Auer2002,
abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.},
author = {Auer, Peter and Cesa-Bianchi, Nicol{\`{o}} and Fischer, Paul},
doi = {10.1023/A:1013689704352},
issn = {08856125},
journal = {Machine Learning},
keywords = {Adaptive allocation rules,Bandit problems,Finite horizon regret},
month = {may},
number = {2-3},
pages = {235--256},
publisher = {Springer},
title = {{Finite-time analysis of the multiarmed bandit problem}},
url = {https://link.springer.com/article/10.1023/A:1013689704352},
volume = {47},
year = {2002}
}

% Adam
@article{Kingma2014,
   abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
   author = {Diederik P. Kingma and Jimmy Ba},
   month = {12},
   title = {Adam: A Method for Stochastic Optimization},
   url = {http://arxiv.org/abs/1412.6980},
   year = {2014},
}

@book{Harrison2009,
address = {Cambridge},
author = {Harrison, John},
doi = {10.1017/CBO9780511576430},
isbn = {9780511576430},
publisher = {Cambridge University Press},
title = {{Handbook of Practical Logic and Automated Reasoning}},
year = {2009}
}

@book{Mohri2018,
author = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
edition = {2},
isbn = {9781787284395},
publisher = {MIT Press},
title = {{Foundations of Machine Learning}},
url = {https://cs.nyu.edu/$\sim$mohri/mlbook/},
year = {2018}
}

% RankNet
@inproceedings{Burges2005,
abstract = {We investigate using gradient descent methods for learning ranking functions; we propose a simple probabilistic cost function, and we introduce RankNet, an implementation of these ideas using a neural network to model the underlying ranking function. We present test results on toy data and on data from a commercial internet search engine.},
address = {New York, New York, USA},
author = {Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
booktitle = {ICML 2005 - Proceedings of the 22nd International Conference on Machine Learning},
doi = {10.1145/1102351.1102363},
isbn = {1595931805},
pages = {89--96},
publisher = {ACM Press},
title = {{Learning to Rank using Gradient Descent}},
url = {http://portal.acm.org/citation.cfm?doid=1102351.1102363},
year = {2005}
}

% Tseitin transformation
@incollection{Tseitin1983,
address = {Berlin, Heidelberg},
author = {Tseitin, G. S.},
booktitle = {Automation of Reasoning},
doi = {10.1007/978-3-642-81955-1\_28},
pages = {466--483},
publisher = {Springer Berlin Heidelberg},
title = {{On the Complexity of Derivation in Propositional Calculus}},
url = {http://link.springer.com/10.1007/978-3-642-81955-1\_28},
year = {1983}
}

% TPTP
@article{Sutcliffe2017,
author = {Sutcliffe, Geoff},
doi = {10.1007/s10817-017-9407-7},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
month = {dec},
number = {4},
title = {{The TPTP Problem Library and Associated Infrastructure}},
volume = {59},
year = {2017}
}

% TPTP Syntax
@misc{TptpSyntax,
title = {{TPTP Syntax}},
url = {http://www.tptp.org/TPTP/SyntaxBNF.html},
urldate = {2021-02-22}
}

% Heterogeneous information network (HIN)
@article{Shi2015,
archivePrefix = {arXiv},
arxivId = {1511.04854},
author = {Shi, Chuan and Li, Yitong and Zhang, Jiawei and Sun, Yizhou and Yu, Philip S.},
eprint = {1511.04854},
month = {nov},
title = {{A Survey of Heterogeneous Information Network Analysis}},
url = {https://arxiv.org/abs/1511.04854},
year = {2015}
}

% Argument-order-preserving graphification by the use of auxiliary argument nodes
% Section 5, paragraph Representation
@inproceedings{Rawson2020,
author = {Rawson, Michael and Reger, Giles},
booktitle = {Joint Proceedings of the 7th Workshop on Practical Aspects of Automated Reasoning (PAAR) and the 5th Satisfiability Checking and Symbolic Computation Workshop (SC-Square) Workshop},
editor = {Fontaine, Pascal and Korovin, Konstantin and Kotsireas, Ilias S. and R{\"{u}}mmer, Philipp and Tourret, Sophie},
pages = {109--119},
title = {{Directed Graph Networks for Logical Reasoning (Extended Abstract)}},
url = {http://ceur-ws.org/Vol-2752/paper8.pdf},
year = {2020}
}

@article{Olsak2019,
abstract = {Automated reasoning and theorem proving have recently become major challenges for machine learning. In other domains, representations that are able to abstract over unimportant transformations, such as abstraction over translations and rotations in vision, are becoming more common. Standard methods of embedding mathematical formulas for learning theorem proving are however yet unable to handle many important transformations. In particular, embedding previously unseen labels, that often arise in definitional encodings and in Skolemization, has been very weak so far. Similar problems appear when transferring knowledge between known symbols. We propose a novel encoding of formulas that extends existing graph neural network models. This encoding represents symbols only by nodes in the graph, without giving the network any knowledge of the original labels. We provide additional links between such nodes that allow the network to recover the meaning and therefore correctly embed such nodes irrespective of the given labels. We test the proposed encoding in an automated theorem prover based on the tableaux connection calculus, and show that it improves on the best characterizations used so far. The encoding is further evaluated on the premise selection task and a newly introduced symbol guessing task, and shown to correctly predict 65% of the symbol names.},
archivePrefix = {arXiv},
arxivId = {1911.12073},
author = {Ol{\v{s}}{\'{a}}k, Miroslav and Kaliszyk, Cezary and Urban, Josef},
eprint = {1911.12073},
month = {nov},
title = {{Property Invariant Embedding for Automated Reasoning}},
url = {http://arxiv.org/abs/1911.12073},
year = {2019}
}

% Graph neural networks (GNNs)
@article{Zhou2018,
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
eprint = {1812.08434},
month = {dec},
title = {{Graph Neural Networks: A Review of Methods and Applications}},
url = {http://arxiv.org/abs/1812.08434},
year = {2018}
}
