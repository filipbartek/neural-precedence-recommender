\documentclass[runningheads]{llncs}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[binary-units=true,detect-weight=true]{siunitx}

% How to write a paper:
% https://mj.ucw.cz/papers/jakpsat.pdf
% Jones 2016: https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/
% AWR: https://jazyky.fel.cvut.cz/vyuka/RPP/BE9M04AKP/

% PAAR paper: https://github.com/filipbartek/learning-precedences-from-elementary-symbol-features/releases/download/paar2020%2Fceur-2/Learning_Precedences_from_Simple_Symbol_Features.pdf

\input{preamble}
\input{glossary}
\input{front}

\usepackage{svg}

\usepackage[pdf]{graphviz}
\usepackage{tikz}

\usepackage{hyperref}
\hypersetup{
pdftitle={Neural Precedence Recommender},
pdfauthor={Filip BÃ¡rtek, Martin Suda},
pdfkeywords={saturation-based theorem proving, simplification ordering, symbol precedence, machine learning, graph convolutional network}
}

\usepackage{cleveref}

\begin{document}

\maketitle

\begin{abstract}
\input{abstract}
\end{abstract}

\section{Introduction}

\input{introduction}

\section{Preliminaries}

\input{preliminaries}

\section{Architecture}
\label{sec:architecture}

\input{architecture}

\section{Experimental evaluation}
\label{sec:evaluation}

\input{evaluation}

\section{Related work}

MS: my sami (PAAR paper) jsem si related workem. Budem se vuci tomu muset vymezit.
Jinak me ale nic moc bezprostredniho nenepada a nevim tedy, jestli se tedy primo
nutit do sekce s timto nazvem!

\section{Conclusion}

\subsection{Future work}

Generalization from trail acc to val acc may be improved.

Highest val accuracy does not transfer to highest ATP success rate. Generalization to ATP is sub-par.

Larger graphs

Joint model (trained jointly on predicate and function precedences)

Differentiate questions due to satiterations from questions due to success and failure

MS: Is there a knowledge transfer possible between related setups when we in vampire change
options (seemingly?) orthogonal to precedence (saturation algorithm, additional inference rules / reductions, AVATAR on/off,
clause selection strategies, etc.)?

KBO is a also parametrized by weights (along with the precedence). Could we learn those as well? (Jointly?)

Reinforcement learning will allow using a trained recommender to generate data from harder problems.

In our experiments, too much attention is spent on uninteresting examples.
We learn to order pairs of non-optimal precedences.
However, if the recommender ordered a non-optimal pair wrong, it could still produce the optimum precedence correctly.
Besides, we train from pairs of successful runs that only differ in number of iterations.

\section*{Acknowledgments}
% > Acknowledgements should generally be placed in an unnumbered subsection at the end of the paper.

% https://sgs.cvut.cz/index.php?action=faq
% This work was supported by the Grant Agency of the Czech Technical University in Prague, grant No. SGS...

\todo{MS: zvazit, jestli nerozepsat zvlast Martin, zvlast Filip.
Pripadne se zeptat Hanky, jestli bychom nemeli nejak vypichnout
jen GACR.}

This work was supported by
the Czech Science Foundation project 20-06390Y,
the project RICAIP no. 857306 under the EU-H2020 programme,
and
the Grant Agency of the Czech Technical University in Prague, grant\\
no.~SGS20/215/OHK3/3T/37.


% > LaTeX users should avoid self-defined environments and use the bibliographic style MathPhySci for computer science proceedings.
% > It is not possible to have hyperlinks in references.
\bibliographystyle{splncs04}
\bibliography{main}

\appendix

\section{Graph structure}

\begin{itemize}
\item The graph representation of problem $P$ contains exactly one root node of type \ntype{problem}.
\item Each clause is represented by a \ntype{clause} node connected to the root \ntype{problem} node.
\item Each atom is represented by an \ntype{atom} node (in case the atom is not an equality)
or an \ntype{equality} node (in case the atom is an equality).
For each literal occurrence there is an edge connecting the respective atom to the respective clause.
The type of the edge corresponds to the polarity of the literal:
\epos{} for positive literal and \eneg{} for negative literal.
\item Each \ntype{equality} node is connected to two nodes that represent the operands,
each of which is of type \ntype{term} or \ntype{variable}.
The commutativity of the equality operator is reflected by the fact that the operand edges are not ordered.
\item Each \ntype{atom} node is connected to one \ntype{predicate} node that represents the predicate symbol being applied by this atom.
Note that these edges connect the applications of a predicate symbol across the whole problem.
\item Each \ntype{atom} node is connected to zero or more \ntype{argument} nodes that represent the argument positions of the atom.
\item Each pair of \ntype{argument} nodes that correspond to consecutive argument positions is connected by an edge.
\item Each \ntype{argument} node is connected to a node that represents the argument term,
which is either a \ntype{term} node or a \ntype{variable} node.
\item Each \ntype{term} node is connected to one \ntype{function} node that represents the function symbol being applied by this term.
\item For each variable, there is an edge connecting the \ntype{clause} node of the clause that binds the variable to the \ntype{variable} node that represents the variable.
\end{itemize}

\section{Loss derivative}

The loss is differentiable with respect to the symbol costs:
\begin{align*}
\frac{\partial \loss}{\partial c_i}
&= -\sigmoid(-C(\Better{\PrecBetter}{\PrecWorse}{P})) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i) \\
&= (p(\Better{\PrecBetter}{\PrecWorse}{P}) - 1) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)
\end{align*}

This means that it is possible to backpropagate the loss gradient into the symbol cost model. \todo{MS: tohle bude tezky,
ale ackoliv ML people by tohle uz asi chapali, ATP crowd spis bude
potrebovat obsirnejsi vysvetleni.}

\section{Experiment details}

\begin{figure}[h]
\caption{The dependence of preprocessing time on the number of nodes in the problem graph on 1000 random validation problems}
\label{fig:preprocessing}
\centering
% \includesvg[width=\textwidth]{preprocessing}
% Source: https://docs.google.com/spreadsheets/d/1GujYNEtETpC3jk4iyENLjptv8mDmI5f1ZEhbmwtqnPM/edit#gid=394425425&fvid=659935521
% Experiment: VML-715
\end{figure}

\end{document}
