----------------------- REVIEW 2 ---------------------

  Detailed comments
  -----------------

 - p12: To clarify the last paragraph of the page, that introduces concepts with which people outside of ML wouldn't be familiar with,
   I suggest to use columns to show that some sentences are definitions for the terms introduced in the previous sentences,
   in particular, "... and 0 otherwise. Adaptive sampling..." -> "... and 0 otherwise: Adaptive sampling..." and
   "... with a parallelizing relaxation. In each iteration..." -> "with a parallelizing relaxation: In each iteration..."
   FB: Let's ignore this comment.

   MS: pise sice "columns", ale mysli "colons" / "dvojtecky". Vubec by mi nevadilo je tam dat, jak pise. Tobe ano?
   FB: Mne trochu ano, protoze se mi to pripada spise matouci nez vysvetlujici. Ale nejsem zasadne proti.

 - p13: Same comment as just above: "... Adam optimizer [15]. Learning rate..." -> "... Adam optimizer [15]: Learning rate..."
   FB: Let's ignore this comment.

   MS: Chapu to jako pokus o strukturovani textu. Nebo myslis, ze je to typograficky nespravne?
   FB: Nemyslim, ze je to typograficky nespravne. Pripada mi to stejne, jako predchozi navrh pridani dvojtecek.

 - p14: In your PAAR paper [7], the experimental results show that your linear model is not as good as the baseline but it is no longer the case here.
   How do you explain this? If it was further improved after PAAR, it should be mentioned.
   FB: Let's ignore this comment.

   MS: Ma pravdu? How do we explain this? :)
   FB: I think this is because here we evaluate on a different distribution of problems, one that is possibly more similar to the training set. In the PAAR paper, the test problems were sampled from problems with at most 1024 predicates in TPTP v7.2.0 (15751/16748 = 94.05 %). Here, the test problems are sampled from problems with at most 100k nodes (7658/8526 = 89.82 %) in TPTP v7.4.0. Should I discuss this in this paper? It seems of relatively little interest.

  Minor comments
  --------------

 - p16-17: The titles of some articles (mostly the arXiv ones, book titles are a different matter) are capitalized, while the others are not. This could be made uniform.
   FB: Let's clean up the bibliography.

   MS: Tohle cele jeste jednou prekope Springer, takze bych tim neztracel moc casu... (Staci, ze pomocnicci v Indii poznaji, ktery clanek jsme meli na mysli.)
   FB: Ok, bibliografii nebudu skoro vubec uklizet, jenom prekontroluju, ze se daji ty zdroje jasne identifikovat.

----------------------- REVIEW 3 ---------------------

----------- Overall evaluation -----------
  Detailed comments:

  - p1 (and elsewhere): Please check the paper for proper use of
    articles. In the case of superposition, it has "native support",
    not "a native support". There are similar problems (too many or
    too few articles) throughout the paper.
    FB: Let's do this using Grammarly and Writefull.
  - p16: The paper is technically over length, but only by the
    acknowledgements section (and would have the same number of total
    pages without it).
    FB: Let's shorten the paper so that even the acknowledgements fit within the limit.
    The email from the organizers says that the limit is strict,
    and that it excludes references (so I assume it includes everything else).

    MS: In my other paper, I will risk Acknowledgements on the 16th page. Let's see if they will notice :)
