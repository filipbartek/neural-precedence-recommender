% !TEX root = main.tex

To demonstrate the capacity of the precedence recommender described in \cref{sec:architecture},
a series of experiments was performed.
%\todo{MS: vzdycky kdyz to jen trochu jde, snaz se pouzivat cinny rod (a pritomny cas): To demonstrate ..., we performed ... Ale taky tu trochu chybi, co nas ceka dal, ve stylu: In this section, we report ... }
In this section, we describe the design and configuration of the experiments,
and then compare the performance of the trained models to baseline heuristics.
\todo{MS: az na to ``was performed'' dobry! ;)}

\subsection{Solver}

The empirical evaluation was performed using a modified version of the \gls{atp} Vampire 4.3.0 \cite{10.1007/978-3-642-39799-8_1}.
The prover was used to generate the training data and to evaluate the trained precedence recommender.
To generate the training data,
Vampire was modified to output \gls{cnf} representations of the problems
and annotated problem signatures in a machine-readable format.
%in \gls{json} format and annotated problem signatures in \gls{csv} format.\todo{MS: Mentioning JSON or CSV seems to be too low level. ``programmer documatation'' material.}
For the evaluation of the precedences generated by the recommender,
Vampire was modified to allow the user to supply explicit predicate and function symbol precedences for the proof search
(normally, the user only picks a precedence generation heuristic).
\todo[inline]{FB: Add a link to the modified Vampire.}

\todo[inline,author=MS]{Literal comparison mode is not a standard thing. Mentioning the option name is again too low level. Explaining the effect (point two) is appropriate, although a bit too vague. To kdyztak opravim ja. 
Popsat presne setup je dulezite, kvuli reprodukovatelnosti, ale ne nutne primo v clanku (budem nejspis stejne dodavat odkaz na nejake reproducibility repo).
Ted zminit AVATAR je nevhodne, pokud nevysvetlis, co to aspon ramcove je. A pokud to budes vysvetlovat, je otazka, proc tim ztracet misto, kdyz to neni bezprostredne relevantni pro dalsi vysvetlovani.}

Vampire was run with a time limit of 10 seconds.
To increase the potential impact of predicate precedences,
we used a simple \gls{tkbo} \cite{Ludwig2007,Kovacs2011}
that compares atoms according to the predicate precedence first,
Using the ordinary \gls{kbo} as a tie-breaker.
Ordinary \gls{kbo} was used to compare terms.
\todo[inline,author=FB]{Describe the detailed configuration in an appendix and reference the appendix here.}

% All explicit options:
% vampire --encode on --statistics full --time_statistics on --proof off --avatar off --saturation_algorithm discount --age_weight_ratio 10 --literal_comparison_mode predicate --symbol_precedence frequency --time_limit 10

% Notable explicit options:
% vampire --avatar off --saturation_algorithm discount --age_weight_ratio 10 --literal_comparison_mode predicate --symbol_precedence frequency --time_limit 10

% Notable implicit options:
% --term_ordering kbo

\subsection{Training data}

The training data consists of examples of the form $(P, \PrecBetter, \PrecWorse)$,
where $P$ is a \gls{cnf} problem and $\PrecBetter, \PrecWorse$ are precedences of symbols of problem $P$
such that out of the two precedences, $\PrecBetter$ yields a proof in fewer iterations of the saturation loop (see \cref{sec:saturation}).
\todo{FB: Justify saturation loop iterations as a proxy for success. MS: Ano, ale driv nez zde!}

Since neither of the common \glspl{sot}, i.e., \gls{kbo} nor \gls{lpo},
\todo{FB: Consider omitting LPO completely if we don't discuss it anywhere in the paper.}
ever compares a predicate symbol with a function symbol,
two separate precedences can be considered for each problem:
a predicate precedence and a function precedence.
We trained a predicate precedence recommender separately from a function precedence recommender
to simplify the training process and to isolate the effects of the predicate and function precedences.
\todo{FB: Weak, handwavy spot. Consider improving the argumentation. MS: tady activum dokonce pomuze 
stim weak spotem. "A recommender is trained separately, because" zni trochu jako "autorita predepisuje delate to prave takto,
protoze <dobre duvody>". Kdyz reknes "we trained, because", ty duvodu uz mohou byt pouze prakticke a ctenar to pochopi! }
This section describes how the training data for training a \emph{predicate} precedence recommender was generated.
Training data for training a function precedence recommender was generated analogously.
\todo{MS: taky jsem to hodil do minuleho casu. Myslim, ze to je opet blizsi skutecnosti: V Cestine:
"Takhle jsme to delali" (at vite, co presne kritizovat) vs "Takhle se to dela" (kritika pak muze byt o dost silnejsi,
protoze jakoby tvrdis, ze prezentujes spravnou metodiku).}

\subsubsection{Problem set}

\todo{MS: mozna bych dal propagoval cinny rod a minuly cas ...}

The examples are generated by sampling the \gls{fol} part of the problem library \gls{tptp} v7.4.0 \cite{10.1007/978-3-030-29436-6_29}.
A total of \num{17053} problems formulated in \gls{fof} and \gls{cnf} are sampled.
The problems formulated in \gls{fof} are converted to \gls{cnf} by Vampire.
% vampire --mode clausify
Let $\ProblemsTptp$ denote the set of all \num{17053} \gls{cnf} problems available for training and evaluation.

\subsubsection{Sampling}

The examples are generated by iterative sampling of $\ProblemsTptp$.
In each iteration, a problem $P \in \ProblemsTptp$ is chosen and Vampire is executed twice on $P$
with two (uniformly) random predicate precedences and a common random function precedence.
% with two predicate precedences chosen with uniform probability from the set of all predicate precedences on $P$.
% One function precedence for $P$ is chosen with uniform probability, and it is used for both executions.
% \todo[author=FB]{Why do we sample function precedences randomly?}
The ``background'' random function precedence serves as additional noise (in addition to the variability 
contained in \gls{tptp}) and makes sure that the predicate precedence recommender
will not be able to rely on any specificities that would come from fixing function precedences in the training data.

The two executions are compared in terms of performance:
predicate precedence $\PrecBetter$ is recognized as better than predicate precedence $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}$,
if the proof search finishes successfully with $\PrecBetter$ ($\SolverRun{P}{\Prec} = \top$)
and if the number of iterations of the saturation loop with $\PrecBetter$ is smaller than with $\PrecWorse$.
\todo{FB: Use notation for saturation loop iterations if the notation was established earlier. 
If failure is denoted by $\infty$, we can simply use $<$.}
If one of the two precedences is recognized as better,
the example $(P, \PrecBetter, \PrecWorse)$ is produced,
where $\PrecBetter$ is the better precedence,
and $\PrecWorse$ is the other precedence.
Otherwise, for example, if Vampire fails on both precedences, we go back to sampling another problem.

To ensure the efficiency of the sampling, the process is interpreted as an instance of Bernoulli multi-armed bandit problem,
\todo{Cite? MS: kdyz bude dobra citace, sem by se urcite sikla:) Pri nejhorsim Sutton \& Barto to jisti.}
with the reward of a trial being 1 in case an example is produced, and 0 otherwise.
Adaptive sampling balances
exploring problems that have been tried relatively scarcely and
exploiting problems that have yielded examples relatively often.
For each problem $P \in \ProblemsTptp$,
the generator keeps track of the number of times the problem has been tried $n_P$
and the number of examples generated from that problem $s_P$.
The ratio of $s_P$ to $n_P$ corresponds to the average reward of problem $P$ observed so far.
The problems are sampled using the allocation strategy \acrshort{ucb1} \cite{Auer2002} with a parallelizing relaxation.
In each iteration, the generator samples the problem $P$ that maximizes
$$
\frac{s_P}{n_P} + \sqrt{\frac{2 \ln n}{n_P}}
$$
where $n = \sum_{P \in \ProblemsTptp} n_P$ is the total number of tries on all problems.
The parallelizing relaxation means that the $s_P$ values are only updated once in \num{1000} iterations,
allowing up to \num{2000} parallel solver executions.
\todo{Explain in detail?}

The sampling runs until a total of \num{1000000} examples are generated.
% sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/out/20210108-generate-predicate/questions_generated
For example, while generating \num{1000000} examples for the predicate precedence dataset,
the least explored problem was tried 19 times, and the most exploited problem was tried 504 times.
\num{5349} out of the \num{17053} problems yielded at least one example.
\todo{FB: Remove these two sentences because the give too arbitrary detail?}
\todo{MS: Ne, za mne naopak super! Trochu se to tim ozivi a dal to ukazuje, na prikladu, jak asi funguje ten UCB! }

\subsubsection{Split}

The problems in $\ProblemsTptp$ are split roughly in half to form the train set and the validation set.
Both training and validation sets are restricted to problems whose graph representation consists of at most \num{100000} nodes
to limit the memory requirements of the training.
The train set is further restricted to problems that correspond to at least one training example.
In total there are \num{7648} problems in the validation set $\ProblemsVal$
and \num{2571} problems in the train set $\ProblemsTrain$.
\todo{MS: A kdyz pouzivas validation set behem uceni, ma taky mensi podmnozinu s limitem \num{100000} nodes?}
\todo{FB: Unify the terminology: validation, or train set?
MS: Co by znamenalo unify? Nebo myslis test set?}
% /home/filip/projects/vampire-ml/vampire-ml/outputs/2021-02-11/16-27-02/results.csv
% all: 17053
% train: 8527
% val: 8526
% with_questions: 5349
% graphified (not all attempted): 10219
% train&with_questions: 2647
% train&with_questions&graphified: 2571
% val&graphified: 7648
\todo{MS: jeste by nebylo lepsi vzit nejdriv ty ``male'' problemy a pak teprve pulit.
MS2: tak ale ted uz to menit nebudeme!}

\subsection{Training procedure}

A predicate symbol cost model is trained by gradient backpropagation
\todo{FB: Explain? MS: tohle by melo byt k pochopeni z predchozich sekci.}
on the precedence pair classification task
\todo{FB: Reference a section. MS: Ano!}
using the examples generated from the problems in $\ProblemsTrain$.
\todo{Add references to the sections that describe the architecture.}
To avoid redundant computations, all examples generated from a problem are processed in the same training batch.
Thus, each training batch contains up to \num{128} problems and all the examples generated from these problems.
The symbol cost model is trained using the Adam optimizer \cite{Kingma2014}.
Learning rate starts at \num{1.28e-3}
and is halved each time the train loss stagnates for 10 consecutive epochs.
% tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10)
A \gls{gcn} with depth 4 and message size 16 is used.\todo{MS: zase pasivum. Tady to urcite bude chtit odkaz na sekci, kde se jasne definuje, co to znamena. Jinak recenzenti byvaji dost alergicti na hyperpametry, ktere se jen tak nahodi na nevysvetli. Minimalne nejaky komentar typu: treba, zkouseli jsme u ruzne dalsi hodnoty, ale dopadalo to podobne. Nebo, pozdeji rekeneme, co se deje, kdyz se tohle meni. Nebo: nemeli jsme cas zjistovat, co se deje, kdyz se to meni, tak berem rozumne hodnoty podle blabla.}

Each of the training examples of problem $P$ contributes to the training with the weight $\frac{1}{s_P}$,
where $s_P$ is the number of examples of problem $P$ in the training set,
so that each problem contributes to the training to the same degree irrespective of the relative numbers of examples.
\todo{FB: Shall we remind that the examples are further normalized by $k(n)$ to make even across signature lengths?}
\todo{MS: asi dobry, pokud to bude jasne receny nejaky predchozi sekci.}

MS: nechybi tu odstavec tom, jak klesala loss, ale validacni moc ne.
(Mozna i o accuracy?) Pak o (continuous) ATP eval...
and how we chose the final model?

\subsection{Environment}

All the experiments were run on a computer with the following specification:

\begin{itemize}
\item CPU: Intel Xeon Gold 6140 (72 cores @ \SI{2.30}{GHz})
\item RAM: \SI{383}{GiB}
\item OS: Ubuntu 20.04
\item Kernel: GNU/Linux 5.4.0-40-generic x86\_64
\end{itemize}

% From the paper Reliable benchmarking [BenchExec]:
% – CPU model and size of RAM,
% – specified resource limits,
% – name and version of OS,
% – version of important software packages, such as the kernel or runtime environments like the Java VM,
% – version and configuration of the benchmarked tool(s), and
% – version of the benchmark set (input files)

\subsection{Results}

The final evaluation is performed on $\ProblemsVal$.
For each problem $P \in \ProblemsVal$,
a precedence is generated by the trained recommender
and Vampire is run using this precedence and a wall clock time limit of 10 seconds.
The results are averaged over 5 runs to reduce the effect of noise due to wall clock time limit.
As a baseline, the performance of Vampire with the \texttt{frequency} precedence heuristic was evaluated
with the same time limit.

To generate a precedence for a problem,
the recommender first converts the problem to a machine-friendly \gls{cnf} format,
then converts the \gls{cnf} to a graph,
then predicts symbol costs using the \gls{gcn} model
and finally orders the symbols by their costs to produce the precedence.
To simplify the experiment, the time limit is only imposed on the Vampire run
and excludes the time taken by the recommender to generate the precedence.
\todo{Update if we include the preprocessing time.}
\todo{MS: and if we don't, this would be the perfect place to summarize
how long the just described procedure took on an average problem,
or how it (roughly) scales with the graph/cnf/tptp\_file size.} 

\Cref{tab:results} shows the results.

\begin{table*}
\caption{
Results of the evaluation of various predicate precedence heuristics on $\ProblemsVal$.
Means and standard deviations over 5 runs are reported.
}
\centering
\begin{tabular}{l|ll|ll}

Model & \multicolumn{2}{l}{Successes out of \num{7648}} & \multicolumn{2}{l}{Successes rate} \\
& Mean & Std & Mean & Std \\
\hline

\acrshort{gcn} (predicate) & \num{3923.6} & \num{2.24} & \SI{51.30}{\percent} & \num{2.93e-4} \\
% Success rate: mean: 0.513023013, std: 0.000292887
% Evaluation results: https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-553
% Total: validation_solver_eval/all/problems/measured&split&category: 7648
% Success mean: validation_solver_eval/all/success/count/mean: 3923.6
% Success std: validation_solver_eval/all/success/count/std 2.24
% Success rate: 0.513023013
% Difference in success count from baseline: 154 ~ 0.020135983
% Estimated difference from baseline (estimate on 891 problems): 0.021099888
% Checkpoint: outputs/2021-02-06/14-55-41/tf_ckpts/epoch/weights.00079-0.61.tf VML-540 0.511785

\acrshort{gcn} (function) & ? & ? & \SI{51.2}{\percent} & ? \\
% TODO: This is a hot preview from VML-672. Replace with final results.

\texttt{vampire -lcm predicate} & \num{3769.6} & \num{3.07} & \SI{49.29}{\percent} & \num{4.01e-4} \\
% Success rate: mean: 0.492887029, std: 0.000401412
% https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-490
% /home/filip/projects/vampire-ml/vampire-ml/outputs/2021-02-09/12-13-43
% Row: 'val&graphified&solver_eval'
% Problems total: 7648
% Success rate: 0.492887029

\texttt{vampire -lcm standard} & ? & ? & ? & ? \\

\end{tabular}
\label{tab:results}
\end{table*}
\todo{FB: Add links to Neptune runs?}
\todo{FB: Finalize results for function precedences.}
\todo{FB: Try to evaluate a recommender that uses both predicate and function models.}

\todo{FB: Add discussion.}
\todo{FB: Evaluate on problems larger than 100k nodes.}
