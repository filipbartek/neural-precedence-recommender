% !TEX root = main.tex

% Subsubsekce muzem "odresit" napriklad takto:
%\renewcommand{\subsubsection}{\paragraph}

\todo[inline]{FB: Scan through this section and make sure we use "we" form and past tense consistently.}

To demonstrate the capacity of the trainable precedence recommender described in \cref{sec:architecture,sec:training},
we performed a series of experiments.
In this section, we describe the design and configuration of the experiments,
and then compare the performance of several trained models to a baseline heuristic.

The scripts that were used to generate the training data and to train and evaluate the recommender
are available online.\footnote{\url{https://github.com/filipbartek/vampire-ml/tree/cade28}}
% https://github.com/filipbartek/vampire-ml/tree/10ee2d730f96ea264dc829b8aabd2d95cc083e50

\subsection{Environment}

\subsubsection{System}

All the experiments were run on a computer with
the CPU Intel Xeon Gold 6140 (72 cores @ \SI{2.30}{GHz}) and
\SI{383}{GiB} RAM.
%the OS Ubuntu 20.04 and
%the Linux kernel 5.4.0-40-generic.
\todo{FB: Add version of Python and notable packages, namely DGL and TensorFlow. 
MS: Z tohohle bych vetsinu nebo vsechno prenesl do README na adrese vyse.
Stejne ten paper neobsahuje dost informaci na to, aby si to mohl po nas nekdo naprogramovat a spustit.
Tak uz muze byt uplne jedno, jakou mame verzi Linuxu...}

% From the paper Reliable benchmarking [BenchExec]:
% – CPU model and size of RAM,
% – specified resource limits,
% – name and version of OS,
% – version of important software packages, such as the kernel or runtime environments like the Java VM,
% – version and configuration of the benchmarked tool(s), and
% – version of the benchmark set (input files)

\subsubsection{Solver}

The empirical evaluation was performed using a modified version of the \gls{atp} \Vampire{} 4.3.0 \cite{10.1007/978-3-642-39799-8_1}.
\todo[author=R2]{the reference for Vampire ([20]) describes version 2.6 of Vampire and you are using version 4.3. If available, something more recent would give a better idea of the current capacities of Vampire.}
The prover was used to generate the training data and to evaluate the trained precedence recommender.
To generate the training data,
\Vampire{} was modified to output \gls{cnf} representations of the problems
and annotated problem signatures in a machine-readable format.
%in \gls{json} format and annotated problem signatures in \gls{csv} format.\todo{MS: Mentioning JSON or CSV seems to be too low level. ``programmer documatation'' material.}
For the evaluation of the precedences generated by the recommender,
\Vampire{} was modified to allow the user to supply explicit predicate and function symbol precedences for the proof search
(normally, the user only picks a precedence generation heuristic).
The modified version of \Vampire{} is available online.\footnote{\url{https://github.com/filipbartek/vampire/tree/cade28}}
% https://github.com/filipbartek/vampire/tree/3bbfa9e6cd009f501f74d26eabc7e7811b5bb00e
\todo{MS: nebo jeste lip. Slo by udelat repo,
ve kterym bude textak, co vsechno vysvetli, vcetne linku na ty dve repa co zminujes tady a vyse.}

We run \Vampire{} with a time limit of 10 seconds.
To increase the potential impact of predicate precedences,
we used a simple \gls{tkbo} \cite{Ludwig2007,Kovacs2011}
that compares atoms according to the predicate precedence first,
using the regular \gls{kbo} to break ties between atoms
and to compare terms (using the \Vampire{} option \texttt{-literal\_comparison\_mode predicate}).\todo{MS: ted s vysvetlenim neni naskodu zminit i option name 
``Vampire'' se tim chlubi, ze to ma naimplementovane a my tim rikame, ze jsme si to neprogramovali sami.}
\todo[inline,author=FB]{Describe the detailed configuration in an appendix and reference the appendix here.}
\todo[inline,author=R2]{Did you fix the strategy and heuristics used by Vampire throughout the training and experiments or was it run in portfolio mode? What about AVATAR, was it activated?}

% All explicit options:
% vampire --encode on --statistics full --time_statistics on --proof off --avatar off --saturation_algorithm discount --age_weight_ratio 10 --literal_comparison_mode predicate --symbol_precedence frequency --time_limit 10

% Notable explicit options:
% vampire --avatar off --saturation_algorithm discount --age_weight_ratio 10 --literal_comparison_mode predicate --symbol_precedence frequency --time_limit 10

% Notable implicit options:
% --term_ordering kbo

\subsection{Dataset preparation}

The training data consists of examples of the form $(P, \PrecBetter, \PrecWorse)$,
where $P$ is a \gls{cnf} problem and $\PrecBetter, \PrecWorse$ are precedences of symbols of problem $P$
such that out of the two precedences, $\PrecBetter$ yields a proof in fewer iterations of the saturation loop (see \cref{sec:saturation}).

Since the \gls{tkbo} never compares a predicate symbol with a function symbol,
\todo{FB: Consider referencing an earlier section that explains KBO or TKBO.}
two separate precedences can be considered for each problem:
a predicate precedence and a function precedence.
We trained a predicate precedence recommender separately from a function precedence recommender
to simplify the training process and to isolate the effects of the predicate and function precedences.
This section describes how the training data for the case of training a \emph{predicate} precedence recommender was generated.
Data for training the function precedence recommender was generated analogously.

\subsubsection{Base problem set}

The input problems were assumed to be specified in the \gls{cnf} or the \gls{fof} fragment
of the \acrshort{tptp} language \cite{Sutcliffe2017}.
% http://www.tptp.org/TPTP/SyntaxBNF.html
\Gls{fof} problems were first converted into equisatisfiable \gls{cnf} problems by \Vampire{}.
%New symbols may be introduced during preprocessing,
%namely due to the Tseitin transformation and Skolemization.
%We denote the preprocessed \gls{cnf} problem as $P = (\Sigma, \mathit{Cl})$,
%where $\Sigma$ denotes the list of all predicate and function symbols of the problem,
%and $\mathit{Cl}$ denotes a set of clauses over $\Sigma$ that constitute the problem.

We used the problem library \acrshort{tptp}~v7.4.0 \cite{Sutcliffe2017}
as the source of problems for training and evaluation of the recommender.
We denote the set of all the problems available for training and evaluation as $\ProblemsTptp$ ($\card{\ProblemsTptp} = 17053$).

\subsubsection{Node feature extraction}

In addition to the signature and the structure of the problem,
some metadata was extracted from the input problem to allow training a more efficient recommender.
First, each clause was annotated with its role in the problem,
which could be either axiom, assumption, or negated conjecture.
% This is simplified. There are actually 7 clause roles defined internally in Vampire,
% and it seems that only 4 of them are ever used in FOL problems:
% AXIOM, ASSUMPTION, CONJECTURE, NEGATED_CONJECTURE
% CONJECTURE is used in FOF problems and NEGATED_CONJECTURE is used in CNF problems,
% so the recommender can actually differentiate between these two forms.
Second, each symbol was annotated with two bits of data:
whether the symbol was introduced into the problem during preprocessing,
and whether the symbol appeared in a conjecture clause.
% Note that the second bit is redundant, since the clauses are annotated with their roles.
This metadata was used to construct the initial embeddings of the respective nodes
in the graph representation of the problem (see \cref{sec:gcn}).
\todo{FB: Consider simplifying the paragraph by removing overlap with \cref{sec:gcn}.}

\subsubsection{Examples generation}

The examples were generated by iterative sampling of $\ProblemsTptp$.
In each iteration, a problem $P \in \ProblemsTptp$ was chosen and \Vampire{} was executed twice on $P$
with two (uniformly) random predicate precedences and a common random function precedence.
The ``background'' random function precedence served as additional noise (in addition to the variability 
contained in \acrshort{tptp}) and made sure that the predicate precedence recommender
would not be able to rely on any specificities that would come from fixing function precedences in the training data.

The two executions were compared in terms of performance:
the predicate precedence $\PrecBetter$ was recognized as better than the predicate precedence $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}{P}$,
if the proof search finished successfully with $\PrecBetter$
and if the number of iterations of the saturation loop with $\PrecBetter$ was smaller than with $\PrecWorse$.
\todo{FB: Use notation for saturation loop iterations if the notation was established earlier. 
If failure is denoted by $\infty$, we can simply use $<$.}
If one of the two precedences was recognized as better,
the example $(P, \PrecBetter, \PrecWorse)$ would be produced,
where $\PrecBetter$ was the better precedence,
and $\PrecWorse$ was the other precedence.
Otherwise, for example, if the proof search timed out on both precedences, we would go back to sampling another problem.
\todo{FB: Discuss: How come we mix examples in which both precedences terminate with examples in which only one precedence terminates?}

To ensure the efficiency of the sampling, we interpreted the process as an instance of the Bernoulli multi-armed bandit problem \cite{Sutton1998},
with the reward of a trial being 1 in case an example is produced, and 0 otherwise.
Adaptive sampling balanced
exploring problems that have been tried relatively scarcely, and
exploiting problems that have yielded examples relatively often.
For each problem $P \in \ProblemsTptp$,
the generator kept track of the number of times the problem has been tried $n_P$,
and the number of examples generated from that problem $s_P$.
The ratio $\frac{s_P}{n_P}$ corresponded to the average reward of problem $P$ observed so far.
The problems were sampled using the allocation strategy \acrshort{ucb1} \cite{Auer2002} with a parallelizing relaxation.
% FB: The parallelizing relaxation is not described in Auer2002. We have designed it ourselves.
First, the values of $n_P$ and $s_P$ for each problem $P$ were bootstrapped by sampling the problem a number of times equal to a lower bound on the final value of $n_P$ (at least 1).\footnote{The number of tries each problem was bootstrapped with is
$n_0 = \ceil{\frac{2 \log{N}}{\Parentheses{1 + \sqrt{\frac{2 \log{N} \card{\ProblemsTptp}}{N}}}^2}}$,
where $N$ is the final number of examples to be generated.
For example, if $N=1000000$ and $\card{\ProblemsTptp}=17053$, then $n_0 = 10$.}
% FB: Note that the original UCB1 initially samples each object exactly once.
% FB: More precisely, N can be any lower bound on the number of tries to be performed.
\todo[inline,author=FB,disable]{We bootstrap with a per-problem lower bound on the final number of questions. The lower bound is a solution to the equation for $n_B$:

$$
\frac{s_B}{n_B} + \sqrt{\frac{h \log n}{2 n_B}} < \frac{s_G}{n_G} + \sqrt{\frac{h \log n}{2 n_G}}
$$

By taking $s_B = 0$, $s_G = n_G = \frac{n}{|\ProblemsTptp|}$, we get:

$$
\sqrt{\frac{h \log n}{2 n_B}} < 1 + \sqrt{\frac{h \log n}{2 \frac{n}{|\ProblemsTptp|}}}
$$

This leads to the following number of bootstrap samples:
$$
\ceil*{\frac{c}{2 \Parentheses*{1 + \sqrt{\frac{c |\ProblemsTptp|}{2 N}}}^2}}
$$
where $c = h \log{N}$, $N$ is the desired final number of samples (acting as a lower bound on the total number of tries), and $h$ is the Hoeffding exponent (UCB1 default: 4).

Nicely written for $h=4$:
$$
\ceil*{\frac{2 \log{N}}{\Parentheses*{1 + \sqrt{\frac{4 \log{N} |\ProblemsTptp|}{2 N}}}^2}}
$$

The standard way is to bootstrap with only one sample per problem.
By enlarging the bootstrap set, we get better estimates early on.
The expected outcome is the same but the variance is lower (?).
}
In each subsequent iteration, the generator sampled the problem $P$ that maximized
$\frac{s_P}{n_P} + \sqrt{\frac{2 \ln n}{n_P}}$,
where $n = \sum_{P \in \ProblemsTptp} n_P$ was the total number of tries on all problems.
The parallelizing relaxation means that the $s_P$ values were only updated once in \num{1000} iterations,
allowing up to \num{2000} parallel solver executions.
\todo{Explain in detail?}
\todo[inline,author=R2]{To clarify the last paragraph of the page, that introduces concepts with which people outside of ML wouldn't be familiar with, I suggest to use columns to show that some sentences are definitions for the terms introduced in the previous sentences, in particular, "... and 0 otherwise. Adaptive sampling..." -> "... and 0 otherwise: Adaptive sampling..." and "... with a parallelizing relaxation. In each iteration..." -> "with a parallelizing relaxation: In each iteration..."}

The sampling continued until \num{1000000} examples were generated when training a predicate precedence recommender,
or \num{800000} examples in case of a function precedence recommender.
% sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/out/20210108-generate-predicate/questions_generated
For example, while generating \num{1000000} examples for the predicate precedence dataset,
\num{5349} out of the \num{17053} problems yielded at least one example,
while the least explored problem was tried 19 times, and the most exploited problem 504 times.

\subsubsection{Validation split}

The \num{17053} problems in $\ProblemsTptp$ were first split roughly in half to form the training set and the validation set.
Next, both training and validation sets were restricted
to problems whose graph representation consisted of at most \num{100000} nodes
to limit the memory requirements of the training.
Approximately \SI{90}{\percent} of the problems fit into this limit
%a total of \num{15282} out of the \num{17053} (approximately \SI{90}{\percent}) problems satisfy this requirement.
and there were \num{7648} problems in the resulting validation set $\ProblemsVal$.
The training set $\ProblemsTrain$ was further restricted to problems that correspond to at least one training example,
resulting in \num{2571} problems when training a predicate precedence recommender,
and \num{1953} problems when training a function precedence recommender.
% /home/filip/projects/vampire-ml/vampire-ml/outputs/2021-02-11/16-27-02/results.csv
% all: 17053
% train: 8527
% val: 8526
% with_questions: 5349
% graphified: 15282
% train&with_questions: 2647
% train&with_questions&graphified: 2571
% val&graphified: 7648

\subsection{Hyperparameters}

We used a \gls{gcn} described in \cref{sec:gcn}
with depth 4, message size 16, \gls{relu} activation function,
skip connections \cite{Zhou2018}, and layer normalization \cite{Ba2016}.
We tuned the hyperparameters by a small manual exploration.

\subsection{Training procedure}

A symbol cost model was trained by gradient descent
on the precedence ranking task (see \cref{sec:ranking})
using the examples generated from $\ProblemsTrain$.
To avoid redundant computations, all examples generated from a problem were processed in the same training batch.
Thus, each training batch contained up to \num{128} problems and all the examples generated from these problems.
The symbol cost model was trained using the Adam optimizer \cite{Kingma2014}.
The learning rate started at \num{1.28e-3}
and was halved each time the loss on $\ProblemsTrain$ stagnated for 10 consecutive epochs.
% tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=10)
\todo[author=R2]{Same comment as just above: "... Adam optimizer [15]. Learning rate..." -> "... Adam optimizer [15]: Learning rate..."}

%\subsubsection{Sample weighting}
The examples were weighted.
Each of the examples of problem $P$ contributed to the training with the weight $\frac{1}{s_P}$,
where $s_P$ was the number of examples of problem $P$ in the training set.
This ensured that each problem contributed to the training to the same degree irrespective of the relative numbers of examples.

%\iftoggle{LONG}{
%%\subsubsection{Metrics}
%To analyze the training process,
%we tracked the dynamics of three metrics on $\ProblemsTrain$ and $\ProblemsVal$:
%loss, accuracy and solver performance.
%The solver performance was estimated once per 10 training epochs by running \Vampire{}
%on \num{1000} problems of the respective problem set
%and counting the number of problems successfully solved within the time limit.
%Since the accuracy is a proxy measure of solver performance and the loss is a proxy measure of the accuracy,
%we are interested in generalization from loss to accuracy and from both loss and accuracy to solver performance.
%Similarly, we are interested in generalization from training set to validation set.
%\todo{MS: kdyz se to tady tak pekne pripravi, asi ctenar ceka, ze se to pozdeji 
%nejak zuzitkuje. Pokud se rozhnodnem loss/accuracy/ATP zavislost dal nerozebirat,
%asi je tu navic i tento odstavec, nebo aspon jeho cast.}
%}

%\subsubsection{Termination}
We continued the training until the validation accuracy stopped increasing for 100 consecutive epochs.

\subsection{Final evaluation}

After the training finished,
we performed a final evaluation of the most promising intermediate trained model on the whole $\ProblemsVal$.
The model that manifested the best estimated solver performance on a sample of \num{1000} validation problems
was taken as the most promising.
\todo[inline]{FB: Watch out: This way we may overfit on the 1000 problems used for sample solver performance evaluation. We should leave out these 1000 problems from the final evaluation.}
\todo[inline]{MS: taky me to ted napadlo! Uplne oficialni metodika byva split na train,valid,test. 
Kdy se trenuje na train, hyperparametry (vcetne early stopping) se ladi vuci valid 
a pak se vyhodnocuje na test. Nekdy se pak valid rika devel a test se rika holdout.}

\subsection{Results}

A predicate precedence recommender was trained on approximately \num{500000} examples,
% Half of the 1M predicate examples was used for validation.
and a function precedence recommender was trained on approximately \num{400000} examples.
% Half of the 800k function examples was used for validation.
For each problem $P \in \ProblemsVal$,
a predicate and a function precedences
were generated by the respective trained recommender,
and \Vampire{} was run using these precedences
with a wall clock time limit of 10 seconds.
% Note: We have mentioned the time limit above and here we repeat it for readers who only read Results.
The results are averaged over 5 runs to reduce the effect of noise due to the wall clock time limit.
As a baseline, the performance of \Vampire{} with the \texttt{frequency} precedence heuristic\footnote{
This is \Vampire{}'s analogue of the \texttt{invfreq} scheme in E \cite{E-manual}.}
was evaluated with the same time limit.
For comparison, the two trained recommenders were evaluated separately,
with the predicate precedence recommender using the \texttt{frequency} heuristic to generate the function precedences, and vice versa.

To generate a precedence for a problem,
\todo{MS: tenhle odstavec mozna prehodit s predchozim?}
the recommender first converts the problem to a machine-friendly \gls{cnf} format,
then converts the \gls{cnf} to a graph,
then predicts symbol costs using the \gls{gcn} model
and finally orders the symbols by their costs to produce the precedence.
To simplify the experiment, the time limit of 10 seconds was only imposed on the \Vampire{} run
and excluded the time taken by the recommender to generate the precedence.
When run with 2 threads,
the preprocessing of a single problem
takes at most \num[round-mode=places,round-precision=2]{1.262744486} seconds
for \SI{80}{\percent} of the problems
by extrapolation from a sample of \num{1000} problems.
\todo[author=R2]{What about the remaining 20\% that do not take at most 1.26 seconds? Do they all timeout?}
% Analysis: https://docs.google.com/spreadsheets/d/1GujYNEtETpC3jk4iyENLjptv8mDmI5f1ZEhbmwtqnPM/edit?usp=sharing
% VML-715
\todo{MS: 1) single-core bych chapal jako default. tj netreba zminovat?
2) kterych 1000? To opet drazdi k otazkam. tj to bych asi taky vynechal, ale...
3) to maximum prece zalezi na tom, kterych 1000 to bylo.}
\todo{MS: Idea: kdyz je to linearni: co cas potrebny na recommending
vztahnout k casu klauzifikace? Jako rict, ze to trva x-krat dyl nez jen klauzifikovat?}
\Cref{tab:results} shows the results of the final evaluation.

\begin{table*}[h]
\caption{
Results of the evaluation of symbol precedence heuristics based on various symbol cost models
on $\ProblemsVal$ ($\card{\ProblemsVal} = 7648$).
Means and standard deviations over 5 runs are reported.
The \gls{gcn} models were trained according to the description in \cref{sec:architecture,sec:training,sec:evaluation}.
The model Simple is the final linear model from our previous work \cite{DBLP:conf/cade/Bartek020}.
The models that used \acrlong{ml} only for the predicate precedence
used the \texttt{frequency} heuristic for the function precedence, and vice versa.
The frequency model uses the standard \texttt{frequency} heuristic for both predicate and function precedence.
}
\label{tab:results}
\centering
\begin{tabular}{l|ll|rl}

Symbol cost model & \multicolumn{2}{l}{Successes on $\ProblemsVal$} & \multicolumn{2}{l}{Improvement over baseline} \\
& Mean & Std & Absolute & Relative \\

\hline


\acrshort{gcn} (predicate and function) &
% VML-706
\num{3951.6} &
\num[round-mode=places,round-precision=2]{1.624807680927192} &
%\SI{51.69}{\percent} &
+182.0 &
\num[round-mode=places,round-precision=3]{1.048280985} \\


\acrshort{gcn} (predicate only) &
% Success rate: mean: 0.513023013, std: 0.000292887
% Evaluation results: https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-553
% Total: validation_solver_eval/all/problems/measured&split&category: 7648
% Difference in success count from baseline: 154 ~ 0.020135983
% Estimated difference from baseline (estimate on 891 problems): 0.021099888
% Checkpoint: outputs/2021-02-06/14-55-41/tf_ckpts/epoch/weights.00079-0.61.tf VML-540 0.511785
\num{3923.6} &
% Success mean: validation_solver_eval/all/success/count/mean: 3923.6
\num{2.24} &
% Success std: validation_solver_eval/all/success/count/std 2.24
%\SI{51.30}{\percent} &
% Success rate: 0.513023013
+154.0 &
\num[round-mode=places,round-precision=3]{1.040853141} \\


\acrshort{gcn} (function only) &
% Final evaluation: VML-677
% Evaluated checkpoint: outputs/2021-02-16/12-28-14/tf_ckpts/epoch/weights.00289.tf
% Results file: sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/outputs/2021-02-17/12-01-09/solver_eval/symbol_cost/epoch_-1/logs.yaml
% Total: val/all/problems/measured&split&category: 7648
\num{3874.2} &
% Success mean: val/all/success/count/mean: 3874.2
\num[round-mode=places,round-precision=2]{1.8330302779823362} &
% Success std: val/all/success/count/mean: 1.8330302779823362
%\SI{50.66}{\percent} &
% Success rate: val/all/success/count/mean: 0.5065638075313807
+104.6 &
\num[round-mode=places,round-precision=3]{1.027748302} \\


Simple (predicate only) &
\num{3827.2} &
\num[round-mode=places,round-precision=2]{1.9390719429665317} &
%\SI{50.04}{\percent} &
+57.6 &
\num[round-mode=places,round-precision=3]{1.015280136} \\
% Final vector from PAAR paper: [0,0.429306921481749,0.57069307851825,0,0,0,0,0,0,0,0,0]
% Source: https://docs.google.com/spreadsheets/d/1HSsC7piUAtWt6uwA9SYOX5vmiF0Ab3Ae4FPyGsDALIg/edit#gid=99404775


%Frequency (regular \acrshort{kbo}) &
%\texttt{vampire -lcm standard} &
%\num{3823.0} &
%\num[round-mode=places,round-precision=2]{3.40587727318528} &
%\SI[round-mode=places,round-precision=2]{49.9869247}{\percent} &
%+53.4 &
%\num[round-mode=places,round-precision=3]{1.014165959} \\
% VML-741


Frequency (baseline) &
%\texttt{vampire -lcm predicate} &
% Success rate: mean: 0.492887029, std: 0.000401412
% https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-490
% /home/filip/projects/vampire-ml/vampire-ml/outputs/2021-02-09/12-13-43
% Row: 'val&graphified&solver_eval'
% Problems total: 7648
% Success rate: 0.492887029
\num{3769.6} &
\num{3.07} &
%\SI{49.29}{\percent} &
0.0 &
\num[round-mode=places,round-precision=3]{1.0} \\

\end{tabular}
\end{table*}

\todo[inline,author=R2]{In your PAAR paper [7], the experimental results show that your linear model is not as good as the baseline but it is no longer the case here. How do you explain this? If it was further improved after PAAR, it should be mentioned.}

The results show that the \gls{gcn}-based model outperformed the \texttt{frequency} heuristic by a significant margin.
\todo{FB: Add links to Neptune runs?}
Since the predicate precedence recommender was trained against randomly distributed function precedences,
it is expected to perform well irrespective of the function precedence heuristic it is combined with, and conversely.
Combining the trained recommenders for predicate and function precedences manifested better performance
than any of the two in combination with the standard \texttt{frequency} heuristic,
outperforming the \texttt{frequency} heuristic by approximately \SI{4.8}{\percent}.

\todo[inline,author=R1]{Despite the clear improvement over baseline, the percentage gained does not appear
to be too big. It is possible, that the potential effect of better orderings is not
too high, regardless of the optimizations. Can you give some insights for this
line of thought?
}

We verified that the linear predicate precedence heuristic
trained in \cite{DBLP:conf/cade/Bartek020} outperforms the \texttt{frequency} heuristic.
Moreover, we confirmed the conjecture that using a \gls{gnn} may perform even better \cite{DBLP:conf/cade/Bartek020}.

% The following figures probably exclude the graphification because it is cached.

% Generating questions for predicate precedence recommender:
% - Data: sftp://cluster.ciirc.cvut.cz/home/bartefil/git/vampire-ml/logs/train/20210108-161206
% - Time to generate 1M questions: 1d 18h (1318k attempts)

% Predicate recommender training: VML-540:
% - Best epoch: 79
% - Last epoch: 673
% - Total time: 1d 21h
% - Time to reach epoch 79: 3h 15m

% Generating questions for function precedence recommender: VML-555:
% - Time to generate 800k questions: 3d 16h (1 227 553 attempts)

% Training of function precedence recommender: VML-672:
% - Best epoch: 289
% - Last epoch: 489
% - Total time: 19h 32m
% - Time to reach epoch 289: 11h 37m

\iftoggle{LONG}{
\todo[inline]{MS: kdyz bude misto, dal bych to driv. Souhlasim, ze kdyz se budu zahazovat, tak spolecne s odstavcem "Metrics" drive.}
In the process of training,
we tracked three metrics on the training and validation sets:
loss, accuracy, and solver performance on a sample of 1000 problems.
A typical training ran for approximately 500 epochs
with training loss steadily decreasing and
validation loss decreasing for the initial 50 epochs and then increasing.
Both training and validation accuracy were steadily increasing (training accuracy significantly faster than validation accuracy),
with validation loss entering a plateau around epoch 100.
The solver performance approximately followed the dynamics of the accuracy on the respective problem set.
% Predicate: https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-540/charts
% Function: https://ui.neptune.ai/filipbartek/vampire-ml/e/VML-672/charts
}

\todo[inline]{FB: Discuss the phenomenon of increasing validation loss and accuracy.}
%A possible explanation of the discrepancy between the improving validation accuracy and deteriorating validation loss
%in the latter part of the training process
%is that the improvements of training loss generalize to improvements of loss on some, but not all of the validation examples.
%
%is that due to the limited generalization from training to validation set,
%some improvements of training loss come at the cost of an increase of loss on validation examples that are already misclassified
%(assigned a negative score).
%Such change increases the validation loss but does not affect the validation accuracy.
%At the same time there are validation examples whose loss is decreasing,
