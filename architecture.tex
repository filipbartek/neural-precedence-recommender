\todo{Describe problem again, this time precisely / technically.}
\todo{Prove that minimizing precedence cost corresponds to sorting by symbol cost.}
\todo{Advantage of using pairs of precedences: we need to solve classification rather than regression.}
\todo{Intuice: snazime se nastavit costy tak, aby co nejvic dvojic dopadlo spravne.}
\todo{Some pairs of precedences are not informative. We hope that the non-systematic examples will cancel each other out.}
\todo{Compare our GCN to Michael, Mirek etc.}

\iffalse

\subsection{Learning to generate good permutations}

Generating good symbol precedences is an instance of a more general task
of generating permutations of arbitrary length.
Each input problem corresponds to an input object that specifies the length of a permutation.

Let $X$ be a set of objects.
Let $l: O \to \nat$ assign each object $x \in X$ its signature length $l(x)$.
Let $\{x_1, \ldots, x_n\}$ be the training samples.\todo{MS: je mi jasny, ze tu neni poradek, ale i tak; posledni dva odstavce jsou dost zmateny.}

\subsubsection{Binary classification}

Let $p_\theta : X \to \re$ be a binary classification model.\todo{MS: Dobry priklad na to, ktere pojmy je treba vysvetlovat. model je znamy pojem v logice, tady ale pouzivame jiny, ML vyznam. To by si zaslouzilo komentar. Navic pisem
``binary'' a ``classification'' a neni tu jasny, co je ``binary''
a co jsou ``classes''. Z pohledu ctenare, ktery o tom zatim neslysel, se misto ``binary classficiation model'' mohlo
psat ``housenka'' a vyslo by to pro nej na stejno.}
The model predicts the probability of label $1$.
Let $(x_i, y_i)$ be the training samples,
where $x_i \in X$ and $y_i \in Y = \{0, 1\}$.\todo{MS:
``training'', ``sample'' a ``loss'' jsou dalsi priklady pojmu,
ktere najednou spadly z hury.}

For a training sample $(x, y) \in \re \times \{0, 1\}$, the binary cross-entropy loss is:
$$
L(\theta) = y \log{f_\theta(x)} + (1-y) \log{(1-f_\theta(x))}
$$

If $y_i = 1$ for all $i$, then the loss can be written in a simpler form:
$$
L(\theta) = \log{f_\theta(x)}
$$

\subsubsection{Permutations}

Let $O$ be a set of objects (or contexts).
Given an object $o \in O$, let $\Sigma(o)$ be its signature.
Let $x_i = (o_i, \pi_i, \rho_i)$, where $o_i \in O$
and $\pi_i, \rho_i \in \Perm(\Sigma(o_i))$.
Let $y_i \in \{0, 1\}$.

Let $p_\theta: X \to Y$.

Loss:
$$
L(\theta) = \log{p_\theta(x)}
$$

Let $c_\theta(o, s)$ be the predicted cost of symbol $s$.
Then:
$$
p_\theta(o, \pi, \rho) = C_\theta(o, \pi) - C_\theta(o, \rho)
$$

$$
C_\theta(o, \pi) = \sum_{i=1}^{l(o)}{c(o, \pi_i)}
$$

\begin{align*}
L(\theta) &= \log{p_\theta(o, \pi, \rho)} \\
&= \log{(C_\theta(o, \pi) - C_\theta(o, \rho))} \\
&= \log{(\sum_{i=1}^{l(o)}{c(o, \pi_i)} - \sum_{i=1}^{l(o)}{c(o, \rho_i)})} \\
&= \log{\sum_{i=1}^{l(o)}{c(o, \pi_i) - c(o, \rho_i)}} \\
\end{align*}

If $c$ is differentiable,
we can propagate loss gradients into it.

\subsection{Notation}

We denote the set of all finite vectors over $\re$ by $\re^* = \bigcup_{n=1}^\infty{\re^n}$.

Dot product: $\DotProd{x}{y} = \sum_{i=1}^n x_i \cdot y_i$ for $x, y \in \re^n$.

For any $n \in \nat$, we denote the set of all permutations over the set $\{1, \ldots, n\}$ by $\Perm{n}$.
Permuting a vector $x = (x_1, \ldots, x_n) \in \re^n$ by a permutation $\pi = (\pi_1, \ldots, \pi_n) \in \Perm{n}$ yields the vector $\pi(x) = (x_{\pi_1}, \ldots, x_{\pi_n})$.
$\inv{\pi}$ denotes the permutation inverse to $\pi$.
$\inv{\pi} = ...$.
\todo{Define permutation inversion.}
\todo{MS: Mozna ani ne. Ono je obcas tezky zavest a pouzivat presnout matematickou notaci, ktera se navic muze stavat neprehlednou, kvuli te presnosti. Na druhou stranu, intuitivne, kazdy vi, co by to mela byt inverzni permutace. Takze nerikam psat nepresne veci, ale obcas jde
zustak vagni s tim, ze vim, ze existuje zpusob jak to udelat presnym.
A povrchni ctenar to nemusi resit a matematicky zdatny by si ten detail odvodil spravne ...}

\fi

\subsection{System overview}

The precedence recommender is a system that takes
a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$ as the input,
and produces a precedence $\pi^*$ over the symbols $\Sigma$ as the output.

The architecture is designed so that the recommender can be trained
on the results executions of an \gls{atp} on various problems with random precedences.
The recommender is parameterized by weight tensors
whose values can be trained by gradient descent.
\todo{Ensure we have defined ``gradient descent''.}
The goal of the training is to find parameter values
such that the recommender produces precedences
that are likely to yield a successful proof in few iterations of the saturation loop.
\todo{FB: Too vague?}

The recommender consists of modules that perform specific subtasks (see \cref{fig:architecture}):
\begin{enumerate}
\item Graphifier converts the input \gls{cnf} problem into a problem graph.
\item \gls{gcn} converts a problem graph into symbol embeddings.
The \gls{gcn} contains one or more convolution layers.
\item Projection converts the symbol embeddings into a vector of symbol costs.
\item Sorting converts the symbol costs into a symbol precedence.
It is only used in generating mode.
\item Loss function converts the symbol costs and a pair of precedences into a loss value.
It is only used in training mode.
\end{enumerate}

\begin{figure}[h]
\caption{Recommender architecture overview.
When recommending a precedence, the input is problem $P$ and the output is precedence $\pi^*$.
When training on an example, the input is problem $P$ and precedences $\pi$ and $\rho$,
and the output is the loss value.}
\label{fig:architecture}
\centering
\digraph[scale=0.4]{ArchitectureOverview}{
graph [splines=ortho,ranksep=0.2];
node [shape=box, fontsize=20];
edge [fontsize=20];

Problem [label="CNF problem P"];
Graphifier [style=rounded, label="Graphifier"];
g [label="Graph"];
GCN [style=rounded, label="GCN"];
SymbolEmbedding [label="Symbol embeddings"];
SymbolCostModel [style=rounded, label="Projection"];
SymbolCost [label="Symbol costs"];
Sort [style=rounded, label="Sort"];
Precedence [label=<Output precedence &pi;*>];

Problem -> Graphifier -> g -> GCN -> SymbolEmbedding -> SymbolCostModel -> SymbolCost -> Sort -> Precedence;

pi [label=<Precedence &pi;>];
rho [label=<Precedence &rho;>];
LossFunction [style=rounded, label="Loss function"];
Loss [label="Loss value"];

pi -> LossFunction;
rho -> LossFunction;
SymbolCost -> LossFunction;
LossFunction -> Loss;
}
\end{figure}

\subsection{From \gls{cnf} to graphs}

As the first step of the recommender processing pipeline,
the input problem is converted from a \gls{cnf} representation
to a \emph{heterogeneous directed graph}.\footnote{Data mining literature often uses the term \gls{hin} \cite{Shi2015} for heterogeneous graphs.
We prefer to conform to the terminology common in literature studying \glspl{gnn}.}
\todo{FB: Consider removing the footnote because it is basically useless.}
Each of the nodes is labeled with a node type,
and each edge is labeled with an edge type,
informing the heterogeneous nature of the graph.
The nodes of the graph correspond to various elements that constitute the \gls{cnf} formula,
such as clauses, atoms and predicate symbols.
Each such category of elements corresponds to one node type.
The edges represent the (oriented) relations between the elements,
for example the relation between a clause and one of its atoms,
or the relation between an atom and its predicate symbol.
\Cref{fig:CnfSchema} shows the types of nodes and edges used in our graph representation.

\todo[inline]{Give an example of a problem and its graph.}

\newcommand{\ntype}[1]{\texttt{#1}}
\newcommand{\etype}[1]{\texttt{#1}}
\newcommand{\epos}{\etype{pos}}
\newcommand{\eneg}{\etype{neg}}

\begin{figure}[h]
\caption{CNF network schema}
\label{fig:CnfSchema}
\centering
\tikzstyle{token} = [rectangle, draw]

\begin{tikzpicture}[node distance = 1 and 2, ->]
% https://tex.stackexchange.com/a/332796/202639

% Node and edge types:
% https://docs.google.com/spreadsheets/d/1PCPHEgk6vLxpdpcvB_PGoLx7p4DID6WtvVWy2mDuv4A/edit?usp=sharing

\node (formula) [token] {\ntype{problem}};
% TODO: Consider removing the Formula nodes.
\node (clause) [token, below=of formula] {\ntype{clause}};
\node (atom) [token, below left=of clause] {\ntype{atom}};
\node (equality) [token, below right=of clause] {\ntype{equality}};
\node (predicate) [token, left=of atom] {\ntype{predicate}};
\node (argument) [token, below=of atom] {\ntype{argument}};
\node (term) [token, below=of argument] {\ntype{term}};
\node (function) [token, left=of term] {\ntype{function}};
\node (variable) [token, right=of term] {\ntype{variable}};

\draw (formula) to node [right] {\etype{contains}} (clause);
\draw (clause) to [bend right] node [above] {\epos{}} (atom);
\draw (clause) to [bend left] node [below] {\eneg{}} (atom);
\draw (clause) to [bend left] node [above] {\epos{}} (equality);
\draw (clause) to [bend right] node [below] {\eneg{}} (equality);
\draw (clause) to node [above] {\etype{binds}} (variable);
\draw (atom) to node [above] {\etype{atom\_applies}} (predicate);
\draw (atom) to node [left] {\etype{atom\_has}} (argument);
\draw (equality) to node {\etype{equalizes}} (term);
\draw (equality) to node {\etype{equalizes}} (variable);
\draw (argument) to [bend right] node [left] {\etype{is}} (term);
\draw (argument) to [loop left] node [left] {\etype{precedes}} (argument);
\draw (argument) to node [below] {\etype{is}} (variable);
\draw (term) to node [above] {\etype{term\_applies}} (function);
\draw (term) to [bend right] node [right] {\etype{term\_has}} (argument);

\end{tikzpicture}
\end{figure}

The graph representation has the following properties:
\begin{itemize}
\item For each relation $r$, its inverse $\inv{r}$ is also present in the graph,
represented by a different edge type (unless $r = \inv{r}$ is an identity).
% Note: The relation is considered an identity if it is a subset of the complete identity relation.
\item Lossless: The original problem can be reconstructed from the graph representation completely
(up to equivalent modifications).
\item Signature agnostic: Renaming the symbols and variables in the input problem yields an isomorphic graph.
\item A singleton node of type \ntype{problem} is connected to all the clauses of the problem.
\item The polarity of the literals is expressed by the type of the edge (\epos{} or \eneg{})
connecting the respective atom to the clause it occurs in.
\item For every non-equality atom and term, the order of its arguments is captured by a sequence of \ntype{argument} nodes chained by edges \cite{Rawson2020}.
\item The two operands of equality are not ordered.
This reflects the symmetry of equality.
\item Term-sharing is employed: Redundant atoms and terms share a node representation \cite{}.
Note that since each variable is bound by a clause,
ground terms may be shared across clauses,
but non-ground terms may only be shared within a clause.
\todo{FB: Remove as of little interest?}
\end{itemize}
\todo{FB: Reference appendix if we describe the representation in more detail there.}
\todo[inline]{MS: Filosoficka k ``can be represented''; mozna by se mohlo nekde objevit:
Snazime se do struktury HIN ``otisknout'' celou strukturu CNF (jak jsem rikal,
znamena to, ze zobrazeni je proste), abychom siti nevzali moznost ``vedet o problemu
uplne vsechno'' (az na veci, na kterych nezalezi jako poradi literaly v klauzulich, etc).
Ta filosoficka poznamka je o tom, ze pro dobre uceni tohle vlastne vubec nemusi byt treba,
ze nejaky ``hrubsi otisk'' by mohl stacit tez (a byt treba mensi),
ale my nevime, jak takovy zvolit. }

\subsection{\Gls{gcn}: From graphs to symbol embeddings}

For each symbol in the problem,
we seek to find a vector representation, i.e., an \emph{embedding},
that captures the symbol's properties that are relevant
for the desirable relative rank of the symbol in the symbol precedence.
The symbol embeddings are modeled by a \gls{rgcn} \cite{Schlichtkrull2017},
\todo{Can I use the term \gls{rgcn} when I use a modified version? Namely, the activation is called earlier.}
which is a stack of graph convolutional layers.
Each layer consists of a collection of differentiable modules --- one for each edge type.
A pass through the convolutional layer takes the embeddings of all symbols,
converts them by the edge modules of the adjacent edges to form the messages,
passes the messages to the destination nodes
and aggregates the incoming messages of each node.
In the simple case that each edge module is a dense layer,
the output embeddings $h^{(l+1)}$ is computed from the input embeddings $h^{(l)}$ in the following manner:
$$
h_i^{(l+1)} =
\sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in \mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}
$$
%$$
%h_i^{(l+1)} =
%\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in %\mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
%$$
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
\todo{FB: Mention inspiration: Transformer. See Straka's slides.}
$h_i^{(l)}$ denotes the embedding of node $i$ at layer $l$.
$\mathcal{R}$ denotes the set of all relations in the graph.
$\sigma$ denotes the activation function, for example the \gls{relu}.
$\mathcal{N}_i^r$ denotes the set of neighbors of node $i$ under relation $r$.
$c_{j, i, r} = \sqrt{\card{\mathcal{N}_j^r}} \sqrt{\card{\mathcal{N}_i^r}}$ is a normalization constant \cite{kipf2017semisupervised}.
$W_r^{(l)}$ is a trainable weight matrix representing relation $r$ at layer $l$.

\todo[inline]{Explain residual connections and layer normalization.}
\todo[inline]{MS: neni uplne jiste, ze ``CADE people'' oceni presny zapis 
strutury site, vcetne prvku jako $\mathrm{LayerNorm}$ ve vzorecku.
Nerikam, ze bychom to meli uplne zatajit, ale popis, ktery je zde, spis
patri do appendixu (ML paperu). Na te siti vlastne nic originalniho neni,
tak neni treba vsechno vysvetlit do detailu. Zajimavejsi tu
potom je az to, jak se problem $P$ ``otiskne'' v topologii grafu. 
To uz originalni je (a soutezi to s representacemi jako ta Mirkova)
a popisujes to pak dal.}

\subsection{Projection: From symbol embeddings to symbol costs}

\subsection{Sort: From symbol costs to precedence}

\subsection{Loss}

\subsection{[Alternative: Top-down approach]}

The precedence generator, given a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$,
generates a precedence over $\Sigma$
that is expected to yield a successful proof search.

The recommender first computes a cost value for each symbol of the input problem,
and then orders the symbols by their costs in a non-increasing order.
In this manner, the task of finding good precedences is reduced to the task
of finding a good symbol cost function.
We use a standard \gls{ml} terminology and denote
the practical realization of the symbol cost function as \emph{symbol cost model}.

Note here that the symbol precedence heuristics commonly used in practice
conform to this scheme:
they order the symbols by a numeric property, such as arity or number of occurrences.

\subsection{Symbol cost model}

The symbol cost model, given a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$,
assigns each symbol in $s \in \Sigma$ a real value $c(s)$.
It first uses a symbol embedding model to assign each symbol an embedding.
The resulting symbol cost is a dot product of the symbol embedding with a trainable weight vector:

$$
c(s) = \DotProd{E(s)}{w} + b
$$

\subsection{Symbol embedding model}

The symbol embedding model, given a problem,
assigns each symbol $s \in \Sigma$ an embedding $E(s) \in \re^n$.
Our implementation uses a \gls{rgcn} \cite{}.

\todo[inline]{What is the structure of the graphs? What are the trainable parameters? Etc.}

\subsection{Loss function}

To train the symbol cost model,
examples of the form $(P, \pi, \rho)$ are used.
To be able to train the model by gradient descent,
we need to define a loss function that is differentiable with respect to the model parameters,
and that is minimized by a symbol cost model that produces good precedences.
Optimizing the output precedence directly is not possible
because the sorting operation is not differentiable
and because we generally don't know the best precedence on a given problem.

\todo[inline]{Idea for next project: Optimize precedence directly in a RL fashion: Generate precedence and evaluate with Vampire. If it is the best precedence seen so far, loss is 0 and gradient is 0. Otherwise ground truth is the best precedence seen so far on this problem and we use "differentiable ranking" to backpropagate. Possibly with some exploration, e.g. random swaps of pairs of symbols.}

\newcommand{\Prec}{\pi}
\newcommand{\PrecBetter}{\pi}
\newcommand{\PrecWorse}{\rho}

\subsection{Overview}

Let $\cnf$ be the set of all \gls{cnf} problems.
Let $P \in \cnf$ be an arbitrary problem.
\todo{Consider using $F$ (as formula) instead of $P$ to free up P for probability.}
Let $\signature{P}$ be the signature of $P$, that is a list of all non-logical symbols (predicates and functions)
\todo{Should we rather use either predicates or functions? Or use a compound signature?}
that appear in the problem.
Let $n = \card{\signature{P}}$.
A symbol precedence $\Prec \in \Perm{n}$ for problem $P$ is a permutation of the symbols of $P$.

\newcommand{\Solver}{S}
\newcommand{\SolverRun}[2]{\Solver(#1, #2)}

Let $\Solver$ be an \gls{atp} with a fixed computation environment, configuration and time limit.
The computation of $\Solver$ is assumed to be parameterized by symbol precedence.
\todo{Discuss. What does this mean?}
$\SolverRun{P}{\Prec}$ denotes the result of a proof attempt on problem $P$ with symbol precedence $\Prec$.
$\SolverRun{P}{\Prec} = \top$ if $S$ solves $P$ within the time limit, and $\SolverRun{P}{\Prec} = \bot$ otherwise.
\todo{MS: vadi zminit pocet iteraci smycky tak, jako v minulem paperu?}
Since the result is generally non-deterministic in case the time limit is specified in wall clock units,
we consider $\SolverRun{P}{\Prec}$ to be a random variable with a Bernoulli distribution.
\todo{Cite?}
We denote the probability of a successful proof search $\Prob{\SolverRun{P}{\Prec} = \top}$.
\todo{MS: asi bych se primlouval za to v teto fazi o Bernoullim pomlcet.
Otazky jsme generovali tak, ze proste porovnavame pocty iteraci saturatcni smycky a pocitame s tim, ze beh je deterministicky.
To, ze se pozdeji, pri evalu, pouzije perspektiva nahodnosti
bych uz chapal jako metodiku experimentu a teorii tim nekomplikoval.}

The main task this paper deals with is this:
Given a problem $P \in \cnf$, generate a symbol precedence $\Prec \in \Perm{n}$ that maximizes $\Prob{\SolverRun{P}{\Prec} = \top}$.
\todo[inline]{MS: (Nehlede na to, ze main task by nejspis mel byt vysvetlen mnohem drive...) Asi bych to takhle nestavel. Jak pisu vyse, precijen je
beh dokazovace deterministicky a brat to nejak Bayesovsky by sice mohlo 
byt zajimave, ale jeste mnohem tezsi na obhajeni jako ``svetonazor''.
Co proste priznat nasledujici assumption:
verime, ze pokud bude model spravne odpovidat na otazky $(P, \pi_1, \pi_2)$ (s pravdepodobnosti $> \SI{50}{\percent}$), povede podle nej vybrana permutace minimalizujici \eqref{eq:model_cost} k rychlemu vyreseni problemu (a tim i idealne k vyreseni problemu, ktere byly drive out of reach.)}
\todo{MS: koukni prosim, jestli nejaky takovy mame. Tj zadna random permutace ho nevyresila, ale naucena sit pak ano!}

Instead of modeling $\Prob{\SolverRun{P}{\Prec} = \top}$ directly,
the system described in this paper predicts, given a problem $P$ and a pair of precedences $\PrecBetter, \PrecWorse \in \Perm{n}$,
the probability
\todo{MS: tohle je jeden z oficialnich zpusobu,
jak vysvetlovat neuronky, ale neni nijak jasne do jake miry byva
$\sigma(\mathit{logits})$ blizko nejake pravdepodobnosti. Za mne by klidne stacilo mluvit o tom, ze se snazime klasifikovat co nejvic dvojic
spravne a ze na to pouzivame standard techologii neuronek (Binary Cross Entropy loss (against the final layerâ€™s sigmoid non-linearity)). Tj opet hlasuji za to nemluvit zde o pravdepodobnosti. :)}
\todo{MS: jo, ale pak bude nekde dobre zminit, ze jsme si vedomi, ze dvojice skoro jiste neobsahuji stejne mnozstvi ``signalu'', ze ktereho je mozne se ucit. Je to proste vlastnost vybrane metody a v prumeru to nevadi.}
that $\PrecBetter$ outperforms $\PrecWorse$ in terms of success of proof search. This proxy task allows learning from pairs of precedences that both yield a successful proof search but differ in the number of steps taken in the proof search.
\todo{Explain more.}

% By taking the pairs, we get more data esp. from easy problems.
% Consider weighting the samples by the result type: quantitative / qualitative etc.

\begin{figure}[h]
\caption{System overview}
\label{fig:SystemOverview}
\centering
\usetikzlibrary{shapes}
\tikzstyle{object} = [rectangle, draw]
\tikzstyle{input} = [ellipse, draw]
\tikzstyle{output} = [ellipse, draw]

\begin{tikzpicture}[node distance = 0.5 and 1, ->]
% https://tex.stackexchange.com/a/332796/202639

\node (problem) [input] {\gls{cnf} problem $P$};
\node (symbol embeddings) [object] [below=of problem] {Symbol embeddings};
\node (symbol costs) [object] [below=of symbol embeddings] {Symbol costs};
\node (symbol precedence) [output] [below=of symbol costs] {Symbol precedence};

\draw (problem) to node [left] {GCN} (symbol embeddings);
\draw (symbol embeddings) to node [left] {MLP} (symbol costs);
\draw (symbol costs) to node [left] {Order symbols by their costs} (symbol precedence);

\node (PrecBetter) [input] [right=of problem] {Precedence $\PrecBetter$};
\node (PrecBetterInv) [object] [below=of PrecBetter] {$\inv{\PrecBetter}$};
\draw (PrecBetter) to node [right] {Invert} (PrecBetterInv);

\node (PrecWorse) [input] [right=of PrecBetter] {Precedence $\PrecWorse$};
\node (PrecWorseInv) [object] [below=of PrecWorse] {$\inv{\PrecWorse}$};
\draw (PrecWorse) to node [right] {Invert} (PrecWorseInv);

\node (PrecDiff) [object] [right=2 of symbol costs] {$\inv{\PrecWorse} - \inv{\PrecBetter}$};
\node (PrecDiffNormalized) [object] [below=of PrecDiff] {Normalized};
\node (PrecPairCost) [object] [below=of PrecDiffNormalized] {Precedence pair cost};
\node (loss) [output] [below=of PrecPairCost] {Loss};

\draw (PrecBetterInv) to (PrecDiff);
\draw (PrecWorseInv) to (PrecDiff);
\draw (PrecDiff) to node [right] {Normalize} (PrecDiffNormalized);
\draw (PrecDiffNormalized) to (PrecPairCost);
\draw (PrecPairCost) to (loss);

\draw (symbol costs) to (PrecPairCost);

\end{tikzpicture}
\end{figure}

Fig.~\ref{fig:SystemOverview}
\todo{MS: Na figures/tables bez referneci v textu se pohlizi obzvlast nelibe. Predpokladam, zes planoval pozdeji popsat, presto zmninuji. Konkretne k Fig.~\ref{fig:SystemOverview}:
Napada me: neslo by precedenci definovat tak, aby uz byla tim $\pi^{-1}$? Invertovani zabira v obrazku skoustu mista, ale pritom
jde o technicky detail a hlavni myslenku nijak neosvetluje...}

\subsection{Symbol cost model}

The symbol costs are modeled by a \gls{rgcn}.\cite{Schlichtkrull2017}
\todo{Can I use the term \gls{rgcn} when I use a modified version? Namely, the activation is called earlier.}
The model is a stack of graph convolutional layers.
Each layer consists of one differentiable module for each edge type.
Each module is a dense layer.
$$
h_i^{(l+1)} =
\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in \mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
$$
\todo{Include dropout?}
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
\todo{FB: Mention inspiration: Transformer. See Straka's slides.}
$h_i^{(l)}$ denotes the embedding of node $i$ at layer $l$.
$\mathcal{R}$ denotes the set of all relations in the graph.
$\sigma$ denotes the activation function, for example the \gls{relu}.
$\mathcal{N}_i^r$ denotes the set of neighbors of node $i$ under relation $r$.
$c_{j, i, r} = \sqrt{\card{\mathcal{N}_j^r}} \sqrt{\card{\mathcal{N}_i^r}}$ is a normalization constant.\cite{kipf2017semisupervised}
$W_r^{(l)}$ is a trainable weight matrix representing relation $r$ at layer $l$.

Residual...
Layer norm...

\todo{MS: neni uplne jiste, ze ``CADE people'' oceni presny zapis 
strutury site, vcetne prvku jako $\mathrm{LayerNorm}$ ve vzorecku.
Nerikam, ze bychom to meli uplne zatajit, ale popis, ktery je zde, spis
patri do appendixu (ML paperu). Na te siti vlastne nic originalniho neni,
tak neni treba vsechno vysvetlit do detailu. Zajimavejsi tu
potom je az to, jak se problem $P$ ``otiskne'' v topologii grafu. 
To uz originalni je (a soutezi to s representacemi jako ta Mirkova)
a popisujes to pak dal.}

\subsection{Loss function} 
\label{sec:loss}

Let $\cnf$ be the set of all \gls{cnf} problems.
Let $P \in \cnf$ be an arbitrary problem.
Let $\signature{P}$ be the signature of $P$.
Let $n = \card{\signature{P}}$.

Given a problem $P$, a symbol cost model 
\todo{MS: Zvidavy invalida Jirka Karasek: a co ze je to ten model? 
Mohl byste to to prosim nekde driv vysvetlit?}
$c : \cnf \to \re^*$
\todo{MS: Mozna by se dalo zbavit lehce podivneho $\re^*$ tim,
ze model bude funkce $(P \in \cnf, s \in \Sigma_P) \to \re$?
Zas pak nepujde pouzivat zapis skalarniho soucinu; hmmm.}
returns a vector of costs of the symbols of $P$:
$$
c(P) = (c_1, \ldots, c_n)
$$

Let $\Prec \in \Perm{n}$ be a precedence of symbols of problem $P$.
Let $k(n) = \frac{2}{n(n+1)}$ be a normalization factor for precedences of length $n$.
The symbol cost model $c$ can be extended to a precedence cost model $C$
by taking the weighted sum of symbol costs:
\begin{equation} \label{eq:model_cost}
C(\Prec | P)
= k(n) \sum_{i=1}^n c_{\Prec_i} \cdot i
= k(n) \sum_{i=1}^n c_i \cdot \inv{\Prec}_i
= k(n) \DotProd{c(P)}{\inv{\Prec}}
\end{equation}
Note that the value of $C$ is minimized by a precedence that orders the symbols by their costs in non-increasing order.
\todo{Discuss, prove.}
\todo{Mention here that minimizing C yields the best precedence.}

Fixing the normalization factor $k(n)$ to the value $\frac{2}{n(n+1)}$
ensures that costs of precedences of various lengths are commensurable.
Observe namely that if $c$ assigns each symbol the same cost $c_0$,
then the precedence cost is equal to $c_0$ irrespective of the signature length $n$:
$$
C(\Prec | P) = \frac{2}{n(n+1)} \sum_{i=1}^n c_0 \cdot i = c_0
$$

Let $\PrecBetter, \PrecWorse \in \Perm{n}$ be two symbol precedences over $P$.
Let $\PrecBetter$ yield a faster proof search on $P$ than $\PrecWorse$, denoted as $\Better{\PrecBetter}{\PrecWorse}$.
The precedence cost model can be extended to predict the probability that $\PrecBetter$ is better than $\PrecWorse$:
\todo{Fix this. Ensure the polarity is sound.}
\todo{MS: zatim chybi vysvetleni $\sigmoid$.}
\todo{MS: duvod proc mi v tomhle kontextu moc nesedi mluvit o pravdepodobnosti
je ten, ze bez dalsiho vysvetlovani to vypada, ze si myslime, ze
kdyz pomoci $\sigmoid$ splacnem v podstate libovolne hodnoty do
intervalu $(0,1)$, zecne to automaticky fungovat jako pravdepodobnost.}
\begin{align*}
p(\Better{\PrecBetter}{\PrecWorse} | P)
&= \sigmoid \SquareBracket{C(\PrecWorse | P) - C(\PrecBetter | P)} \\
%&= \sigmoid \SquareBracket{k(n) \sum_{i=1}^n c_i \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)} \\
&= \sigmoid \SquareBracket{k(n) \DotProd{c(P)}{\inv{\PrecWorse} - \inv{\PrecBetter}}}
\end{align*}
It is easy to see that $p(\Better{\PrecBetter}{\PrecWorse} | P) > 0.5$ if and only if $C(\PrecWorse | P) > C(\PrecBetter | P)$,
and that the value of $p$ can be increased by increasing $C(\PrecWorse | P)$ or decreasing $C(\PrecBetter | P)$.

We consider the difference $C(\PrecWorse | P) - C(\PrecBetter | P)$
to be the "logit"\todo{MS: Logit je taky tezky pojem, urcite ne automaticky znamy u ATP people.} score of the pair of precedences $\PrecBetter, \PrecWorse$,
and denote it by $C(\Better{\PrecBetter}{\PrecWorse} | P)$.

We define the loss of $c$ on the training sample $(\PrecBetter, \PrecWorse, P)$ as binary cross-entropy
with ground truth $\Better{\PrecBetter}{\PrecWorse}$:

\begin{align*}
L(\PrecBetter, \PrecWorse, P)
&= - \log p(\Better{\PrecBetter}{\PrecWorse} | P) \\
&= - \log \sigmoid \SquareBracket{k(n) \DotProd{c(P)}{\inv{\PrecWorse} - \inv{\PrecBetter}}} \\
&= - \log \sigmoid \SquareBracket{k(n) \sum_{i=1}^n c_i \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)}
\end{align*}

The loss is differentiable with respect to the symbol costs:
\begin{align*}
\frac{\partial L}{\partial c_i}
&= -\sigmoid(-C(\Better{\PrecBetter}{\PrecWorse} | P)) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i) \\
&= (p(\Better{\PrecBetter}{\PrecWorse} | P) - 1) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)
\end{align*}

This means that it is possible to backpropagate the loss gradient into the symbol cost model. \todo{MS: tohle bude tezky,
ale ackoliv ML people by tohle uz asi chapali, ATP crowd spis bude
potrebovat obsirnejsi vysvetleni.}

\subsubsection{Generalization}

Note that this approach is generally applicable to all problems where it is necessary to generate permutations of arbitrary length.

\todo[inline]{Finish.}

\subsection{Generating precedences}
\label{sec:generating}

When presented with a \gls{cnf} problem $P$ with signature $\symbols$,
the recommender produces a precedence $\pi$ of symbols from $\symbols$.
\todo{MS: proc nepouzivat znaceni z predchoziho clanku, kdy $P = (\symbols,\mathit{Cl})$?}
In order to generate the precedence,
the recommender first assigns a cost value to each symbol
by invoking a symbol cost model (a trained \gls{gcn}) on a graph representation of $P$.
Ordering the symbols by their predicted costs in nondecreasing order yields the precedence $\pi$.

\subsection{Training}

The training is performed using a fixed \acrlong{atp}.
\todo{MS: zase spis preferuj cinny rod. A klidne muzes proste rict, ze pouzivame vampira :)}
The configuration of the prover,
including for example saturation algorithm, age-weight ratio, and term ordering scheme,
is arbitrary\todo{MS: tohle slovo je prilis silny. Veta by spis mela vysvetlit, ze jsme si neco vybrali, protoze je nam to v postate jedno. Ale zaroven si uvedomujeme, ze to nejak ovlivni vysledek a ze v ultimatnim super-toolu, by se na vsech ostatni paramatrech dalo conditionovat.} and fixed.
The prover needs to support refutational reasoning on \gls{cnf} problems
and use a term simplification ordering parameterized by a symbol precedence.
For example, the \glspl{atp} \vampire{} and E satisfy this requirement.
Note that both of these provers support the \gls{kbo} and \gls{lpo} term simplification ordering schemes,
and that each of these schemes is parameterized by a symbol precedence.
\todo{MS: Jak jsme se o tom bavili; v ramvi Occamovky neni treba zminovat LPO.}

As outlined in \cref{sec:generating},
it is necessary to train a model of symbol costs.
The model is a \gls{gcn}.

\todo[inline]{Include a metagraph and an example graph of a problem.}
\todo[inline]{Compare to HINs}
% https://medium.com/@jason_trost/heterogeneous-information-networks-and-applications-to-cyber-security-23b245461adb

Since it is not obvious what the target symbol cost values should be,
the symbol cost model is not trained directly.
Instead, it is plugged into a classifier that predicts,
given a problem $P$ and a pair of precedences $\pi_0, \pi_1$,
which of the two precedences yields a better performance on $P$.

The symbol cost model is trained by plugging the model into a classifier
that is trained to predict which of a pair of precedences
yields a better performance on an arbitrary problem.

\begin{figure}[ht]
\caption{Architecture overview}
\centering
\digraph[scale=0.4]{precedencepairclassifierdetailed}{
	graph [splines=ortho];
	node [shape=renctangle, fontsize=20];
	edge [fontsize=20];
	fol [label="FOL problem", shape=oval];
	pi0 [shape=oval, label=<&pi;<SUB>0</SUB>>];
	pi1 [shape=oval, label=<&pi;<SUB>1</SUB>>];
	invpi0 [label=<&pi;<SUB>0</SUB><SUP>-1</SUP>>];
	invpi1 [label=<&pi;<SUB>1</SUB><SUP>-1</SUP>>];
	cnf [label="Clause normal form (CNF)"];
	symbolembeddings [label="Symbol embeddings"];
	symbolcosts [label="Symbol costs"];
	pi1pi0 [label="Inverse precedence difference"];
	normalized [label="Normalized inverse precedence difference"];
	paircost [label="Precedence pair cost"];
	fol -> cnf [xlabel=" Vampire "];
	cnf -> symbolembeddings [xlabel=< <B>Graph Convolution Network</B> >];
	symbolembeddings -> symbolcosts [xlabel=< <B>Feed-forward neural network</B> >, style=bold];
	symbolcosts -> paircost [style=bold];
	paircost -> loss [xlabel=" Binary cross-entropy ", style=bold];
	loss [label="Loss", shape=oval];
	pi0 -> invpi0 [xlabel=" Invert "];
	pi1 -> invpi1 [xlabel=" Invert "];
	invpi0 -> pi1pi0;
	invpi1 -> pi1pi0;
	pi1pi0 -> normalized [xlabel=" Normalize "];
	normalized -> paircost;
	symbolprecedence [label="Symbol precedence", style=dashed];
	symbolcosts -> symbolprecedence [xlabel=" Order symbols by their costs ", style=dashed];
}
\end{figure}

\subsection{Layers}
'
\begin{enumerate}
\item Problem -> symbol embeddings
\item Symbol embedding -> symbol cost
\item Symbol costs -> precedence cost
\end{enumerate}

\subsection{Cost models}

%Let $\CostSym: \symbols \rightarrow \re$ be a differentiable symbol cost model.

We define the precedence cost:
$$
\CostPrec(\pi) =
C \sum_{1 \leq i \leq n} \CostSym(\pi(i)) \cdot i =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot \inv{\pi}(s_i)
$$
Precedence cost is minimized by $\pi$ that orders the symbols by their costs in non-increasing order
($\forall (1 \leq i < j \leq n) . (\CostSym(\pi(i)) \geq \CostSym(\pi(j)))$).

Note that we can weight the symbols with an arbitrary nondecreasing function $f$ of symbol index:
$$
\CostPrec(\pi) =
C \sum_{1 \leq i \leq n} \CostSym(\pi(i)) \cdot f(i) =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot f(\inv{\pi}(s_i))
$$

We set $C = \frac{2}{n(n+1)}$ so that $\CostSym(s) = 1$ for all $s$ implies $\CostPrec(\pi) = 1$ for all $\pi$.

% Note that we use this orientation because the TensorFlow metric BinaryCrossentropy classifies 0 as negative and we use the value 0 for "failed to classify" logits.
Given a pair of precedences $\pi_0, \pi_1$,
we define the log-odds of the event "$\pi_0$ is better than $\pi_1$":
$$
\CostPrecPair(\pi_0, \pi_1) =
\CostPrec(\pi_1) - \CostPrec(\pi_0) =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot [\inv{\pi_1}(s_i) - \inv{\pi_0}(s_i)]
$$
Clearly $\CostPrecPair(\pi_0, \pi_1) > 0$ iff $\CostPrec(\pi_0) < \CostPrec(\pi_1)$.
For a pair of precedences about which we know that $\pi_0$ is better than $\pi_1$,
we want $\CostPrecPair(\pi_0, \pi_1) > 0$.

We model the probability of the event ``$\pi_0$ is better than $\pi_1$''
by the sigmoid of $\CostPrecPair(\pi_0, \pi_1)$:
$$
p(\pi_0, \pi_1) = \sigmoid(\CostPrecPair(\pi_0, \pi_1))
$$

We use the binary cross-entropy loss to train the model.
Given a pair of precedences such that $\pi_0$ is better than $\pi_1$,
the loss is as follows:
$$
Loss(\pi_0, \pi_1) = -\log(\sigmoid(\CostPrecPair(\pi_0, \pi_1)))
$$
