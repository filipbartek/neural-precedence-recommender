% !TEX root = main.tex

\todo{Describe problem again, this time precisely / technically.}
\todo{Advantage of using pairs of precedences: we need to solve classification rather than regression.}
\todo{Intuice: snazime se nastavit costy tak, aby co nejvic dvojic dopadlo spravne.}
\todo{Some pairs of precedences are not informative. We hope that the non-systematic examples will cancel each other out.}
\todo{Compare our GCN to Michael, Mirek etc.}

\subsection{System overview}

The precedence recommender is a system that takes
a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$ as the input,
and produces a precedence $\pi^*$ over the symbols $\Sigma$ as the output.
For the recommender to be useful, it needs to produce a precedence
that solves the input problem in a timely fashion.

The recommender described in this section
first computes a cost value for each symbol of the input problem,
and then orders the symbols by their costs in a non-increasing order.
In this manner, the task of finding good precedences is reduced to the task
of finding a good symbol cost function.
Note that the symbol precedence heuristics commonly used in the \glspl{atp}
conform to this general scheme:
they order the symbols by a numeric property, such as arity or number of occurrences.

The architecture is designed so that the recommender can be trained
on the results of \gls{atp} executions on various problems with random precedences.
Since the recommender contains a neural network,
it is parameterized by weight tensors
whose values can be trained by gradient descent.
\todo{Ensure we have defined ``gradient descent''.}
\todo{MS: chapu ucel (a vidim, ze dalsi veta navazuje na ``parameters'', ale je to kostrbate.
Recommender = system, chapu jako program. Programy vetsinou neparametrizujeme tenzorama a gradient descent zije na jine urovni,
nez aby parametrizovane programy primo ucil. Uceni je spis nejaka technologie, kterou recommender pouziva, aby ... ``produces precedences
that are likely to yield a successful proof''.  }
The goal of the training is to find parameter values such that the recommender produces precedences
that are likely to yield a successful proof in as few iterations of the saturation loop as possible.

The recommender consists of modules that perform specific subtasks,
each of which is described in detail in one of the following sections (see also \cref{fig:architecture}):
\begin{itemize}
\item \Cref{sec:graphifier}: Graphifier converts the input \gls{cnf} problem into a problem graph.
\item \Cref{sec:gcn}: \Gls{gcn} converts a problem graph into symbol embeddings.
\todo{MS: Kdyz embeddingy nebudou v preliminaries, je asi OK ctenare, ktery by o nich neslysel, zde trochu vydesit.
Ale v te prislusne podsekci tim zas zacit.}
\item \Cref{sec:output}: An output function \cite{Zhou2018} converts the symbol embeddings into a vector of symbol costs.
\todo{MS: ``output function \cite{Zhou2018}'' my nic nerika, mel bych to znat?\\
FB: Zhou2018 je review GNNs. Output function je termin, ktery se tam pouziva. Ta citace je nejspis tady nepotrebna.}
\item \Cref{sec:ranking}: Sorting converts the symbol costs into a symbol precedence.
It is only used in generating mode.
\item \Cref{sec:training}: Loss function converts the symbol costs and a pair of precedences into a loss value.
It is only used in training mode.
\end{itemize}
\todo{MS: tohle zatim chapu jako predbezny nastrel. Leda by uz pred tim bylo vysvetleno:
embedding, \gls{gcn}/convolution layers, ... \\
FB: Staci predestrit, ze detaily vysvetlim pozdeji? MS: asi jo :)}

\begin{figure}[h]
\caption{Recommender architecture overview.
When recommending a precedence, the input is problem $P$ and the output is precedence $\pi^*$.
When training on an example, the input is problem $P$ and precedences $\pi$ and $\rho$,
and the output is the loss value.}
\label{fig:architecture}
\centering
\digraph[scale=0.4]{ArchitectureOverview}{
graph [splines=ortho,ranksep=0.2];
node [shape=box, fontsize=20];
edge [fontsize=20];

Problem [label="CNF problem P"];
Graphifier [style=rounded, label="Graphifier"];
g [label="Graph"];
GCN [style=rounded, label="GCN"];
SymbolEmbedding [label="Symbol embeddings"];
SymbolCostModel [style=rounded, label="Projection"];
SymbolCost [label="Symbol costs"];
Sort [style=rounded, label="Sort"];
Precedence [label=<Output precedence &pi;*>];

Problem -> Graphifier -> g -> GCN -> SymbolEmbedding -> SymbolCostModel -> SymbolCost -> Sort -> Precedence;

pi [label=<Precedence &pi;>];
rho [label=<Precedence &rho;>];
LossFunction [style=rounded, label="Loss function"];
Loss [label="Loss value"];

pi -> LossFunction;
rho -> LossFunction;
SymbolCost -> LossFunction;
LossFunction -> Loss;
}

\iffalse

\usetikzlibrary{shapes}
\tikzstyle{object} = [rectangle, draw]
\tikzstyle{input} = [ellipse, draw]
\tikzstyle{output} = [ellipse, draw]

\begin{tikzpicture}[node distance = 0.5 and 1, ->]
% https://tex.stackexchange.com/a/332796/202639

\node (problem) [input] {\gls{cnf} problem $P$};
\node (symbol embeddings) [object] [below=of problem] {Symbol embeddings};
\node (symbol costs) [object] [below=of symbol embeddings] {Symbol costs};
\node (symbol precedence) [output] [below=of symbol costs] {Symbol precedence};

\draw (problem) to node [left] {GCN} (symbol embeddings);
\draw (symbol embeddings) to node [left] {MLP} (symbol costs);
\draw (symbol costs) to node [left] {Order symbols by their costs} (symbol precedence);

\node (PrecBetter) [input] [right=of problem] {Precedence $\PrecBetter$};
\node (PrecBetterInv) [object] [below=of PrecBetter] {$\inv{\PrecBetter}$};
\draw (PrecBetter) to node [right] {Invert} (PrecBetterInv);

\node (PrecWorse) [input] [right=of PrecBetter] {Precedence $\PrecWorse$};
\node (PrecWorseInv) [object] [below=of PrecWorse] {$\inv{\PrecWorse}$};
\draw (PrecWorse) to node [right] {Invert} (PrecWorseInv);

\node (PrecDiff) [object] [right=2 of symbol costs] {$\inv{\PrecWorse} - \inv{\PrecBetter}$};
\node (PrecDiffNormalized) [object] [below=of PrecDiff] {Normalized};
\node (PrecPairCost) [object] [below=of PrecDiffNormalized] {Precedence pair cost};
\node (loss) [output] [below=of PrecPairCost] {Loss};

\draw (PrecBetterInv) to (PrecDiff);
\draw (PrecWorseInv) to (PrecDiff);
\draw (PrecDiff) to node [right] {Normalize} (PrecDiffNormalized);
\draw (PrecDiffNormalized) to (PrecPairCost);
\draw (PrecPairCost) to (loss);

\draw (symbol costs) to (PrecPairCost);

\end{tikzpicture}

\fi

\end{figure}
\todo{FB: Improve the diagram. Consider using tikz. See the disabled tikz figure in the source file.}

\subsection{From \gls{cnf} to graphs}
\label{sec:graphifier}

As the first step of the recommender processing pipeline,
the input problem is converted from a \gls{cnf} representation
to a \emph{heterogeneous (directed) graph} \cite{Zhou2018}.
% Zhou uses the term "heterogeneous graph".
%\footnote{Data mining literature often uses the term \gls{hin} \cite{Shi2015} for heterogeneous graphs.
%We prefer to conform to the terminology common in literature studying \glspl{gnn}.}
Each of the nodes of the graph is labeled with a node type,
and each edge is labeled with an edge type,
defining the heterogeneous nature of the graph.
Each node corresponds to one of the elements that constitute the \gls{cnf} formula,
such as a clause, an atom or a predicate symbol.
Each such category of elements corresponds to one node type.
The edges represent the (oriented) relations between the elements,
for example the incidence relation between a clause and one of its (literals') atoms,
or the relation between an atom and its predicate symbol.
$\mathcal{R}$ denotes the set of all relations in the graph.
\Cref{fig:CnfSchema} shows the types of nodes and edges used in our graph representation.
\Cref{fig:GcnExample} shows an example of a graph representation of a simple problem.

\newcommand{\ntype}[1]{\texttt{#1}}
\newcommand{\etype}[1]{\texttt{#1}}
\newcommand{\epos}{\etype{pos}}
\newcommand{\eneg}{\etype{neg}}

\begin{figure}[h]
\caption{CNF network schema}
\label{fig:CnfSchema}
\centering
\tikzstyle{token} = [rectangle, draw]

\begin{tikzpicture}[node distance = 1 and 2, ->]
% https://tex.stackexchange.com/a/332796/202639

% Node and edge types:
% https://docs.google.com/spreadsheets/d/1PCPHEgk6vLxpdpcvB_PGoLx7p4DID6WtvVWy2mDuv4A/edit?usp=sharing

\node (formula) [token] {\ntype{problem}};
% TODO: Consider removing the Formula nodes.
\node (clause) [token, below=of formula] {\ntype{clause}};
\node (atom) [token, below left=of clause] {\ntype{atom}};
\node (equality) [token, below right=of clause] {\ntype{equality}};
\node (predicate) [token, left=of atom] {\ntype{predicate}};
\node (argument) [token, below=of atom] {\ntype{argument}};
\node (term) [token, below=of argument] {\ntype{term}};
\node (function) [token, left=of term] {\ntype{function}};
\node (variable) [token, right=of term] {\ntype{variable}};

\draw (formula) to node [right] {\etype{contains}} (clause);
\draw (clause) to [bend right] node [above] {\epos{}} (atom);
\draw (clause) to [bend left] node [below] {\eneg{}} (atom);
\draw (clause) to [bend left] node [above] {\epos{}} (equality);
\draw (clause) to [bend right] node [below] {\eneg{}} (equality);
\draw (clause) to node [above] {\etype{binds}} (variable);
\draw (atom) to node [above] {\etype{atom\_applies}} (predicate);
\draw (atom) to node [left] {\etype{atom\_has}} (argument);
\draw (equality) to node {\etype{equalizes}} (term);
\draw (equality) to node {\etype{equalizes}} (variable);
\draw (argument) to [bend right] node [left] {\etype{is}} (term);
\draw (argument) to [loop left] node [left] {\etype{precedes}} (argument);
\draw (argument) to node [below] {\etype{is}} (variable);
\draw (term) to node [above] {\etype{term\_applies}} (function);
\draw (term) to [bend right] node [right] {\etype{term\_has}} (argument);

\end{tikzpicture}
\end{figure}

\begin{figure}[h]
\caption{Graph representation of the \gls{cnf} formula $a=b \wedge f(a,b) \neq f(b,b)$.}
\label{fig:GcnExample}
\centering
\digraph[scale=0.3]{GcnExample}{
	node [fontsize=32, shape=record];
	edge [fontsize=32, dir=both, arrowtail=empty];
	problem [label=<problem|a=b &and; f(a,b)&ne;f(b,b)>];
	c0 [label="clause|a=b"];
	c1 [label=<clause|f(a,b)&ne;f(b,b)>];
	problem -> c0;
	problem -> c1;
	t0 [label="equality atom|a=b"];
	t1 [label="equality atom|f(a,b)=f(b,b)"];
	c0 -> t0 [label=" + "];
	c1 -> t1 [label=" &ndash; "];
	ta [label="term|a"];
	tb [label="term|b"];
	ff [label="function|f", style=bold];
	fa [label="function|a", style=bold];
	fb [label="function|b", style=bold];
	tfab [label="term|f(a,b)"];
	tfbb [label="term|f(b,b)"];
	tfab0 [label="argument|1", style=dotted];
	tfab1 [label="argument|2", style=dotted];
	tfbb0 [label="argument|1", style=dotted];
	tfbb1 [label="argument|2", style=dotted];
	t0 -> ta;
	t0 -> tb;
	t1 -> tfab;
	t1 -> tfbb;
	tfab -> ff;
	tfab -> tfab0;
	tfab0 -> tfab1;
	tfab0 -> ta;
	tfab1 -> tb;
	tfbb -> ff;
	tfbb -> tfbb0;
	tfbb0 -> tfbb1;
	tfbb0 -> tb;
	tfbb1 -> tb;
	ta -> fa;
	tb -> fb;
}
\end{figure}

The graph representation has the following properties:
\begin{itemize}
\item Lossless: The original problem can be faithfully reconstructed from the corresponding graph representation
(up to logical equivalence).
\item Signature agnostic: Renaming the symbols and variables in the input problem yields an isomorphic graph.
\item For each relation $r \in \mathcal{R}$, its inverse $\inv{r}$ is also present in the graph,
typically represented by a different edge type.
\todo{MS: tohle jsem nepochopil. Nemuzeme rict, ze (az na nejakou vyjimkou) jsou edges v obou smerech?\\
FB: Chci vyjasnit, ze inverzni edge ma jiny edge type.}
\item A singleton node of type \ntype{problem} is connected to all the clauses of the problem.
\item The polarity of the literals is expressed by the type of the edge (\epos{} or \eneg{})
connecting the respective atom to the clause it occurs in.
\item For every non-equality atom and term, the order of its arguments is captured by a sequence of \ntype{argument} nodes chained by edges \cite{Rawson2020}.
\item The two operands of equality are not ordered.
This reflects the symmetry of equality.
\item Perfect sub-expression sharing:
\todo{MS: Predpokladam ze dva ruzne ground literaly p(c) tam budou taky jen jendnou?\\
FB: Literaly nemaji nody. Atomy maji nody a polarita literalu je zakodovana v typu hrany, ktery jej spojuje s klauzuli.
MS: O to my, neslo. Slo o to, jestli se sdily ground termy mezi klauzulemi, ted uz dobry! :)}
Redundant atoms and terms share a node representation.
\todo{FB: Cite some text about sub-expression sharing. Perhaps Rawson2020?}
\todo{MS: Ale mezitim se to tu zmenilo a ja prestavam chapat, co je ``Redundant''.}
Note that since each variable is bound by a clause,
ground terms are shared across clauses,
but non-ground terms are only shared within the context of a clause.
\todo{FB: Remove as of little interest?}
\end{itemize}
\todo{FB: Reference appendix if we describe the representation in more detail there.}
\todo[inline]{MS: Filosoficka k ``can be represented''; mozna by se mohlo nekde objevit:
Snazime se do struktury HIN ``otisknout'' celou strukturu CNF (jak jsem rikal,
znamena to, ze zobrazeni je proste), abychom siti nevzali moznost ``vedet o problemu
uplne vsechno'' (az na veci, na kterych nezalezi jako poradi literaly v klauzulich, etc).
Ta filosoficka poznamka je o tom, ze pro dobre uceni tohle vlastne vubec nemusi byt treba,
ze nejaky ``hrubsi otisk'' by mohl stacit tez (a byt treba mensi), ale my nevime, jak takovy zvolit.\\
FB: Zkusim to popsat, kdyz zbyde cas.}
\todo{FB: Mention other encodings that have been proposed by Mirek and Michael.}

\subsection{\Gls{gcn}: From graphs to symbol embeddings}
\label{sec:gcn}

For each symbol in the input problem $P$,
we seek to find a vector representation, i.e., an \emph{embedding},
that captures the symbol's properties that are relevant
for correctly ranking the symbol in the symbol precedences over $P$.

The symbol embeddings are output by a \gls{rgcn} \cite{Schlichtkrull2017},
which is a stack of \emph{graph convolutional layers}.
Each layer consists of a collection of differentiable modules---one module per edge type.
The computation of the \gls{gcn} starts with assigning each node an initial embedding
and then iteratively updates the embeddings by passing them through the convolutional layers.
\todo{FB: Ensure terms are clear (preferably defined): embedding, vector, trainable vector, feature vector.
MS: (convolutional, layers, ...)}

The initial embedding $h_a^{(0)}$ of a node $a$ is a concatenation of two vectors:
a \emph{feature vector} specific for that node (typically empty)
and a trainable vector shared by all nodes of the same type.
In our particular implementation,
feature vectors are used in nodes that correspond to clauses and symbols.
Each clause node has a feature vector with a one-hot encoding of the role of the clause,
which can be either axiom, assumption, or negated conjecture \cite{TptpSyntax,Sutcliffe2017}.
Each symbol node has a feature vector with two bits of data:
whether the symbol was introduced into the problem during preprocessing,
and whether the symbol appears in a conjecture clause.

One pass through the convolutional layer
updates the node embeddings by passing a message along each of the edges.
For an edge of type $r \in \mathcal{R}$ going from source node $s$ to destination node $d$ at layer $l$,
the message is composed by converting the embedding of the source node $h_s^{(l)}$
using the module associated with the edge type $r$.
In the simple case that the module is a fully connected layer with weight matrix $W_r^{(l)}$ and bias vector $b_r^{(l)}$,
the message is $W_r^{(l)} h_s^{(l)} + b_r^{(l)}$.
% Notation is from Kipf: RGCN paper.
Each message is then divided by the normalization constant
$c_{s,d} = \sqrt{\card{\mathcal{N}_s^r}} \sqrt{\card{\mathcal{N}_d^r}}$ \cite{kipf2017semisupervised},
where $\mathcal{N}_a^r$ is the set of neighbors of node $a$ under the relation $r$.
\todo{FB: Mention that we mean both in- and out-neighbors?}

Once all the messages are computed,
they are aggregated at the destination nodes to form the new node embeddings.
Each node $d$ aggregates all the incoming messages of a given edge type $r$ by summation,
then passes the sum through an activation function $\sigma$ such as the \gls{relu},
and finally aggregates the messages across the edge types by summation,
yielding the new embedding $h_d^{(l+1)}$.

The following formula captures the complete update of embedding of node $d$ by layer $l$:
$$
h_d^{(l+1)} =
\sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{s \in \mathcal{N}_d^r} \frac{1}{c_{s,d}} (W_r^{(l)} h_s^{(l)} + b_r^{(l)})}
$$
\todo{FB: Include LayerNorm and Residual if we end up using them.}
%$$
%h_i^{(l+1)} =
%\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in %\mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
%$$
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
%\todo{FB: Mention inspiration: Transformer. See Straka's slides.}

\todo[inline]{MS: neni uplne jiste, ze ``CADE people'' oceni presny zapis 
strutury site, vcetne prvku jako $\mathrm{LayerNorm}$ ve vzorecku.
Nerikam, ze bychom to meli uplne zatajit, ale popis, ktery je zde, spis
patri do appendixu (ML paperu). Na te siti vlastne nic originalniho neni,
tak neni treba vsechno vysvetlit do detailu. Zajimavejsi tu
potom je az to, jak se problem $P$ ``otiskne'' v topologii grafu. 
To uz originalni je (a soutezi to s representacemi jako ta Mirkova)
a popisujes to pak dal.}

\subsection{Output layer: From symbol embeddings to symbol costs}
\label{sec:output}
% Terminology: Deep Learning Book

The symbol cost of each symbol is computed by passing the symbol's embedding through a linear output unit,
which is an affine transformation with no activation function.
\todo{FB: Is this clear at this point?}

It is possible to use a more complex output layer in place of the linear unit,
e.g., a feedforward network with one or more hidden layers.
Our experiments showed no significant improvement when a hidden layer was added,
likely because the underlying \gls{gcn} learns a sufficiently complex transformation.

Let $\theta$ denote the vector of all the parameters of the whole \acrlong{nn} consisting of the \gls{gcn} and the output unit.
Given an input problem $P$ with signature $\Sigma = (s_1, \ldots, s_n)$,
we denote the cost of symbol $s_i$ predicted by the \acrlong{nn} as $c(i, P; \theta)$.
In the rest of this text,
we refer to the predicted cost of $s_i$ simply as $c(i)$
because the problem $P$ and the parameters $\theta$ are fixed in each respective context.

\subsection{Sorting: From symbol costs to precedence}
\label{sec:ranking}

\subsubsection{Precedence cost}
We extend the notion of cost from symbols to precedences
by summing up the symbol costs
weighted by their positions in the given precedence $\pi$:
$$
C(\pi) = Z_n \sum_{i=1}^n i \cdot c(\pi(i))
% We call the normalization factor Z_n to follow convention from Foundations of Machine Learning, p. 122.
$$
$Z_n = \frac{2}{n(n+1)}$ is a normalization factor
that ensures the commensurability of precedence costs across signature sizes.
More precisely, normalizing by $Z_n$ makes the expected value of precedence cost
independent of the signature size $n$:
\begin{align*}
\mathbb{E}_\pi [C(\pi)]
&= \mathbb{E}_\pi \SquareBracket{Z_n \sum_{i=1}^n i \cdot c(\pi(i))} \\
&= Z_n \sum_{i=1}^n i \cdot \mathbb{E}_{\pi, i} [c(\pi(i))] \\
&= Z_n \Parentheses{\sum_{i=1}^n i} \mathbb{E}_i [c(i)] \\
&= \frac{2}{n(n+1)} \frac{n(n+1)}{2} \mathbb{E}_i [c(i)] \\
&= \mathbb{E}_i [c(i)]
\end{align*}
\todo{FB: Consider making the background problem explicit by using $C(\pi|P)$ or $C(\pi,P)$.}
\todo[inline]{FB: Consider accessing elements $\pi$ as vector elements $\pi_i$ instead of $\pi(i)$. Keep in mind that $\inv{\pi}$ must be updated as well. The motivation for using $\pi(i)$ is that $\inv{\pi}(i)$ looks clearer than $\inv{\pi}_i$. How about using $(\inv{\pi})_i$? We may also omit the inversion completely.}

\subsubsection{Cost minimization by sorting}
\begin{lemma}
Precedence cost $C$ is minimized by the precedence that sorts the symbols by their costs in non-increasing order:
$$
\argmin_\pi C(\pi) \in \argsort^- (c(1), \ldots, c(n))
$$
where $\argsort^-(x)$ is the set of all permutations $\rho$ that sort vector $x$ in non-increasing order ($x_{\rho(1)} \geq x_{\rho(2)} \geq \ldots \geq x_{\rho(n)}$).
\end{lemma}

\begin{proof}
We prove the lemma by contradiction.
Let $\pi$ minimize $C$ and let $\pi$ not sort the costs in non-increasing order.
Then there exist $k < l$ such that $c(\pi(k)) < c(\pi(l))$.
Let $\bar{\pi}$ be a precedence obtained from $\pi$ by swapping the elements $k$ and $l$.
Then we obtain
%$\bar{\pi} = (\pi(1), \ldots, \pi(k-1), \pi(l), \pi(k+1), \ldots, \pi(l-1), \pi(k), \pi(l+1), \ldots, \pi(n))$.
\begin{align*}
\frac{C(\bar{\pi}) - C(\pi)}{Z_n}
&= kc(\bar{\pi}(k)) + lc(\bar{\pi}(l)) - kc(\pi(k)) - lc(\pi(l)) \\
&= kc(\pi(l)) + lc(\pi(k)) - kc(\pi(k)) - lc(\pi(l)) \\
&= k(c(\pi(l)) - c(\pi(k))) - l(c(\pi(l)) - c(\pi(k))) \\
&= (k-l) (c(\pi(l)) - c(\pi(k))) \\
&< 0
\end{align*}
\todo{FB: Isn't the inclusion of $Z_n$ too confusing?}
The final inequality is because $k-l < 0$ and $c(\pi(l)) - c(\pi(k)) > 0$.
Clearly, $Z_n > 0$ for any $n \geq 0$.
Thus, $C(\bar{\pi}) < C(\pi)$, which is contradicts the assumption that $\pi$ minimizes $C$. \qed
\end{proof}

Once the symbol costs are known,
producing a precedence that minimizes the precedence cost is cheap
because sorting is a fast operation.

Note that a precedence that minimizes $C$
orders the symbols with the lowest cost as the last, prioritizing them for early inferences.

\todo[inline]{FB: Why is the equality predicate always the first in the precedence?
MS: Andrei Voronokov reasons. It's typically better in practice to postpone equational reasoning,
so we want equalities to be generally small.}
\todo[inline]{FB: Mention that the common heuristics fit this scheme.}

\subsection{Training}
\label{sec:training}

In \cref{sec:graphifier,sec:gcn,sec:output,sec:ranking} we described the structure of a recommender system that generates a precedence for an arbitrary input problem.
The efficacy of the recommender depends on the quality of the underlying symbol cost function.
In theory, the symbol cost function can assign the costs so that
sorting the symbols by their costs yields an optimum precedence.
Furthermore, all the information necessary to determine the optimum precedence is present in the graph representation of the input problem
thanks to the lossless property of the graph encoding mentioned before.
\todo{MS: Hlavne tady ale jakoby chybi druha pulky ty vety. Neco jako ``In practice, however, ...'' Nemyslis?} 
Our approach to defining an appropriate symbol cost function is based on statistical learning
from executions of an \gls{atp} on a set of problems with random precedences.

Our ultimate goal is to train the precedence cost function $C$ so that it is minimized by the best precedence,
measuring the quality of a precedence by the number of iterations of the saturation loop taken to solve the problem.
Since the number of possible precedences grows with the factorial of the signature size,
it is not feasible to determine the best precedence conclusively on most practical problems.
Instead of learning to classify one or more precedences on each problem as the best,
we train the system to decide which of a pair of arbitrary precedences is better.
We do this by training $C$ so that better precedences are assigned lower costs.
The motivation for learning to order pairs of precedences
is that it may allow the system to generalize to precedences that are better than any of those seen during training.
\todo{FB: We should test this hypothesis by training on one problem in isolation.}
\todo{FB: Argue better.}

\subsubsection{Training data}

Each training example has the form $(P, \PrecBetter, \PrecWorse)$,
where $P = (\Sigma, \mathit{Cl})$ is a problem
and $\PrecBetter, \PrecWorse$ are precedences over $\Sigma$
such that the prover using $\PrecBetter$ solves $P$ in fewer iterations of the saturation loop than with $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}{P}$.
\todo{FB: Is this sufficient?}
\todo{FB: Describe the distribution of problems and precedences.}

\subsubsection{Loss function}

Let $(P, \PrecBetter, \PrecWorse)$ be a training example ($\Better{\PrecBetter}{\PrecWorse}{P}$).
The precedence cost classifies this example correctly if $C(\PrecBetter) < C(\PrecWorse)$,
or alternatively $S(\PrecBetter, \PrecWorse) = C(\PrecWorse) - C(\PrecBetter) > 0$.
% We have positive S score for correctly predicted examples.
% The loss function transorms that into a loss value close to 0.
We approach this problem as an instance of binary classification with the logistic loss \cite{Mohri2018},
% p. 128
a loss function routinely used in classification tasks in \acrlong{ml}:
\todo[inline]{MS: First mention of a ``binary classifier''!
We classify the examples, sure, but you did not say it yet.\\
FB: Is it ok to mention binary classification for the first time here if we cite \cite{Mohri2018} immediately?}
\todo[inline]{MS: [...] pisem
``binary'' a ``classification'' a neni tu jasny, co je ``binary''
a co jsou ``classes''. Z pohledu ctenare, ktery o tom zatim neslysel, se misto ``binary classficiation model'' mohlo
psat ``housenka'' a vyslo by to pro nej na stejno.}
\begin{align*}
\loss(P, \PrecBetter, \PrecWorse)
&= - \log \sigmoid S(\PrecBetter, \PrecWorse) \\
&= - \log \sigmoid (C(\PrecWorse) - C(\PrecBetter)) \\
&= - \log \sigmoid Z_n \sum_{i=1}^n i (c(\PrecWorse(i)) - c(\PrecBetter(i))) \\
&= - \log \sigmoid Z_n \sum_{i=1}^n c(i) (\inv{\PrecWorse}(i) - \inv{\PrecBetter}(i))
\end{align*}
% FB: Note: I have included the full expansion to make it visible how the loss depends on $c$.
% To a skilled NN practitioner, it should now be obvious that the loss is differentiable w.r.t. $c$.

Note that the classifier cannot simply train $S$ to output a positive number on all pairs of precedences
because $S$ is defined as a difference of two precedence costs.
Intuitively, by training on the example $(P, \PrecBetter, \PrecWorse)$
we are pushing $C(\PrecBetter)$ down and $C(\PrecWorse)$ up.

The loss function is clearly differentiable with respect to the symbol costs,
\todo{Shall we include the derivative?}
and the symbol cost function $c$ is differentiable with respect to its trainable parameters.
This enables the use of gradient descent to find the values of the parameters of $c$
that minimize the loss value.
