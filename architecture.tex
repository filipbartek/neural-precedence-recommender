% !TEX root = main.tex

The precedence recommender is a system that takes
a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$ as the input,
and produces a precedence $\pi^*$ over the symbols $\Sigma$ as the output.
For the recommender to be useful, it needs to produce a precedence
that is likely to yield a proof in as few iterations of the saturation loop as possible.

The recommender described in this section
first uses a neural network to compute a cost value for each symbol of the input problem,
and then orders the symbols by their costs in a non-increasing order.
In this manner, the task of finding good precedences is reduced to the task
of training a good symbol cost function,
as discussed in \cref{sec:training}.
%The architecture is designed so that the recommender can be trained
%on the results of \gls{atp} executions on various problems with random precedences.
%Since the recommender contains a neural network,
%it is parameterized by weight tensors
%whose values can be trained by gradient descent.

The recommender consists of modules that perform specific subtasks,
each of which is described in detail in one of the following\iftoggle{LONG}{
sections (see also \cref{fig:architecture}):
\begin{itemize}
\item \Cref{sec:graphifier}: The graph constructor transforms the input \gls{cnf} problem into a problem graph.
\item \Cref{sec:gcn}: The \gls{gcn} computes symbol embeddings from the problem graph.
\item \Cref{sec:output}: The output layer extracts symbol costs from the symbol embeddings.
\item \Cref{sec:sorting}: The final symbol precedence is obtained by sorting the symbols by their costs.
\end{itemize}
}{
sections (see also \cref{fig:architecture}).
}

\begin{figure}[h]
\caption{Recommender architecture overview.
When recommending a precedence, the input is problem $P$ and the output is precedence $\pi^*$.
When training, the input is problem $P$ and precedences $\pi$ and $\rho$,
and the output is the loss value.
The trainable modules and the edges along which the loss gradient is propagated are emphasized by bold lines.}
\label{fig:architecture}
\centering
\digraph[scale=0.5]{ArchitectureOverview}{
graph [splines=ortho, ranksep=0.25];
node [shape=box, fontsize=14, width=0, height=0];

{ rank = same;
Problem [label="Problem P"];
pi [label=<Precedence &pi;>];
rho [label=<Precedence &rho;>];
}

Graphifier [style=rounded, label="Graph constructor"];
g [label="Graph"];
GCN [style=<rounded,bold>, label="GCN"];
SymbolEmbedding [label="Symbol embeddings"];
SymbolCostModel [style=<rounded,bold>, label="Output layer"];
SymbolCost [label="Symbol costs"];

{ rank = same;
Sort [style=rounded, label="Sort"];
LossFunction [style=rounded, label="Loss function"];
}

{ rank = same;
Precedence [label=<Precedence &pi;*>];
Loss [label="Loss value"];
}

Problem -> Graphifier -> g -> GCN;
GCN -> SymbolEmbedding -> SymbolCostModel -> SymbolCost [style=bold];
SymbolCost -> Sort;
Sort -> Precedence;

pi -> LossFunction:nw;
rho -> LossFunction:ne;
SymbolCost -> LossFunction [style=bold];
LossFunction -> Loss [style=bold];
}

\iffalse

\usetikzlibrary{shapes}
\tikzstyle{object} = [rectangle, draw]
\tikzstyle{input} = [ellipse, draw]
\tikzstyle{output} = [ellipse, draw]

\begin{tikzpicture}[node distance = 0.5 and 1, ->]
% https://tex.stackexchange.com/a/332796/202639

\node (problem) [input] {\gls{cnf} problem $P$};
\node (symbol embeddings) [object] [below=of problem] {Symbol embeddings};
\node (symbol costs) [object] [below=of symbol embeddings] {Symbol costs};
\node (symbol precedence) [output] [below=of symbol costs] {Symbol precedence};

\draw (problem) to node [left] {GCN} (symbol embeddings);
\draw (symbol embeddings) to node [left] {MLP} (symbol costs);
\draw (symbol costs) to node [left] {Order symbols by their costs} (symbol precedence);

\node (PrecBetter) [input] [right=of problem] {Precedence $\PrecBetter$};
\node (PrecBetterInv) [object] [below=of PrecBetter] {$\inv{\PrecBetter}$};
\draw (PrecBetter) to node [right] {Invert} (PrecBetterInv);

\node (PrecWorse) [input] [right=of PrecBetter] {Precedence $\PrecWorse$};
\node (PrecWorseInv) [object] [below=of PrecWorse] {$\inv{\PrecWorse}$};
\draw (PrecWorse) to node [right] {Invert} (PrecWorseInv);

\node (PrecDiff) [object] [right=2 of symbol costs] {$\inv{\PrecWorse} - \inv{\PrecBetter}$};
\node (PrecDiffNormalized) [object] [below=of PrecDiff] {Normalized};
\node (PrecPairCost) [object] [below=of PrecDiffNormalized] {Precedence pair cost};
\node (loss) [output] [below=of PrecPairCost] {Loss};

\draw (PrecBetterInv) to (PrecDiff);
\draw (PrecWorseInv) to (PrecDiff);
\draw (PrecDiff) to node [right] {Normalize} (PrecDiffNormalized);
\draw (PrecDiffNormalized) to (PrecPairCost);
\draw (PrecPairCost) to (loss);

\draw (symbol costs) to (PrecPairCost);

\end{tikzpicture}

\fi

\end{figure}
\todo{FB: Improve the diagram. Consider using tikz. See the disabled tikz figure in the source file.}
\todo[author=R2]{The small bold arrows are quite difficult to distinguish from the small non-bold arrows.}

\subsection{Graph constructor: From \gls{cnf} to graphs}
\label{sec:graphifier}

As the first step of the recommender processing pipeline,
the input problem is converted from a \gls{cnf} representation
to a \emph{heterogeneous (directed) graph} \cite{Zhou2018}.
% Zhou uses the term "heterogeneous graph".
%\footnote{Data mining literature often uses the term \gls{hin} \cite{Shi2015} for heterogeneous graphs.
%We prefer to conform to the terminology common in literature studying \glspl{gnn}.}
Each of the nodes of the graph is labeled with a node type,
and each edge is labeled with an edge type,
defining the heterogeneous nature of the graph.
Each node corresponds to one of the elements that constitute the \gls{cnf} formula,
such as a clause, an atom or a predicate symbol.
Each such category of elements corresponds to one node type.
The edges represent the (oriented) relations between the elements,
for example the incidence relation between a clause and one of its (literals') atoms,
or the relation between an atom and its predicate symbol.
$\mathcal{R}$ denotes the set of all relations in the graph.
\Cref{fig:CnfSchema} shows the types of nodes and edges used in our graph representation.
\Cref{fig:GcnExample} shows an example of a graph representation of a simple problem.

\newcommand{\ntype}[1]{\texttt{#1}}
\newcommand{\etype}[1]{\texttt{#1}}
\newcommand{\epos}{\etype{pos}}
\newcommand{\eneg}{\etype{neg}}

\begin{figure}[h]
\caption{\gls{cnf} graph schema}
\label{fig:CnfSchema}
\centering

\digraph[scale=0.5]{CnfSchema}{
graph [ranksep=0.3];
node [fontsize=14, shape=box, height=0, width=0];
edge [fontsize=14];

problem;
clause;
%{ rank = same;
predicate;
atom;
equality;
%}
argument;
term;
function;
variable;

problem -> clause [label=< contains >];
clause -> atom:nw [label=< pos >];
clause -> atom:ne [label=< neg >];
clause -> equality:nw [label=< pos >];
clause -> equality:ne [label=< neg >];
clause -> variable [label=< binds >];
atom -> predicate [label=< atom_applies>];
atom -> argument [label=< atom_has >];
equality -> term [label=< equalizes >];
equality -> variable [label=< equalizes >];
argument -> argument [label=< precedes >];
argument -> term [label=< is >];
argument -> variable [label=< is >];
term -> argument [label=< term_has >];
term -> function [label=< term_applies >];
}

\iffalse
\tikzstyle{token} = [rectangle, draw]

\begin{tikzpicture}[node distance = 1 and 2, ->]
% https://tex.stackexchange.com/a/332796/202639

% Node and edge types:
% https://docs.google.com/spreadsheets/d/1PCPHEgk6vLxpdpcvB_PGoLx7p4DID6WtvVWy2mDuv4A/edit?usp=sharing

\node (formula) [token] {\ntype{problem}};
% TODO: Consider removing the Formula nodes.
\node (clause) [token, below=of formula] {\ntype{clause}};
\node (atom) [token, below left=of clause] {\ntype{atom}};
\node (equality) [token, below right=of clause] {\ntype{equality}};
\node (predicate) [token, left=of atom] {\ntype{predicate}};
\node (argument) [token, below=of atom] {\ntype{argument}};
\node (term) [token, below=of argument] {\ntype{term}};
\node (function) [token, left=of term] {\ntype{function}};
\node (variable) [token, right=of term] {\ntype{variable}};

\draw (formula) to node [right] {\etype{contains}} (clause);
\draw (clause) to [bend right] node [above] {\epos{}} (atom);
\draw (clause) to [bend left] node [below] {\eneg{}} (atom);
\draw (clause) to [bend left] node [above] {\epos{}} (equality);
\draw (clause) to [bend right] node [below] {\eneg{}} (equality);
\draw (clause) to node [above] {\etype{binds}} (variable);
\draw (atom) to node [above] {\etype{atom\_applies}} (predicate);
\draw (atom) to node [left] {\etype{atom\_has}} (argument);
\draw (equality) to node {\etype{equalizes}} (term);
\draw (equality) to node {\etype{equalizes}} (variable);
\draw (argument) to [bend right] node [left] {\etype{is}} (term);
\draw (argument) to [loop left] node [left] {\etype{precedes}} (argument);
\draw (argument) to node [below] {\etype{is}} (variable);
\draw (term) to node [above] {\etype{term\_applies}} (function);
\draw (term) to [bend right] node [right] {\etype{term\_has}} (argument);

\end{tikzpicture}
\fi

\end{figure}
\todo{FB: Clean up the diagram.}

\begin{figure}[h]
\caption{Graph representation of the \gls{cnf} formula $a=b \wedge f(a,b) \neq f(b,b)$.}
\label{fig:GcnExample}
\centering
\digraph[scale=0.5]{GcnExample}{
graph [ranksep=0.3];
node [fontsize=14, shape=record, height=0, width=0];
edge [fontsize=14, dir=both, arrowtail=empty];

problem [label=<problem|a=b &and; f(a,b)&ne;f(b,b)>];

{ rank = same;
c0 [label="clause|a=b"];
c1 [label=<clause|f(a,b)&ne;f(b,b)>];
}

problem -> c0;
problem -> c1;

{ rank = same;
t0 [label="equality atom|a=b"];
t1 [label="equality atom|f(a,b)=f(b,b)"];
}

c0 -> t0 [label=" + "];
c1 -> t1 [label=" &ndash; "];

{ rank = same;
tfab [label="term|f(a,b)"];
tfbb [label="term|f(b,b)"];
}

{ rank = same;
ta [label="term|a"];
tb [label="term|b"];
}

ff [label="function|f", style=bold];
fa [label="function|a", style=bold];
fb [label="function|b", style=bold];
tfab0 [label="argument|1", style=dotted];
tfab1 [label="argument|2", style=dotted];
tfbb0 [label="argument|1", style=dotted];
tfbb1 [label="argument|2", style=dotted];
t0 -> ta;
t0 -> tb;
t1 -> tfab;
t1 -> tfbb;
tfab -> ff;
tfab -> tfab0;
tfab0 -> tfab1;
tfab0 -> ta;
tfab1 -> tb;
tfbb -> ff;
tfbb -> tfbb0;
tfbb0 -> tfbb1;
tfbb0 -> tb;
tfbb1 -> tb;
ta -> fa;
tb -> fb;

% Technical details:
%ff -> ff [dir=forward];
%fa -> fa [dir=forward];
%fb -> fb [dir=forward];
}
\end{figure}
\todo[author=R2]{There are unneeded differences in the notations used in the two figures; for example, pos/neg vs +/-, equality vs equality atom, the various (and non-specified) types of boxes around the nodes in fig. 3...}

The graph representation has the following properties:
\begin{itemize}
\item Lossless: The original problem can be faithfully reconstructed from the corresponding graph representation
(up to logical equivalence).
\item Signature agnostic: Renaming the symbols and variables in the input problem yields an isomorphic graph.
\item For each relation $r \in \mathcal{R}$, its inverse $\inv{r}$ is also present in the graph,
typically\todo{MS: jaka je vyjimka?} represented by a different edge type.
\todo{MS: tohle jsem nepochopil. Nemuzeme rict, ze (az na nejakou vyjimkou) jsou edges v obou smerech?\\
FB: Chci vyjasnit, ze inverzni edge ma jiny edge type.}
%\item A singleton node of type \ntype{problem} is connected to all the clauses of the problem.
\item The polarity of the literals is expressed by the type of the edge (\epos{} or \eneg{})
connecting the respective atom to the clause it occurs in.
\item For every non-equality atom and term, the order of its arguments is captured by a sequence of \ntype{argument} nodes chained by edges \cite{Rawson2020}.
\item The two operands of equality are not ordered.
This reflects the symmetry of equality.
\item Sub-expression sharing \cite{Chvalovsky2019,Olsak2019,Rawson2020}:
\todo[inline]{MS: (Almost)}
\todo[inline]{MS: Predpokladam ze dva ruzne ground literaly p(c) tam budou taky jen jendnou?\\
FB: Literaly nemaji nody. Atomy maji nody a polarita literalu je zakodovana v typu hrany, ktery jej spojuje s klauzuli.
MS: O to my, neslo. Slo o to, jestli se sdily ground termy mezi klauzulemi, ted uz dobry! :)}
Identical atoms and terms share a node representation.
\todo{FB: Cite some text about sub-expression sharing. Perhaps Rawson2020?}
\todo{MS: Ale mezitim se to tu zmenilo a ja prestavam chapat, co je ``Redundant''!}
%Note that since each variable is bound by a clause,
%ground terms are shared across clauses,
%but non-ground terms are only shared within the context of a clause.
\todo{FB: Remove as of little interest?}
\end{itemize}
\todo{FB: Reference appendix if we describe the representation in more detail there.}
\todo{FB: Mention other encodings that have been proposed by Mirek and Michael and compare ours to theirs.}

\subsection{\Gls{gcn}: From graphs to symbol embeddings}
\label{sec:gcn}

For each symbol in the input problem $P$,
we seek to find a vector representation, i.e., an \emph{embedding},
that captures the symbol's properties that are relevant
for correctly ranking the symbol in the symbol precedences over $P$.

The symbol embeddings are output by a \gls{rgcn} \cite{Schlichtkrull2017},
which is a stack of \emph{graph convolutional layers}.
Each layer consists of a collection of differentiable modules---one module per edge type.
\todo[author=R1]{Are there just so many nodes in the layer as the types of graph edges in Figure 2, or is each edge in the whole graph (a large set) represented by a collection of modules?}
The computation of the \gls{gcn} starts with assigning each node an initial embedding
and then iteratively updates the embeddings by passing them through the convolutional layers.

The initial embedding $h_a^{(0)}$ of a node $a$ is a concatenation of two vectors:
a \emph{feature vector} specific for that node (typically empty)
and a trainable vector shared by all nodes of the same type.
In our particular implementation,
feature vectors are used in nodes that correspond to clauses and symbols.
Each clause node has a feature vector with a one-hot encoding of the role of the clause,
which can be either axiom, assumption, or negated conjecture \cite{TptpSyntax,Sutcliffe2017}.
Each symbol node has a feature vector with two bits of data:
whether the symbol was introduced into the problem during preprocessing (most notably clausification),
and whether the symbol appears in a conjecture clause.

One pass through the convolutional layer
updates the node embeddings by passing a message along each of the edges.
For an edge of type $r \in \mathcal{R}$ going from source node $s$ to destination node $d$ at layer $l$,
the message is composed by converting the embedding of the source node $h_s^{(l)}$
using the module associated with the edge type $r$.
In the simple case that the module is a fully connected layer with weight matrix $W_r^{(l)}$ and bias vector $b_r^{(l)}$,
the message is $W_r^{(l)} h_s^{(l)} + b_r^{(l)}$.
% Notation is from Kipf: RGCN paper.
Each message is then divided by the normalization constant
$c_{s,d} = \sqrt{\card{\mathcal{N}_s^r}} \sqrt{\card{\mathcal{N}_d^r}}$ \cite{kipf2017semisupervised},
where $\mathcal{N}_a^r$ is the set of neighbors of node $a$ under the relation $r$.
\todo{FB: Mention that we mean both in- and out-neighbors?}

Once all the messages are computed,
they are aggregated at the destination nodes to form the new node embeddings.
Each node $d$ aggregates all the incoming messages of a given edge type $r$ by summation,
then passes the sum through an activation function $\sigma$ such as the \gls{relu},
and finally aggregates the messages across the edge types by summation,
yielding the new embedding $h_d^{(l+1)}$.

The following formula captures the complete update of embedding of node $d$ by layer $l$:
$$
h_d^{(l+1)} =
\sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{s \in \mathcal{N}_d^r} \frac{1}{c_{s,d}} (W_r^{(l)} h_s^{(l)} + b_r^{(l)})}
$$

%$$
%h_i^{(l+1)} =
%\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in %\mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
%$$
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
%\todo{FB: Mention inspiration: Transformer. See Straka's slides.}

\todo{Compare our GCN to Michael, Mirek etc.}

\subsection{Output layer: From symbol embeddings to symbol costs}
\label{sec:output}
% Terminology: Deep Learning Book

The symbol cost of each symbol is computed by passing the symbol's embedding through a linear output unit,
which is an affine transformation with no activation function.

It is possible to use a more complex output layer in place of the linear unit,
e.g., a feedforward network with one or more hidden layers.
Our experiments showed no significant improvement when a hidden layer was added,
likely because the underlying \gls{gcn} learns a sufficiently complex transformation.

Let $\theta$ denote the vector of all the parameters of the whole \acrlong{nn} consisting of the \gls{gcn} and the output unit.
Given an input problem $P$ with signature $\Sigma = (s_1, \ldots, s_n)$,
we denote the cost of symbol $s_i$ predicted by the \acrlong{nn} as $c(i, P; \theta)$.
In the rest of this text,
we refer to the predicted cost of $s_i$ simply as $c(i)$
because the problem $P$ and the parameters $\theta$ are fixed in each respective context.

\subsection{Sort: From symbol costs to precedence}
\label{sec:sorting}

The symbol precedence heuristics commonly used in the \glspl{atp} sort the symbols by some numeric property
that is inexpensive to compute,
such as the number of occurrences in the input problem, or the symbol arity.
In our precedence recommender,
we use a \gls{gcn}-based symbol cost model $c$ in place of the simple symbol property,
\todo[author=R1]{What exactly is the GCN-bases symbol cost? Is it the cost calculated by
the model for each symbol, or are different copies of symbols in different occurrences given
different costs?}
and generate a precedence by sorting the symbols by their predicted costs.
An advantage of this scheme is that sorting is a fast operation.

Moreover, as we show in \cref{sec:training}, it is possible
to train the underlying symbol costs by gradient descent.

%Note that a precedence that minimizes $C$
%orders the symbols with the lowest cost as the last, prioritizing them for early inferences.

\section{Training procedure}
\label{sec:training}

In \cref{sec:architecture} we described the structure of a recommender system that generates a symbol precedence for an arbitrary input problem.
The efficacy of the recommender depends on the quality of the underlying symbol cost function $c$.
In theory, the symbol cost function can assign the costs so that
sorting the symbols by their costs yields an optimum precedence.
This is because, at least in principle, all the information necessary 
to determine the optimum precedence is present in the graph representation of the input problem
thanks to the lossless property of the graph encoding.
\todo{MS: Hlavne tady ale jakoby chybi druha pulky ty vety. Neco jako ``In practice, however, ...'' Nemyslis?} 
Our approach to defining an appropriate symbol cost function is based on statistical learning
from executions of an \gls{atp} on a set of problems with random precedences.

To train a useful symbol cost function $c$,
we define a precedence cost function $C$ using the symbol cost function $c$
in a manner than ensures that minimizing $C$ corresponds to sorting the symbols by $c$.
Finding a precedence that minimizes $C$ can then be done efficiently and precisely.
We proceed to train $C$ on the proxy task of ranking the precedences.
% We have:
% Data allows us to tell whether pi < rho.
% We need the symbols sorted by c be a good precedence.

\subsection{Precedence cost}

%Sorting a vector $x$ of length $n$ in a non-increasing order corresponds to finding a permutation $\pi$ that minimizes
%the sum of the components of $x$ weighted by their positions in $\pi$.
%By defining the cost of a precedence as a measure that is minimized by sorting,
%we obtain a practical notion that can ultimately be trained by gradient descent.

We extend the notion of cost from symbols to precedences
by taking the sum of the symbol costs
weighted by their positions in the given precedence $\pi$:
\todo[inline]{FB: Consider accessing elements $\pi$ as vector elements $\pi_i$ instead of $\pi(i)$. Keep in mind that $\inv{\pi}$ must be updated as well. The motivation for using $\pi(i)$ is that $\inv{\pi}(i)$ looks clearer than $\inv{\pi}_i$. How about using $(\inv{\pi})_i$? We may also omit the inversion completely.}
\todo{FB: Consider using the terminology of RankNet: $C(\pi) = o_i$, $S(\pi, \rho) = o_{ij}$, $\loss = C_{ij}$}
\begin{equation*} \label{eq:cost_model}
C(\pi) = Z_n \sum_{i=1}^n i \cdot c(\pi(i))% We call the normalization factor Z_n to follow convention from Foundations of Machine Learning, p. 122.
\end{equation*}
$Z_n = \frac{2}{n(n+1)}$ is a normalization factor
that ensures the commensurability of precedence costs across signature sizes.
More precisely, normalizing by $Z_n$ makes the expected value of the precedence cost
independent of the signature size $n$:
\begin{multline*}
\mathbb{E}_\pi [C(\pi)]
= \mathbb{E}_\pi \SquareBracket{Z_n \sum_{i=1}^n i \cdot c(\pi(i))}
= Z_n \sum_{i=1}^n i \cdot \mathbb{E}_\pi [c(\pi(i))] \\
= Z_n \Parentheses{\sum_{i=1}^n i} \mathbb{E}_i [c(i)]
= \frac{2}{n(n+1)} \frac{n(n+1)}{2} \mathbb{E}_i [c(i)]
= \mathbb{E}_i [c(i)]
\end{multline*}
\todo[inline,author=R2]{In the equations showing that the expected value of the precedence cost is independent of the size of the signature, there is a (minor) problem in the second line: the i occurring in $E_i[c(i)]$ is not defined and probably unneeded if, as hinted by the equations, the expected value of each symbol is the same (which should also be stated somewhere).}

When $C$ is defined in this way,
the precedence produced by the recommender (see \cref{sec:sorting}) minimizes $C$.
\todo{Marting == for the camera ready version ==
Write here that there could be alternavi formulas to \eqref{eq:cost_model}
and we pick this one as the arguably simplest, for the lack of a better choice.}

\begin{lemma}
Precedence cost $C$ is minimized by any precedence that sorts the symbols by their costs in non-increasing order:
$$
\argmin_\rho C(\rho) = \argsort^- (c(1), \ldots, c(n))
$$
where $\argsort^-(x)$ is the set of all permutations $\pi$
that sort vector $x$ in non-increasing order ($x_{\pi(1)} \geq x_{\pi(2)} \geq \ldots \geq x_{\pi(n)}$).
\end{lemma}

\begin{proof}
We prove direction ``$\argmin_\rho C(\rho) \subseteq \argsort^- (c(1), \ldots, c(n))$'' by contradiction.
Let $\pi$ minimize $C$ and let $\pi$ not sort the costs in non-increasing order.
Then there exist $k < l$ such that $c(\pi(k)) < c(\pi(l))$.
Let $\bar{\pi}$ be a precedence obtained from $\pi$ by swapping the elements $k$ and $l$.
Then we obtain
%$\bar{\pi} = (\pi(1), \ldots, \pi(k-1), \pi(l), \pi(k+1), \ldots, \pi(l-1), \pi(k), \pi(l+1), \ldots, \pi(n))$.
\begin{align*}
\frac{C(\bar{\pi}) - C(\pi)}{Z_n}
&= kc(\bar{\pi}(k)) + lc(\bar{\pi}(l)) - kc(\pi(k)) - lc(\pi(l)) \\
&= kc(\pi(l)) + lc(\pi(k)) - kc(\pi(k)) - lc(\pi(l)) \\
&= k(c(\pi(l)) - c(\pi(k))) - l(c(\pi(l)) - c(\pi(k))) \\
&= (k-l) (c(\pi(l)) - c(\pi(k))) \\
&< 0
\end{align*}
The final inequality is because $k-l < 0$ and $c(\pi(l)) - c(\pi(k)) > 0$.
Clearly, $Z_n > 0$ for any $n \geq 0$.
\todo{FB: Isn't the inclusion of $Z_n$ too confusing?}
Thus, $C(\bar{\pi}) < C(\pi)$, which is contradicts the assumption that $\pi$ minimizes $C$.

It is easy to see that all the precedences that sort the symbol costs in a non-increasing order
have the same precedence cost.
Since $\emptyset \neq \argmin_\rho C(\rho) \subseteq \argsort^- (c(1), \ldots, c(n))$,
each of the precedences in $\argsort^- (c(1), \ldots, c(n))$ has the cost $\min_\rho C(\rho)$.
It follows that $\argsort^- (c(1), \ldots, c(n)) \subseteq \argmin_\rho C(\rho)$.
\qed
\end{proof}

\todo[inline]{FB: Discuss that sorting would minimize even if we weighted by a strictly monotonous function other than identity.}

\todo[inline]{FB: Why is the equality predicate always the first in the precedence?
MS: Andrei Voronokov reasons. It's typically better in practice to postpone equational reasoning,
so we want equalities to be generally small.}

\subsection{Learning to rank precedences}
\label{sec:ranking}

Our ultimate goal is to train the precedence cost function $C$ so that it is minimized by the best precedence,
measuring the quality of a precedence by the number of iterations of the saturation loop taken to solve the problem.

Approaching this task directly, as a regression problem,
runs into the difficulty of establishing sensible target cost values for the precedences in the training dataset,
especially when a wide variety of input problems is covered.
Approaching the task as binary classification of precedences
seems possible, but it is not clear which precedences should be a priori
labeled as positive and which as negative, to give a guarantee
that a precedence minimizing the precedence cost (i.e. the one obtained by sorting)
would be among the best in any good sense.
\todo{FB: I think we could ensure that the precedence that minimizes $C$ is relatively good, for example the best of the observed. I hope that ranking generalizes better to unseen precedences, but I am not sure whether it does and I haven't done an experiment to confirm that.}
% such as learning to detect the precedences that yield a successful proof search within the allocated time.

We cast the task as an instance of score-based ranking problem \cite{Mohri2018,Burges2005}
% Mohri2018: p. 239, chapter 10 Ranking
by training a classifier to decide which of a \emph{pair} of precedences is better, based on their costs.
We train the classifier in a way that ensures that better precedences are assigned lower costs.
The motivation for learning to order pairs of precedences
is that it allows learning on easy problems,
and that it may allow the system to generalize to precedences that are better than any of those seen during training.
\todo{FB: We should test this hypothesis by training on one problem in isolation.}
\todo[inline]{MS: ta druha myslenka, o ktere jsem mluvil pred obedem, se deje nekde v tomhle odstavci.
Jasne je, ze chceme vypichnout uceni ze dvojic precedenci jako jeden z klicovych napadu. Trochu min jasne je, proc by teda dvojice mely byt dobre.
Ja mel pocit, ze kdyz jsme se vloni snazili na tenhle problem napasovat regresi, 
pusobilo ``neprirozene'' vnucovat modelu konkretni cisla z vampiru. Jasne, nejak to resila normalizace
(a muselo se davat pozor aby cisla davala smysl nejen napric problemy (jeden resi vsechno rychle, jiny obcas neresi -- penalizace)
ale i kvuli ruznym velikostem signatury. Coz teda tady mame porad.) ale porad tam bylo to, ze nejak z vnejsku
modelu narizujeme, na ktere hodnoty ma cilit.
My tady ale vime, ze nam na konkretnich hodnotach sybol costu nezalezi, 
a ze ani nemusi byt rozumne porovnavatelne mezi problemy,
jediny, co je dulezity, je, aby setridena permutace byla ta (to the best of model's knowledge) nejlepsi.
Takze ja bych shrnul, ze s dvojicema obchazime nutnost stanovovat konkretni target values pro regresi (``problem volby spolecnych jednotek velicin''?)
a zaroven rafinovane menime ulohu z regresivni na classifikacni.\\
FB: Regrese $C$ neni jedina alternativa. Mohli bychom klasifikovat jednotlive precedence (viz text). Mohli bychom relaxovat pozadavek, ze setridena permutace je nejlepsi; stacila by "dost dobra". Zkusil jsem nejak vyargumentovat, proc je klasifikace dvojic lepsi nez klasifikace jednotlivych precedenci.}

\todo{Intuice: snazime se nastavit costy tak, aby co nejvic dvojic dopadlo spravne.}
\todo{Some pairs of precedences are not informative. We hope that the non-systematic examples will cancel each other out.}

\todo[inline]{MS: Tady je asi hlavni ``dira'' ve vysvetlovani...
Na to, abys vzal symbol costy a zavolal sort nepotrebujes definovat
cost precedenci a neco o nem dokazovat.

Nevim, jestli to nechces rict az pozdeji,
nebot precedence cost opravdu potrebujem az pro uceni!

Teda vlastne by mi nevadilo o tom mluvit zde, (az na to, ze rozcestnik drive rika
``Sorting converts the symbol costs into a symbol precedence.
It is only used in generating mode.'')

ale to vyzneni, kde to vypada, ze to delame kvuli tomu sortu, je matouci.

Predstavuju si odstavec, kde rikame, ze precedence cost je dulezity koncept,
protoze ma jednak tu vlastnost, ze je minimalizovan sortenim
ale druhak prirazuje cost i nesetridenym permutacim a tak ho muzem pouzit pri uceni.
(Coz by splnoval i jiny vzorecek nez \eqref{eq:cost_model}), namely
jina striktne monotonni funkce na pronasobeni nez to $i$ tam,
ale berem proste tenhle, protoze neni jasne, proc by jiny mel byt lespi,
a tenhle je nejjednodussi.)}

\subsubsection{Training data}

Each training example has the form $(P, \PrecBetter, \PrecWorse)$,
where $P = (\Sigma, \mathit{Cl})$ is a problem
and $\PrecBetter, \PrecWorse$ are precedences over $\Sigma$
such that the prover using $\PrecBetter$ solves $P$ in fewer iterations of the saturation loop than with $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}{P}$.
\todo{FB: Is this sufficient?}
\todo{FB: Describe the distribution of problems and precedences.}

\subsubsection{Loss function}

Let $(P, \PrecBetter, \PrecWorse)$ be a training example ($\Better{\PrecBetter}{\PrecWorse}{P}$).
The precedence cost classifies this example correctly if $C(\PrecBetter) < C(\PrecWorse)$,
or alternatively $S(\PrecBetter, \PrecWorse) = C(\PrecWorse) - C(\PrecBetter) > 0$.
% We have positive S score for correctly predicted examples.
% The loss function transorms that into a loss value close to 0.
We approach this problem as an instance of binary classification with the logistic loss \cite{Mohri2018},
% p. 128
a loss function routinely used in classification tasks in \acrlong{ml}:
\todo{FB: Consider exposing the form with inverse precedences to single out the $c$ values and expose the $c$ gradient better.}
\begin{multline*}
\loss(P, \PrecBetter, \PrecWorse)
= - \log \sigmoid S(\PrecBetter, \PrecWorse)
= - \log \sigmoid (C(\PrecWorse) - C(\PrecBetter)) \\
= - \log \sigmoid Z_n \sum_{i=1}^n i (c(\PrecWorse(i)) - c(\PrecBetter(i)))
%= - \log \sigmoid Z_n \sum_{i=1}^n c(i) (\inv{\PrecWorse}(i) - \inv{\PrecBetter}(i))
\end{multline*}
% FB: Note: I have included the full expansion to make it visible how the loss depends on $c$.
% To a skilled NN practitioner, it should now be obvious that the loss is differentiable w.r.t. $c$.

Note that the classifier cannot simply train $S$ to output a positive number on all pairs of precedences
because $S$ is defined as a difference of two precedence costs.
Intuitively, by training on the example $(P, \PrecBetter, \PrecWorse)$
we are pushing $C(\PrecBetter)$ down and $C(\PrecWorse)$ up.

The loss function is clearly differentiable with respect to the symbol costs,
and the symbol cost function $c$ is differentiable with respect to its trainable parameters.
This enables the use of gradient descent to find the values of the parameters of $c$
that minimize the loss value.
\todo[author=R2]{I expect that you mean "to *locally* minimize the loss value". If you do, the fix is simple (just add "locally"); if not, more explanations are needed.}

\Cref{fig:architecture} shows how the loss function is plugged into the recommender for the training.
