% !TEX root = main.tex

\todo{Describe problem again, this time precisely / technically.}
\todo{Prove that minimizing precedence cost corresponds to sorting by symbol cost.}
\todo{Advantage of using pairs of precedences: we need to solve classification rather than regression.}
\todo{Intuice: snazime se nastavit costy tak, aby co nejvic dvojic dopadlo spravne.}
\todo{Some pairs of precedences are not informative. We hope that the non-systematic examples will cancel each other out.}
\todo{Compare our GCN to Michael, Mirek etc.}

\iffalse

\subsection{Learning to generate good permutations}

Generating good symbol precedences is an instance of a more general task
of generating permutations of arbitrary length.
Each input problem corresponds to an input object that specifies the length of a permutation.

Let $X$ be a set of objects.
Let $l: O \to \nat$ assign each object $x \in X$ its signature length $l(x)$.
Let $\{x_1, \ldots, x_n\}$ be the training samples.\todo{MS: je mi jasny, ze tu neni poradek, ale i tak; posledni dva odstavce jsou dost zmateny.}

\subsubsection{Binary classification}

Let $p_\theta : X \to \re$ be a binary classification model.\todo{MS: Dobry priklad na to, ktere pojmy je treba vysvetlovat. model je znamy pojem v logice, tady ale pouzivame jiny, ML vyznam. To by si zaslouzilo komentar. Navic pisem
``binary'' a ``classification'' a neni tu jasny, co je ``binary''
a co jsou ``classes''. Z pohledu ctenare, ktery o tom zatim neslysel, se misto ``binary classficiation model'' mohlo
psat ``housenka'' a vyslo by to pro nej na stejno.}
The model predicts the probability of label $1$.
Let $(x_i, y_i)$ be the training samples,
where $x_i \in X$ and $y_i \in Y = \{0, 1\}$.\todo{MS:
``training'', ``sample'' a ``loss'' jsou dalsi priklady pojmu,
ktere najednou spadly z hury.}

For a training sample $(x, y) \in \re \times \{0, 1\}$, the binary cross-entropy loss is:
$$
L(\theta) = y \log{f_\theta(x)} + (1-y) \log{(1-f_\theta(x))}
$$

If $y_i = 1$ for all $i$, then the loss can be written in a simpler form:
$$
L(\theta) = \log{f_\theta(x)}
$$

\subsubsection{Permutations}

Let $O$ be a set of objects (or contexts).
Given an object $o \in O$, let $\Sigma(o)$ be its signature.
Let $x_i = (o_i, \pi_i, \rho_i)$, where $o_i \in O$
and $\pi_i, \rho_i \in \Perm(\Sigma(o_i))$.
Let $y_i \in \{0, 1\}$.

Let $p_\theta: X \to Y$.

Loss:
$$
L(\theta) = \log{p_\theta(x)}
$$

Let $c_\theta(o, s)$ be the predicted cost of symbol $s$.
Then:
$$
p_\theta(o, \pi, \rho) = C_\theta(o, \pi) - C_\theta(o, \rho)
$$

$$
C_\theta(o, \pi) = \sum_{i=1}^{l(o)}{c(o, \pi_i)}
$$

\begin{align*}
L(\theta) &= \log{p_\theta(o, \pi, \rho)} \\
&= \log{(C_\theta(o, \pi) - C_\theta(o, \rho))} \\
&= \log{(\sum_{i=1}^{l(o)}{c(o, \pi_i)} - \sum_{i=1}^{l(o)}{c(o, \rho_i)})} \\
&= \log{\sum_{i=1}^{l(o)}{c(o, \pi_i) - c(o, \rho_i)}} \\
\end{align*}

If $c$ is differentiable,
we can propagate loss gradients into it.

\subsection{Notation}

We denote the set of all finite vectors over $\re$ by $\re^* = \bigcup_{n=1}^\infty{\re^n}$.

Dot product: $\DotProd{x}{y} = \sum_{i=1}^n x_i \cdot y_i$ for $x, y \in \re^n$.

For any $n \in \nat$, we denote the set of all permutations over the set $\{1, \ldots, n\}$ by $\Perm{n}$.
Permuting a vector $x = (x_1, \ldots, x_n) \in \re^n$ by a permutation $\pi = (\pi_1, \ldots, \pi_n) \in \Perm{n}$ yields the vector $\pi(x) = (x_{\pi_1}, \ldots, x_{\pi_n})$.
$\inv{\pi}$ denotes the permutation inverse to $\pi$.
$\inv{\pi} = ...$.
\todo{Define permutation inversion.}
\todo{MS: Mozna ani ne. Ono je obcas tezky zavest a pouzivat presnout matematickou notaci, ktera se navic muze stavat neprehlednou, kvuli te presnosti. Na druhou stranu, intuitivne, kazdy vi, co by to mela byt inverzni permutace. Takze nerikam psat nepresne veci, ale obcas jde
zustak vagni s tim, ze vim, ze existuje zpusob jak to udelat presnym.
A povrchni ctenar to nemusi resit a matematicky zdatny by si ten detail odvodil spravne ...}

\fi

\subsection{System overview}

The precedence recommender is a system that takes
a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$ as the input,
and produces a precedence $\pi^*$ over the symbols $\Sigma$ as the output.

The architecture is designed so that the recommender can be trained
on the results of \gls{atp} executions on various problems with random precedences.
Since the recommender contains a neural network,
it is parameterized by weight tensors
whose values can be trained by gradient descent.
\todo{Ensure we have defined ``gradient descent''.}
\todo{MS: chapu ucel (a vidim, ze dalsi veta navazuje na ``parameters'', ale je to kostrbate.
Recommender = system, chapu jako program. Programy vetsinou neparametrizujeme tenzorama a gradient descent zije na jine urovni,
nez aby parametrizovane programy primo ucil. Uceni je spis nejaka technologie, kterou recommender pouziva, aby ... ``produces precedences
that are likely to yield a successful proof''.  }
The goal of the training is to find parameter values such that the recommender produces precedences
that are likely to yield a successful proof in as few iterations of the saturation loop as possible.\todo{MS: mozna udernejsi?}

The recommender consists of modules that perform specific subtasks,
each of which is described in detail in one of the following sections (see also \cref{fig:architecture}):
\begin{enumerate}
\item Graphifier converts the input \gls{cnf} problem into a problem graph.
\item \Gls{gcn} converts a problem graph into symbol embeddings.
\todo{MS: Kdyz embeddingy nebudou v preliminaries, je asi OK ctenare, ktery by o nich neslysel, zde trochu vydesit.
Ale v te prislusne podsekci tim zas zacit.}
\item An output function \cite{Zhou2018} converts the symbol embeddings into a vector of symbol costs.
\todo{MS: ``output function \cite{Zhou2018}'' my nic nerika, mel bych to znat?}
\item Ranking converts the symbol costs into a symbol precedence.
It is only used in generating mode.
\item Loss function converts the symbol costs and a pair of precedences into a loss value.
It is only used in training mode.
\end{enumerate}
\todo{MS: tohle zatim chapu jako predbezny nastrel. Leda by uz pred tim bylo vysvetleno:
embedding, \gls{gcn}/convolution layers, ... \\
FB: Staci predestrit, ze detaily vysvetlim pozdeji? MS: asi jo :)}

\begin{figure}[h]
\caption{Recommender architecture overview.
When recommending a precedence, the input is problem $P$ and the output is precedence $\pi^*$.
When training on an example, the input is problem $P$ and precedences $\pi$ and $\rho$,
and the output is the loss value.}
\label{fig:architecture}
\centering
\digraph[scale=0.4]{ArchitectureOverview}{
graph [splines=ortho,ranksep=0.2];
node [shape=box, fontsize=20];
edge [fontsize=20];

Problem [label="CNF problem P"];
Graphifier [style=rounded, label="Graphifier"];
g [label="Graph"];
GCN [style=rounded, label="GCN"];
SymbolEmbedding [label="Symbol embeddings"];
SymbolCostModel [style=rounded, label="Projection"];
SymbolCost [label="Symbol costs"];
Sort [style=rounded, label="Sort"];
Precedence [label=<Output precedence &pi;*>];

Problem -> Graphifier -> g -> GCN -> SymbolEmbedding -> SymbolCostModel -> SymbolCost -> Sort -> Precedence;

pi [label=<Precedence &pi;>];
rho [label=<Precedence &rho;>];
LossFunction [style=rounded, label="Loss function"];
Loss [label="Loss value"];

pi -> LossFunction;
rho -> LossFunction;
SymbolCost -> LossFunction;
LossFunction -> Loss;
}
\end{figure}

\subsection{From \gls{cnf} to graphs}
\label{sec:graphifier}

As the first step of the recommender processing pipeline,
the input problem is converted from a \gls{cnf} representation
to a \emph{heterogeneous (directed) graph} \cite{Zhou2018}.
% Zhou uses the term "heterogeneous graph".
%\footnote{Data mining literature often uses the term \gls{hin} \cite{Shi2015} for heterogeneous graphs.
%We prefer to conform to the terminology common in literature studying \glspl{gnn}.}
Each of the nodes is labeled with a node type,
and each edge is labeled with an edge type,
defining the heterogeneous nature of the graph.
Each node corresponds to one of the elements that constitute the \gls{cnf} formula,
such as a clause, an atom or a predicate symbol.
Each such category of elements corresponds to one node type.
The edges represent the (oriented) relations between the elements,
for example the incidence relation between a clause and one of its (literals') atoms,
or the relation between an atom and its predicate symbol.
\Cref{fig:CnfSchema} shows the types of nodes and edges used in our graph representation.
\Cref{fig:GcnExample}\todo{MS: ten se mi libi!} shows an example of a graph representation of a simple problem.

\newcommand{\ntype}[1]{\texttt{#1}}
\newcommand{\etype}[1]{\texttt{#1}}
\newcommand{\epos}{\etype{pos}}
\newcommand{\eneg}{\etype{neg}}

\begin{figure}[h]
\caption{CNF network schema}
\label{fig:CnfSchema}
\centering
\tikzstyle{token} = [rectangle, draw]

\begin{tikzpicture}[node distance = 1 and 2, ->]
% https://tex.stackexchange.com/a/332796/202639

% Node and edge types:
% https://docs.google.com/spreadsheets/d/1PCPHEgk6vLxpdpcvB_PGoLx7p4DID6WtvVWy2mDuv4A/edit?usp=sharing

\node (formula) [token] {\ntype{problem}};
% TODO: Consider removing the Formula nodes.
\node (clause) [token, below=of formula] {\ntype{clause}};
\node (atom) [token, below left=of clause] {\ntype{atom}};
\node (equality) [token, below right=of clause] {\ntype{equality}};
\node (predicate) [token, left=of atom] {\ntype{predicate}};
\node (argument) [token, below=of atom] {\ntype{argument}};
\node (term) [token, below=of argument] {\ntype{term}};
\node (function) [token, left=of term] {\ntype{function}};
\node (variable) [token, right=of term] {\ntype{variable}};

\draw (formula) to node [right] {\etype{contains}} (clause);
\draw (clause) to [bend right] node [above] {\epos{}} (atom);
\draw (clause) to [bend left] node [below] {\eneg{}} (atom);
\draw (clause) to [bend left] node [above] {\epos{}} (equality);
\draw (clause) to [bend right] node [below] {\eneg{}} (equality);
\draw (clause) to node [above] {\etype{binds}} (variable);
\draw (atom) to node [above] {\etype{atom\_applies}} (predicate);
\draw (atom) to node [left] {\etype{atom\_has}} (argument);
\draw (equality) to node {\etype{equalizes}} (term);
\draw (equality) to node {\etype{equalizes}} (variable);
\draw (argument) to [bend right] node [left] {\etype{is}} (term);
\draw (argument) to [loop left] node [left] {\etype{precedes}} (argument);
\draw (argument) to node [below] {\etype{is}} (variable);
\draw (term) to node [above] {\etype{term\_applies}} (function);
\draw (term) to [bend right] node [right] {\etype{term\_has}} (argument);

\end{tikzpicture}
\end{figure}

\begin{figure}[h]
\caption{Graph representation of the \gls{cnf} formula $a=b \wedge f(a,b) \neq f(b,b)$.}
\label{fig:GcnExample}
\centering
\digraph[scale=0.3]{GcnExample}{
	node [fontsize=32, shape=record];
	edge [fontsize=32, dir=both, arrowtail=empty];
	problem [label=<problem|a=b &and; f(a,b)&ne;f(b,b)>];
	c0 [label="clause|a=b"];
	c1 [label=<clause|f(a,b)&ne;f(b,b)>];
	problem -> c0;
	problem -> c1;
	t0 [label="equality atom|a=b"];
	t1 [label="equality atom|f(a,b)=f(b,b)"];
	c0 -> t0 [label=" + "];
	c1 -> t1 [label=" &ndash; "];
	ta [label="term|a"];
	tb [label="term|b"];
	ff [label="function|f", style=bold];
	fa [label="function|a", style=bold];
	fb [label="function|b", style=bold];
	tfab [label="term|f(a,b)"];
	tfbb [label="term|f(b,b)"];
	tfab0 [label="argument|1", style=dotted];
	tfab1 [label="argument|2", style=dotted];
	tfbb0 [label="argument|1", style=dotted];
	tfbb1 [label="argument|2", style=dotted];
	t0 -> ta;
	t0 -> tb;
	t1 -> tfab;
	t1 -> tfbb;
	tfab -> ff;
	tfab -> tfab0;
	tfab0 -> tfab1;
	tfab0 -> ta;
	tfab1 -> tb;
	tfbb -> ff;
	tfbb -> tfbb0;
	tfbb0 -> tfbb1;
	tfbb0 -> tb;
	tfbb1 -> tb;
	ta -> fa;
	tb -> fb;
}
\end{figure}

The graph representation has the following properties:
\begin{itemize}
\item Lossless: The original problem can be faithfully reconstructed from the corresponding graph representation
(up to logical equivalence).
\item Signature agnostic: Renaming the symbols and variables in the input problem yields an isomorphic graph.
\item For each relation $r$, its inverse $\inv{r}$ is also present in the graph,
typically represented by a different edge type.
\todo{MS: tohle jsem nepochopil. Nemuzeme rict, ze (az na nejakou vyjimkou) jsou edges v obou smerech?\\
FB: Chci vyjasnit, ze inverzni edge ma jiny edge type.}
\item A singleton node of type \ntype{problem} is connected to all the clauses of the problem.
\item The polarity of the literals is expressed by the type of the edge (\epos{} or \eneg{})
connecting the respective atom to the clause it occurs in.
\item For every non-equality atom and term, the order of its arguments is captured by a sequence of \ntype{argument} nodes chained by edges \cite{Rawson2020}.
\item The two operands of equality are not ordered.
This reflects the symmetry of equality.
\item Perfect sub-expression sharing:
\todo{MS: Predpokladam ze dva ruzne ground literaly p(c) tam budou taky jen jendnou?\\
FB: Literaly nemaji nody. Atomy maji nody a polarita literalu je zakodovana v typu hrany, ktery jej spojuje s klauzuli.
MS: O to my, neslo. Slo o to, jestli se sdily ground termy mezi klauzulemi, ted uz dobry! :)}
Redundant atoms and terms share a node representation \cite{}.
\todo{MS: Ale mezitim se to tu zmenilo a ja prestavam chapat, co je ``Redundant''.}
Note that since each variable is bound by a clause,
ground terms are shared across clauses,
but non-ground terms are only shared within the context of a clause.
\todo{FB: Remove as of little interest?}
\end{itemize}
\todo{FB: Reference appendix if we describe the representation in more detail there.}
\todo[inline]{MS: Filosoficka k ``can be represented''; mozna by se mohlo nekde objevit:
Snazime se do struktury HIN ``otisknout'' celou strukturu CNF (jak jsem rikal,
znamena to, ze zobrazeni je proste), abychom siti nevzali moznost ``vedet o problemu
uplne vsechno'' (az na veci, na kterych nezalezi jako poradi literaly v klauzulich, etc).
Ta filosoficka poznamka je o tom, ze pro dobre uceni tohle vlastne vubec nemusi byt treba,
ze nejaky ``hrubsi otisk'' by mohl stacit tez (a byt treba mensi), ale my nevime, jak takovy zvolit.\\
FB: Zkusim to popsat, kdyz zbyde cas.}
\todo{FB: Mention other encodings that have been proposed by Mirek and Michael.}

\subsection{\Gls{gcn}: From graphs to symbol embeddings}
\label{sec:gcn}

For each symbol in the problem,
we seek to find a vector representation, i.e., an \emph{embedding},
that captures the symbol's properties that are relevant
for correctly ranking the symbol in the observed symbol precedences.
\todo{FB: What does "correct" mean? MS: nic moc, ale v prvnim paragrafu sekce se to snad snese a zni to imho dobre:)
Nebo mas lepsi napad? "successfully"?
Napsat presne ale strucne, ze ty embeddingy jsou takove, aby siti pomohly mit co nejnizsi loss na proxy tasku 
hadani dvojic otazek, bude o dost tezsi...}
The symbol embeddings are output by a \gls{rgcn} \cite{Schlichtkrull2017},
which is a stack of graph convolutional layers.
Each layer consists of a collection of differentiable modules---one module per edge type.
The computation of the \gls{gcn} starts with assigning each node an initial embedding
and then repeatedly updates the embeddings by passing them through convolutional layers.
\todo{MS: to se mi libi, ze to nekde zacina a nekam to smeruje.}
\todo{FB: Ensure terms are clear (preferably defined): embedding, vector, trainable vector, feature vector.
MS: (convolutional, layers, ...)}

The initial embedding is a concatenation of two vectors:
a node feature vector (typically empty)
and a trainable vector shared by all nodes of the same type.
In our particular implementation,
feature vectors are used in nodes that correspond to clauses and symbols.
Each clause node has a feature vector with a one-hot encoding of the role of the clause,
which can be either axiom, assumption, or negated conjecture.
Each symbol node has a feature vector with two bits of data:
whether the symbol was introduced into the problem during preprocessing,
and whether the symbol appears in a conjecture clause.

One pass through the convolutional layer
updates the node embeddings by passing a message along each of the edges.
For an edge of type $r \in \mathcal{R}$ going from source node $s$ to destination node $d$ at layer $l$,
the message is composed by converting the embedding of the source node $h_s^{(l)}$
using the module associated with the edge type $r$.
In the simple case that the module is a dense layer with weight matrix $W_r^{(l)}$,
\todo{MS: hnidopich nevi, co to znamena ``dense layer''}
the message is $h_s^{(l)} W_r^{(l)}$.\todo{MS: mas nejakou preferenci pro column/row vectors a z jake strany je prirozene nasobit?
Ja bych mozna spis psal $W_r^{(l)} h_s^{(l)}$, a mozna s explicitnim  $W_r^{(l)} \cdot h_s^{(l)}$.}
Each message is then divided by a normalization constant
$c_{s,d} = \sqrt{\card{\mathcal{N}_s^r}} \sqrt{\card{\mathcal{N}_d^r}}$ \cite{kipf2017semisupervised},
where $\mathcal{N}_n^r$ is the set of neighbors of node $n$ under the relation $r$.
\todo{FB: Mention that we mean both in- and out-neighbors?}
Once all the messages are computed,
they are aggregated by the destination nodes to form the new node embedding.
Each node $d$ aggregates all the incoming messages of a given edge type $r$ by summation,
then passes the sum through an activation function $\sigma$ such as the \gls{relu},
and finally aggregates the messages across the edge types by summation,
yielding the new embedding $h_d^{(l+1)}$.
The following formula captures the update of embedding of node $d$:
$$
h_d^{(l+1)} =
\sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{s \in \mathcal{N}_d^r} \frac{1}{c_{s,d}} (h_s^{(l)} W_r^{(l)} + b_r^{(l)})}
$$
%$$
%h_i^{(l+1)} =
%\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in %\mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
%$$
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
%\todo{FB: Mention inspiration: Transformer. See Straka's slides.}

\todo[inline]{Explain residual connections and layer normalization.}
\todo[inline]{MS: neni uplne jiste, ze ``CADE people'' oceni presny zapis 
strutury site, vcetne prvku jako $\mathrm{LayerNorm}$ ve vzorecku.
Nerikam, ze bychom to meli uplne zatajit, ale popis, ktery je zde, spis
patri do appendixu (ML paperu). Na te siti vlastne nic originalniho neni,
tak neni treba vsechno vysvetlit do detailu. Zajimavejsi tu
potom je az to, jak se problem $P$ ``otiskne'' v topologii grafu. 
To uz originalni je (a soutezi to s representacemi jako ta Mirkova)
a popisujes to pak dal.}

\subsection{Output layer: From symbol embeddings to symbol costs}
\label{sec:output}

The symbol cost of each symbol is computed by passing the symbol's embedding through a dense layer with a single output unit.
No activation function is applied so that the output values can span the whole $\re$.
\todo{MS: provided the input embeddings can...}

Note that it is possible to use a more complex projection module,
e.g., a feed-forward network with one or more hidden layers.
\todo{FB: Ensure the term is defined.}
Our experiments showed no significant improvement when a hidden layer was added,
likely because the underlying \gls{gcn} learns a sufficiently complex transformation.

For input problem $P$
with signature $\Sigma = (s_1, \ldots, s_n)$,
we denote the cost of the $i$-th symbol as $c(i)$.
\todo{FB: Consider using $c(s_i)$.}
\todo{FB: Consider making the background problem explicit by using $c(i|P)$ or $C(i,P)$.}

\subsection{Ranking: From symbol costs to precedence}
\label{sec:ranking}

We extend the notion of cost from symbols to precedences
by summing up the symbol costs
weighted by their positions in the given precedence $\pi$:
$$
C(\pi) = \sum_{i=1}^n c(\pi(i)) \cdot i
$$
\todo{FB: Consider making the background problem explicit by using $C(\pi|P)$ or $C(\pi,P)$.}
\todo[inline]{FB: Consider accessing elements $\pi$ as vector elements $\pi_i$ instead of $\pi(i)$. Keep in mind that $\inv{\pi}$ must be updated as well. The motivation for using $\pi(i)$ is that $\inv{\pi}(i)$ looks clearer than $\inv{\pi}_i$. How about using $(\inv{\pi})_i$? We may also omit the inversion completely.}

\begin{lemma}
Precedence cost $C$ is minimized by the precedence that ranks the symbols by their costs in non-increasing order:
% FB: The ranking terminology is from Fast Differentiable [...] Ranking.
$$
\argmin_\pi C(\pi) \in \argsort^- (c(1), \ldots, c(n))
$$
\end{lemma}

\begin{proof}
We prove the lemma by contradiction.
Let $\pi$ minimize $C$ and let $\pi$ not rank the costs in non-increasing order.
Then there exist $k < l$ such that $c(\pi(k)) < c(\pi(l))$.
Let $\bar{\pi}$ be a precedence obtained from $\pi$ by swapping the elements $k$ and $l$.
Then we obtain
%$\bar{\pi} = (\pi(1), \ldots, \pi(k-1), \pi(l), \pi(k+1), \ldots, \pi(l-1), \pi(k), \pi(l+1), \ldots, \pi(n))$.
\begin{align*}
C(\bar{\pi}) - C(\pi)
&= kc(\bar{\pi}(k)) + lc(\bar{\pi}(l)) - kc(\pi(k)) - lc(\pi(l)) \\
&= kc(\pi(l)) + lc(\pi(k)) - kc(\pi(k)) - lc(\pi(l)) \\
&= k(c(\pi(l)) - c(\pi(k))) - l(c(\pi(l)) - c(\pi(k))) \\
&= (k-l) (c(\pi(l)) - c(\pi(k))) \\
&< 0
\end{align*}
The final inequality is because $k-l < 0$ and $c(\pi(l)) - c(\pi(k)) > 0$.
Thus, $C(\bar{\pi}) < C(\pi)$, which is contradicts the assumption that $\pi$ minimizes $C$. \qed
\end{proof}

Once the symbol costs are known,
producing a precedence that minimizes the precedence cost is cheap
because ranking is a fast operation.\todo{MS: can we not say ``sorting''? Also slightly earlier.}

Note that a precedence that minimizes $C$\todo{MS: Indefinite article; there can be more than one such...}
orders the symbols with the lowest cost as the last, prioritizing them for early inferences.

\todo[inline]{FB: Why is the equality predicate always the first in the precedence?
MS: Andrei Voronokov reasons. It's typically better in practice to postpone equational reasoning,
so we want equalities to be generally small.}
\todo[inline]{FB: Mention that the common heuristics fit this scheme.}

\subsection{Training}

In \cref{sec:graphifier,sec:gcn,sec:output,sec:ranking} we described the structure of a recommender system that generates a precedence for an arbitrary input problem.
The efficacy of the recommender depends on the quality of the underlying symbol cost function.
In theory, the symbol cost function can assign the costs so that
ranking the symbols by their costs yields an optimum precedence,
\todo{MS: hezky, to zacina dobre!}
and all the information necessary to determine the optimum precedence is present in the graph representation of the input problem.
\todo{MS: ``because the of the lossless property of the graph encoding mentioned before.''
(Na druhou stranu nevime, jestli to dokaze zvladnout navrzena architectura.)}
\todo{MS: Hlavne tady ale jakoby chybi druha pulky ty vety. Neco jako ``In practice, however, ...'' Nemyslis?} 
Our approach to defining an appropriate symbol cost function is based on statistical learning
from executions of an \gls{atp} on a set of problems with various\todo{MS: proc ne ``random''?} precedences.

\subsubsection{Training data}

Each training example has the form $(P, \PrecBetter, \PrecWorse)$,
where $P = (\Sigma, \mathit{Cl})$ is a problem
and $\PrecBetter, \PrecWorse$ are precedences over $\Sigma$
such that the prover using $\PrecBetter$ solves $P$ in fewer iterations of the saturation loop than with $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}$.\todo{MS: Could we have $\PrecBetter \prec_P\PrecWorse$?}
\todo{Is this sufficient?}

\subsubsection{Loss function}

\todo{Two levels of proxy metrics: 0-1 loss, differentiable loss (hinge, logistic)}
To ensure that ranking the symbols by their costs
yields a good precedence,
we want the symbol cost function $c$
to satisfy the inequality $C(\PrecBetter) < C(\PrecWorse)$
for as many training examples $(P, \PrecBetter, \PrecWorse)$ as possible.
%
This can alternatively be expressed as $s(\PrecBetter, \PrecWorse) := C(\PrecBetter) - C(\PrecWorse) < 0$,
introducing a new quantity
$s(\PrecBetter, \PrecWorse)$
as the \emph{score} of the (ordered) precedence pair $(\PrecBetter, \PrecWorse)$.
Given a set of examples of the form $(P, \PrecBetter, \PrecWorse)$
where $\Better{\PrecBetter}{\PrecWorse}$,
our goal is to maximize the accuracy
$\frac{1}{m} \sum_x \iverson{s(\PrecBetter, \PrecWorse) < 0}$.
\todo{MS: Not sure if we can assume $\iverson{X}$ to be universally understandable.}
% Alternative: We actually don't care about the relative order of non-minimum precedences.

A common approach to training a binary classifier\todo{MS: First mention of a ``binary classifier''!
We classify the examples, sure, but you did not say it yet.}
is to relax the non-differentiable accuracy $\iverson{s(\PrecBetter, \PrecWorse) < 0}$
to a differentiable proxy
such as the logistic loss
$L = - \log \sigmoid s(\PrecBetter, \PrecWorse)$.
\todo{MS: neni tu ted spatne zniminko? Nebo spis uz v definici score? Cekal bych, ze pro positivni examply (coz jsou u nas vsechny)
bude chit $s$ kladne.}

\subsection{Notes}

We need to train $c$ in a way that ensures that $C$ is minimized by a good precedence.
On pairs,
$C(\pi)$ should be smaller than $C(\rho)$ iff $\Better{\pi}{\rho}$.

% What if we trained the binary classifier on vector:
% C(\pi), C(\rho), C(\pi)^2, C(\rho)^2 (kernel trick?)

Let $P = (\Sigma, \mathit{Cl})$ be a problem.
Let $\PrecBetter, \PrecWorse$ be two precedences over $\Sigma$.
% that are comparable according to AST.
Let $y = 1$ if $\PrecBetter$ is better than $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}$,
and $y = 0$ otherwise.

The examples that the recommender will be trained on have the form
$(P, \PrecBetter, \PrecWorse)$, where $P = (\Sigma, \mathit{Cl})$ is a \gls{cnf} problem, and $\PrecBetter, \PrecWorse$ are precedences over $\Sigma$
where $\PrecBetter$ yields a faster proof search than $\PrecWorse$,
\todo{FB: Rephrase?}
denoted as $\Better{\PrecBetter}{\PrecWorse}$.

Given an example $x$,
a binary classifier predicts the probability of event $1$,
denoted as $p(x)$.
The classifier is trained on samples of the form $(x, y)$,
where $x$ is the observable state and $y \in \{0, 1\}$ is the target label.
Logistic regression is a popular approach to train a binary classifier.
Logistic regression is based on the logistic loss:
$$
L(x, y) = - y \log p(x) - (1-y) \log (1-p(x))
$$


% Hinge loss (y \in {-1, 1}):
% L = max(0, 1 - ty)
% t = 1: L = max(0, 1-y)

% Binary crossentropy (y \in {0, 1}):
% L = - y log p(1)) - (1-y) log p(0)
% y = 1: L = - log p(1) = - log sigmoid c

We train the system on results of \gls{atp} executions on problems with random precedences.
Let $P = (\Sigma, \mathit{Cl})$ be a problem
and let $\PrecBetter, \PrecWorse$ be two precedences over $\Sigma$.
We run an \gls{atp} on $P$ with the two precedences.
If the run with $\PrecBetter$ finds the proof successfully and uses less saturation loop iterations than the run with $\PrecWorse$,
we can be certain that $\PrecBetter$ is a better precedence for $P$ than $\PrecWorse$,
denoted as $\Better{\PrecBetter}{\PrecWorse}$.

A binary classifier predicts the probability of complementary events $0$ and $1$,
denoted as $p(0)$ and $p(1)$ respectively.
The events are complementary,
meaning $p(0) = 1 - p(1)$ and $p(0) + p(1) = 1$.

A binary classifier with a binary crossentropy loss
takes the predicted probability $p$ of events $0, 1$
and computes the loss:
$$
L(y) = y log(p(1)) + (1-y) log(p(0))
$$

The examples that the recommender will be trained on have the form
$(P, \PrecBetter, \PrecWorse)$, where $P = (\Sigma, \mathit{Cl})$ is a \gls{cnf} problem, and $\PrecBetter, \PrecWorse$ are precedences over $\Sigma$
where $\PrecBetter$ yields a faster proof search than $\PrecWorse$,
\todo{FB: Rephrase?}
denoted as $\Better{\PrecBetter}{\PrecWorse}$.

We train a binary classifier that decides,
for a pair of precedences $\PrecBetter, \PrecWorse$,
whether $\Better{\PrecBetter}{\PrecWorse}$.
Since all the training examples are oriented so that $\Better{\PrecBetter}{\PrecWorse}$,
the classification target value for all the samples is $1$.
\todo{FB: Somebody might think that this is a problem because the classifier can simply learn to always say "1". The structure of the classifier ($C(x_1) - C(x_2)$) prevents that. Consider explaining.}
Thus the binary crossentropy loss can be expressed as a simple expression:
$$
L(P, \PrecBetter, \PrecWorse) = - \log \sigmoid (C(\PrecWorse) - C(\PrecBetter))
$$

Derivation:
$$
L(P, \PrecBetter, \PrecWorse) = - \sum y \log p(y)
$$

$$
p(0) = \sigmoid (C(\PrecBetter) - C(\PrecWorse)) \\
p(1) = \sigmoid (C(\PrecWorse) - C(\PrecBetter))
$$

\todo{Mention normalization.}

\subsection{[Alternative: Top-down approach]}

The precedence generator, given a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$,
generates a precedence over $\Sigma$
that is expected to yield a successful proof search.

The recommender first computes a cost value for each symbol of the input problem,
and then orders the symbols by their costs in a non-increasing order.
In this manner, the task of finding good precedences is reduced to the task
of finding a good symbol cost function.
We use a standard \gls{ml} terminology and denote
the practical realization of the symbol cost function as \emph{symbol cost model}.

Note that the symbol precedence heuristics commonly used in practice
conform to this scheme:
they order the symbols by a numeric property, such as arity or number of occurrences.
\todo{MS: tohle se mi libi!}

\subsection{Symbol cost model}

The symbol cost model, given a \gls{cnf} problem $P = (\Sigma, \mathit{Cl})$,
assigns each symbol in $s \in \Sigma$ a real value $c(s)$.
It first uses a symbol embedding model to assign each symbol $s$ an embedding $E(s)$.
The resulting symbol cost is a dot product of the symbol embedding with a trainable weight vector:

$$
c(s) = \DotProd{E(s)}{w} + b
$$

\subsection{Symbol embedding model}

The symbol embedding model, given a problem,
assigns each symbol $s \in \Sigma$ an embedding $E(s) \in \re^n$.
Our implementation uses a \gls{rgcn} \cite{}.

\todo[inline]{What is the structure of the graphs? What are the trainable parameters? Etc.}

\subsection{Loss function}

To train the symbol cost model,
examples of the form $(P, \pi, \rho)$ are used.
To be able to train the model by gradient descent,
we need to define a loss function that is differentiable with respect to the model parameters,
and that is minimized by a symbol cost model that produces good precedences.
Optimizing the output precedence directly is not possible
because the sorting operation is not differentiable
and because we generally don't know the best precedence on a given problem.

\todo[inline]{Idea for next project: Optimize precedence directly in a RL fashion: Generate precedence and evaluate with Vampire. If it is the best precedence seen so far, loss is 0 and gradient is 0. Otherwise ground truth is the best precedence seen so far on this problem and we use "differentiable ranking" to backpropagate. Possibly with some exploration, e.g. random swaps of pairs of symbols.}

\subsection{Overview}

Let $\cnf$ be the set of all \gls{cnf} problems.
Let $P \in \cnf$ be an arbitrary problem.
\todo{Consider using $F$ (as formula) instead of $P$ to free up P for probability.}
Let $\signature{P}$ be the signature of $P$, that is a list of all non-logical symbols (predicates and functions)
\todo{Should we rather use either predicates or functions? Or use a compound signature?}
that appear in the problem.
Let $n = \card{\signature{P}}$.
A symbol precedence $\Prec \in \Perm{n}$ for problem $P$ is a permutation of the symbols of $P$.

\newcommand{\Solver}{S}
\newcommand{\SolverRun}[2]{\Solver(#1, #2)}

Let $\Solver$ be an \gls{atp} with a fixed computation environment, configuration and time limit.
The computation of $\Solver$ is assumed to be parameterized by symbol precedence.
\todo{Discuss. What does this mean?}
$\SolverRun{P}{\Prec}$ denotes the result of a proof attempt on problem $P$ with symbol precedence $\Prec$.
$\SolverRun{P}{\Prec} = \top$ if $S$ solves $P$ within the time limit, and $\SolverRun{P}{\Prec} = \bot$ otherwise.
\todo{MS: vadi zminit pocet iteraci smycky tak, jako v minulem paperu?}
Since the result is generally non-deterministic in case the time limit is specified in wall clock units,
we consider $\SolverRun{P}{\Prec}$ to be a random variable with a Bernoulli distribution.
\todo{Cite?}
We denote the probability of a successful proof search $\Prob{\SolverRun{P}{\Prec} = \top}$.
\todo{MS: asi bych se primlouval za to v teto fazi o Bernoullim pomlcet.
Otazky jsme generovali tak, ze proste porovnavame pocty iteraci saturatcni smycky a pocitame s tim, ze beh je deterministicky.
To, ze se pozdeji, pri evalu, pouzije perspektiva nahodnosti
bych uz chapal jako metodiku experimentu a teorii tim nekomplikoval.}

The main task this paper deals with is this:
Given a problem $P \in \cnf$, generate a symbol precedence $\Prec \in \Perm{n}$ that maximizes $\Prob{\SolverRun{P}{\Prec} = \top}$.
\todo[inline]{MS: (Nehlede na to, ze main task by nejspis mel byt vysvetlen mnohem drive...) Asi bych to takhle nestavel. Jak pisu vyse, precijen je
beh dokazovace deterministicky a brat to nejak Bayesovsky by sice mohlo 
byt zajimave, ale jeste mnohem tezsi na obhajeni jako ``svetonazor''.
Co proste priznat nasledujici assumption:
verime, ze pokud bude model spravne odpovidat na otazky $(P, \pi_1, \pi_2)$ (s pravdepodobnosti $> \SI{50}{\percent}$), povede podle nej vybrana permutace minimalizujici \eqref{eq:model_cost} k rychlemu vyreseni problemu (a tim i idealne k vyreseni problemu, ktere byly drive out of reach.)}
\todo{MS: koukni prosim, jestli nejaky takovy mame. Tj zadna random permutace ho nevyresila, ale naucena sit pak ano!}

Instead of modeling $\Prob{\SolverRun{P}{\Prec} = \top}$ directly,
the system described in this paper predicts, given a problem $P$ and a pair of precedences $\PrecBetter, \PrecWorse \in \Perm{n}$,
the probability
\todo{MS: tohle je jeden z oficialnich zpusobu,
jak vysvetlovat neuronky, ale neni nijak jasne do jake miry byva
$\sigma(\mathit{logits})$ blizko nejake pravdepodobnosti. Za mne by klidne stacilo mluvit o tom, ze se snazime klasifikovat co nejvic dvojic
spravne a ze na to pouzivame standard techologii neuronek (Binary Cross Entropy loss (against the final layer’s sigmoid non-linearity)). Tj opet hlasuji za to nemluvit zde o pravdepodobnosti. :)}
\todo{MS: jo, ale pak bude nekde dobre zminit, ze jsme si vedomi, ze dvojice skoro jiste neobsahuji stejne mnozstvi ``signalu'', ze ktereho je mozne se ucit. Je to proste vlastnost vybrane metody a v prumeru to nevadi.}
that $\PrecBetter$ outperforms $\PrecWorse$ in terms of success of proof search. This proxy task allows learning from pairs of precedences that both yield a successful proof search but differ in the number of steps taken in the proof search.
\todo{Explain more.}

% By taking the pairs, we get more data esp. from easy problems.
% Consider weighting the samples by the result type: quantitative / qualitative etc.

\begin{figure}[h]
\caption{System overview}
\label{fig:SystemOverview}
\centering
\usetikzlibrary{shapes}
\tikzstyle{object} = [rectangle, draw]
\tikzstyle{input} = [ellipse, draw]
\tikzstyle{output} = [ellipse, draw]

\begin{tikzpicture}[node distance = 0.5 and 1, ->]
% https://tex.stackexchange.com/a/332796/202639

\node (problem) [input] {\gls{cnf} problem $P$};
\node (symbol embeddings) [object] [below=of problem] {Symbol embeddings};
\node (symbol costs) [object] [below=of symbol embeddings] {Symbol costs};
\node (symbol precedence) [output] [below=of symbol costs] {Symbol precedence};

\draw (problem) to node [left] {GCN} (symbol embeddings);
\draw (symbol embeddings) to node [left] {MLP} (symbol costs);
\draw (symbol costs) to node [left] {Order symbols by their costs} (symbol precedence);

\node (PrecBetter) [input] [right=of problem] {Precedence $\PrecBetter$};
\node (PrecBetterInv) [object] [below=of PrecBetter] {$\inv{\PrecBetter}$};
\draw (PrecBetter) to node [right] {Invert} (PrecBetterInv);

\node (PrecWorse) [input] [right=of PrecBetter] {Precedence $\PrecWorse$};
\node (PrecWorseInv) [object] [below=of PrecWorse] {$\inv{\PrecWorse}$};
\draw (PrecWorse) to node [right] {Invert} (PrecWorseInv);

\node (PrecDiff) [object] [right=2 of symbol costs] {$\inv{\PrecWorse} - \inv{\PrecBetter}$};
\node (PrecDiffNormalized) [object] [below=of PrecDiff] {Normalized};
\node (PrecPairCost) [object] [below=of PrecDiffNormalized] {Precedence pair cost};
\node (loss) [output] [below=of PrecPairCost] {Loss};

\draw (PrecBetterInv) to (PrecDiff);
\draw (PrecWorseInv) to (PrecDiff);
\draw (PrecDiff) to node [right] {Normalize} (PrecDiffNormalized);
\draw (PrecDiffNormalized) to (PrecPairCost);
\draw (PrecPairCost) to (loss);

\draw (symbol costs) to (PrecPairCost);

\end{tikzpicture}
\end{figure}

Fig.~\ref{fig:SystemOverview}
\todo{MS: Na figures/tables bez referneci v textu se pohlizi obzvlast nelibe. Predpokladam, zes planoval pozdeji popsat, presto zmninuji. Konkretne k Fig.~\ref{fig:SystemOverview}:
Napada me: neslo by precedenci definovat tak, aby uz byla tim $\pi^{-1}$? Invertovani zabira v obrazku skoustu mista, ale pritom
jde o technicky detail a hlavni myslenku nijak neosvetluje...}

\subsection{Symbol cost model}

The symbol costs are modeled by a \gls{rgcn}.\cite{Schlichtkrull2017}
\todo{Can I use the term \gls{rgcn} when I use a modified version? Namely, the activation is called earlier.}
The model is a stack of graph convolutional layers.
Each layer consists of one differentiable module for each edge type.
Each module is a dense layer.
$$
h_i^{(l+1)} =
\mathrm{LayerNorm} \Parentheses{h_i^{(l)} + \sum_{r \in \mathcal{R}} \sigma \Parentheses{\sum_{j \in \mathcal{N}_i^r} \frac{1}{c_{ji}} h_j^{(l)} W_r^{(l)}}}
$$
\todo{Include dropout?}
% Inspiration: https://ufal.mff.cuni.cz/~straka/courses/npfl114/1920/slides.pdf/npfl114-07.pdf - slide 27 - Transformer
\todo{FB: Mention inspiration: Transformer. See Straka's slides.}
$h_i^{(l)}$ denotes the embedding of node $i$ at layer $l$.
$\mathcal{R}$ denotes the set of all relations in the graph.
$\sigma$ denotes the activation function, for example the \gls{relu}.
$\mathcal{N}_i^r$ denotes the set of neighbors of node $i$ under relation $r$.
$c_{j, i, r} = \sqrt{\card{\mathcal{N}_j^r}} \sqrt{\card{\mathcal{N}_i^r}}$ is a normalization constant.\cite{kipf2017semisupervised}
$W_r^{(l)}$ is a trainable weight matrix representing relation $r$ at layer $l$.

Residual...
Layer norm...

\todo{MS: neni uplne jiste, ze ``CADE people'' oceni presny zapis 
strutury site, vcetne prvku jako $\mathrm{LayerNorm}$ ve vzorecku.
Nerikam, ze bychom to meli uplne zatajit, ale popis, ktery je zde, spis
patri do appendixu (ML paperu). Na te siti vlastne nic originalniho neni,
tak neni treba vsechno vysvetlit do detailu. Zajimavejsi tu
potom je az to, jak se problem $P$ ``otiskne'' v topologii grafu. 
To uz originalni je (a soutezi to s representacemi jako ta Mirkova)
a popisujes to pak dal.}

\subsection{Loss function} 
\label{sec:loss}

Let $\cnf$ be the set of all \gls{cnf} problems.
Let $P \in \cnf$ be an arbitrary problem.
Let $\signature{P}$ be the signature of $P$.
Let $n = \card{\signature{P}}$.

Given a problem $P$, a symbol cost model 
\todo{MS: Zvidavy invalida Jirka Karasek: a co ze je to ten model? 
Mohl byste to to prosim nekde driv vysvetlit?}
$c : \cnf \to \re^*$
\todo{MS: Mozna by se dalo zbavit lehce podivneho $\re^*$ tim,
ze model bude funkce $(P \in \cnf, s \in \Sigma_P) \to \re$?
Zas pak nepujde pouzivat zapis skalarniho soucinu; hmmm.}
returns a vector of costs of the symbols of $P$:
$$
c(P) = (c_1, \ldots, c_n)
$$

Let $\Prec \in \Perm{n}$ be a precedence of symbols of problem $P$.
Let $k(n) = \frac{2}{n(n+1)}$ be a normalization factor for precedences of length $n$.
The symbol cost model $c$ can be extended to a precedence cost model $C$
by taking the weighted sum of symbol costs:
\begin{equation} \label{eq:model_cost}
C(\Prec | P)
= k(n) \sum_{i=1}^n c_{\Prec_i} \cdot i
= k(n) \sum_{i=1}^n c_i \cdot \inv{\Prec}_i
= k(n) \DotProd{c(P)}{\inv{\Prec}}
\end{equation}
Note that the value of $C$ is minimized by a precedence that orders the symbols by their costs in non-increasing order.
\todo{Discuss, prove.}
\todo{Mention here that minimizing C yields the best precedence.}

Fixing the normalization factor $k(n)$ to the value $\frac{2}{n(n+1)}$
ensures that costs of precedences of various lengths are commensurable.
Observe namely that if $c$ assigns each symbol the same cost $c_0$,
then the precedence cost is equal to $c_0$ irrespective of the signature length $n$:
$$
C(\Prec | P) = \frac{2}{n(n+1)} \sum_{i=1}^n c_0 \cdot i = c_0
$$

Let $\PrecBetter, \PrecWorse \in \Perm{n}$ be two symbol precedences over $P$.
Let $\PrecBetter$ yield a faster proof search on $P$ than $\PrecWorse$, denoted as $\Better{\PrecBetter}{\PrecWorse}$.
The precedence cost model can be extended to predict the probability that $\PrecBetter$ is better than $\PrecWorse$:
\todo{Fix this. Ensure the polarity is sound.}
\todo{MS: zatim chybi vysvetleni $\sigmoid$.}
\todo{MS: duvod proc mi v tomhle kontextu moc nesedi mluvit o pravdepodobnosti
je ten, ze bez dalsiho vysvetlovani to vypada, ze si myslime, ze
kdyz pomoci $\sigmoid$ splacnem v podstate libovolne hodnoty do
intervalu $(0,1)$, zecne to automaticky fungovat jako pravdepodobnost.}
\begin{align*}
p(\Better{\PrecBetter}{\PrecWorse} | P)
&= \sigmoid \SquareBracket{C(\PrecWorse | P) - C(\PrecBetter | P)} \\
%&= \sigmoid \SquareBracket{k(n) \sum_{i=1}^n c_i \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)} \\
&= \sigmoid \SquareBracket{k(n) \DotProd{c(P)}{\inv{\PrecWorse} - \inv{\PrecBetter}}}
\end{align*}
It is easy to see that $p(\Better{\PrecBetter}{\PrecWorse} | P) > 0.5$ if and only if $C(\PrecWorse | P) > C(\PrecBetter | P)$,
and that the value of $p$ can be increased by increasing $C(\PrecWorse | P)$ or decreasing $C(\PrecBetter | P)$.

We consider the difference $C(\PrecWorse | P) - C(\PrecBetter | P)$
to be the "logit"\todo{MS: Logit je taky tezky pojem, urcite ne automaticky znamy u ATP people.} score of the pair of precedences $\PrecBetter, \PrecWorse$,
and denote it by $C(\Better{\PrecBetter}{\PrecWorse} | P)$.

We define the loss of $c$ on the training sample $(\PrecBetter, \PrecWorse, P)$ as binary cross-entropy
with ground truth $\Better{\PrecBetter}{\PrecWorse}$:

\begin{align*}
L(\PrecBetter, \PrecWorse, P)
&= - \log p(\Better{\PrecBetter}{\PrecWorse} | P) \\
&= - \log \sigmoid \SquareBracket{k(n) \DotProd{c(P)}{\inv{\PrecWorse} - \inv{\PrecBetter}}} \\
&= - \log \sigmoid \SquareBracket{k(n) \sum_{i=1}^n c_i \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)}
\end{align*}

The loss is differentiable with respect to the symbol costs:
\begin{align*}
\frac{\partial L}{\partial c_i}
&= -\sigmoid(-C(\Better{\PrecBetter}{\PrecWorse} | P)) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i) \\
&= (p(\Better{\PrecBetter}{\PrecWorse} | P) - 1) \cdot k(n) \cdot (\inv{\PrecWorse}_i - \inv{\PrecBetter}_i)
\end{align*}

This means that it is possible to backpropagate the loss gradient into the symbol cost model. \todo{MS: tohle bude tezky,
ale ackoliv ML people by tohle uz asi chapali, ATP crowd spis bude
potrebovat obsirnejsi vysvetleni.}

\subsubsection{Generalization}

Note that this approach is generally applicable to all problems where it is necessary to generate permutations of arbitrary length.

\todo[inline]{Finish.}

\subsection{Generating precedences}
\label{sec:generating}

When presented with a \gls{cnf} problem $P$ with signature $\symbols$,
the recommender produces a precedence $\pi$ of symbols from $\symbols$.
\todo{MS: proc nepouzivat znaceni z predchoziho clanku, kdy $P = (\symbols,\mathit{Cl})$?}
In order to generate the precedence,
the recommender first assigns a cost value to each symbol
by invoking a symbol cost model (a trained \gls{gcn}) on a graph representation of $P$.
Ordering the symbols by their predicted costs in nondecreasing order yields the precedence $\pi$.

\subsection{Training}

The training is performed using a fixed \acrlong{atp}.
\todo{MS: zase spis preferuj cinny rod. A klidne muzes proste rict, ze pouzivame vampira :)}
The configuration of the prover,
including for example saturation algorithm, age-weight ratio, and term ordering scheme,
is arbitrary\todo{MS: tohle slovo je prilis silny. Veta by spis mela vysvetlit, ze jsme si neco vybrali, protoze je nam to v postate jedno. Ale zaroven si uvedomujeme, ze to nejak ovlivni vysledek a ze v ultimatnim super-toolu, by se na vsech ostatni paramatrech dalo conditionovat.} and fixed.
The prover needs to support refutational reasoning on \gls{cnf} problems
and use a term simplification ordering parameterized by a symbol precedence.
For example, the \glspl{atp} \vampire{} and E satisfy this requirement.
Note that both of these provers support the \gls{kbo} and \gls{lpo} term simplification ordering schemes,
and that each of these schemes is parameterized by a symbol precedence.
\todo{MS: Jak jsme se o tom bavili; v ramvi Occamovky neni treba zminovat LPO.}

As outlined in \cref{sec:generating},
it is necessary to train a model of symbol costs.
The model is a \gls{gcn}.

\todo[inline]{Include a metagraph and an example graph of a problem.}
\todo[inline]{Compare to HINs}
% https://medium.com/@jason_trost/heterogeneous-information-networks-and-applications-to-cyber-security-23b245461adb

Since it is not obvious what the target symbol cost values should be,
the symbol cost model is not trained directly.
Instead, it is plugged into a classifier that predicts,
given a problem $P$ and a pair of precedences $\pi_0, \pi_1$,
which of the two precedences yields a better performance on $P$.

The symbol cost model is trained by plugging the model into a classifier
that is trained to predict which of a pair of precedences
yields a better performance on an arbitrary problem.

\begin{figure}[ht]
\caption{Architecture overview}
\centering
\digraph[scale=0.4]{precedencepairclassifierdetailed}{
	graph [splines=ortho];
	node [shape=renctangle, fontsize=20];
	edge [fontsize=20];
	fol [label="FOL problem", shape=oval];
	pi0 [shape=oval, label=<&pi;<SUB>0</SUB>>];
	pi1 [shape=oval, label=<&pi;<SUB>1</SUB>>];
	invpi0 [label=<&pi;<SUB>0</SUB><SUP>-1</SUP>>];
	invpi1 [label=<&pi;<SUB>1</SUB><SUP>-1</SUP>>];
	cnf [label="Clause normal form (CNF)"];
	symbolembeddings [label="Symbol embeddings"];
	symbolcosts [label="Symbol costs"];
	pi1pi0 [label="Inverse precedence difference"];
	normalized [label="Normalized inverse precedence difference"];
	paircost [label="Precedence pair cost"];
	fol -> cnf [xlabel=" Vampire "];
	cnf -> symbolembeddings [xlabel=< <B>Graph Convolution Network</B> >];
	symbolembeddings -> symbolcosts [xlabel=< <B>Feed-forward neural network</B> >, style=bold];
	symbolcosts -> paircost [style=bold];
	paircost -> loss [xlabel=" Binary cross-entropy ", style=bold];
	loss [label="Loss", shape=oval];
	pi0 -> invpi0 [xlabel=" Invert "];
	pi1 -> invpi1 [xlabel=" Invert "];
	invpi0 -> pi1pi0;
	invpi1 -> pi1pi0;
	pi1pi0 -> normalized [xlabel=" Normalize "];
	normalized -> paircost;
	symbolprecedence [label="Symbol precedence", style=dashed];
	symbolcosts -> symbolprecedence [xlabel=" Order symbols by their costs ", style=dashed];
}
\end{figure}

\subsection{Layers}
'
\begin{enumerate}
\item Problem -> symbol embeddings
\item Symbol embedding -> symbol cost
\item Symbol costs -> precedence cost
\end{enumerate}

\subsection{Cost models}

%Let $\CostSym: \symbols \rightarrow \re$ be a differentiable symbol cost model.

We define the precedence cost:
$$
\CostPrec(\pi) =
C \sum_{1 \leq i \leq n} \CostSym(\pi(i)) \cdot i =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot \inv{\pi}(s_i)
$$
Precedence cost is minimized by $\pi$ that orders the symbols by their costs in non-increasing order
($\forall (1 \leq i < j \leq n) . (\CostSym(\pi(i)) \geq \CostSym(\pi(j)))$).

Note that we can weight the symbols with an arbitrary nondecreasing function $f$ of symbol index:
$$
\CostPrec(\pi) =
C \sum_{1 \leq i \leq n} \CostSym(\pi(i)) \cdot f(i) =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot f(\inv{\pi}(s_i))
$$

We set $C = \frac{2}{n(n+1)}$ so that $\CostSym(s) = 1$ for all $s$ implies $\CostPrec(\pi) = 1$ for all $\pi$.

% Note that we use this orientation because the TensorFlow metric BinaryCrossentropy classifies 0 as negative and we use the value 0 for "failed to classify" logits.
Given a pair of precedences $\pi_0, \pi_1$,
we define the log-odds of the event "$\pi_0$ is better than $\pi_1$":
$$
\CostPrecPair(\pi_0, \pi_1) =
\CostPrec(\pi_1) - \CostPrec(\pi_0) =
C \sum_{1 \leq i \leq n} \CostSym(s_i) \cdot [\inv{\pi_1}(s_i) - \inv{\pi_0}(s_i)]
$$
Clearly $\CostPrecPair(\pi_0, \pi_1) > 0$ iff $\CostPrec(\pi_0) < \CostPrec(\pi_1)$.
For a pair of precedences about which we know that $\pi_0$ is better than $\pi_1$,
we want $\CostPrecPair(\pi_0, \pi_1) > 0$.

We model the probability of the event ``$\pi_0$ is better than $\pi_1$''
by the sigmoid of $\CostPrecPair(\pi_0, \pi_1)$:
$$
p(\pi_0, \pi_1) = \sigmoid(\CostPrecPair(\pi_0, \pi_1))
$$

We use the binary cross-entropy loss to train the model.
Given a pair of precedences such that $\pi_0$ is better than $\pi_1$,
the loss is as follows:
$$
Loss(\pi_0, \pi_1) = -\log(\sigmoid(\CostPrecPair(\pi_0, \pi_1)))
$$
